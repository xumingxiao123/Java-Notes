# 计算机网络

#### 1 讲一下ISO七层模型？

图片来源：https://www.cnblogs.com/qishui/p/5428938.html
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200406193147171.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUxODAzOA==,size_16,color_FFFFFF,t_70)
**答：应用层->表示层->会话层->传输层->网络层->数据链路层->物理层**
**应用层**：由用户自己规定，**规定各个应用之间消息传递的形式**等，包括各机互访协议，分布式数据库协议等。比如常见的协议**：HTTP协议**（Hyper Text Transfer Protocol）。

**表示层**：规定传输格式。在满足用户需求的基础上，尽可能的节省传输费用而设置的，比如传输压缩文件，jpeg或者加密文件等格式。

**会话层**：用于建立和拆除会话。计算机收到了发送的数据，但是有那么多进程，具体哪个进程需要用到这个数据，则把他输送到那个进程。

**传输层**：负责将来自会话层的消息传递给网络层。人为制定出单位，分成一个个的信息段，从中又衍生了报文，结合上面几层，我们就可以有目标的发送正确数据给某台计算机了。传输层有两个重要的协议**：TCP和UDP**。

**网络层**：**IP选址及其路由选择**。常见的网络层协议有**IP，ICMP以及ARP**等协议。前两层都是在于可以发数据，以及发的数据是否正确，然而如果连着两台电脑还行，多台电脑而又只想让其中一台可以通信，则需要**路由**。选择性的发，那每台电脑就得有自己的身份，于是出现了IP协议等。

**数据链路层**：提供介质访问和连接管理。

**物理层**：规定一些机电性能，也包括工作方式如双工（电话）、单工（打印机）或半双工（传呼机），建立通信的启动和终止等。

参考网站：[link](https://blog.csdn.net/taotongning/article/details/81352985?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task).[link](https://blog.csdn.net/cmyh100/article/details/82768804).

记忆方法：==鹰标会的传人、王树武==

>规定两个应用之间传输的请求和响应格式？那就是**应用层**负责的事情；接下来是不是需要规定传输格式？这就是表示层；然后需要会话层来建立会话；由传输层将数据包传输到网络层，然后通过数据链路来传输；最底层还需要物理层来规定一些物理硬件层面的东西。

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200801154434207.png" alt="image-20200801154434207" style="zoom:67%;" />

#### 2. 输入url（网址）之后到显示网页的过程？

> 已订正，每个步骤都可以细化成很多问题，也可以说这个问题可以覆盖计算机网络常见知识的每个内容。
>
> 参考链接：[link](https://blog.csdn.net/leoe_/article/details/79476279)

1. **DNS （Domain Name Server）域名解析**：浏览器查询 DNS，获取域名对应的 IP 地址。查找顺序为**：浏览器 、缓存系统的缓存、本地的hosts文件、本地DNS服务器、递归查询、迭代查询**。

   > **递归查询**是用户2113只向**本地DNS服务器**发出请求，然后等待**肯定**或**否定**答案。而**迭代**是本地服务器向根DNS服务器发出请求，而根DNS服务器只是给出下一级DNS服务器的地址，然后本地DNS服务器再向下一级DNS发送查询请求直至得到最终答案。

2. **TCP 连接**：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手；

3. **发送 HTTP 请求**：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求；

4. **服务器处理请求并返回HTTP报文**：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器。

5. **浏览器解析渲染页面**：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。

6. **TCP断开连接**：为什么现在结束？浏览器在解析过程中，如果遇到请求外部资源时，如图像,iconfont,JS等。浏览器将重复1-5过程下载该资源。

>> **DNS？**
>>
>> DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个**分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。在RFC文档中RFC 2181对DNS有规范说明，RFC 2136对DNS的动态更新进行说明，RFC 2308对DNS查询的反向缓存进行说明。
>>
>> **Host文件?**
>
>> 是一个没有扩展名的系统文件，可以用记事本等工具打开，其作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”。
>
>> **为什么要域名解析？**
>
>> 　自己注册了域名之后如何才能看到自己的网站内容，用一个专业术语就叫“域名解析”。
>> 　　在相关术语解释中已经介绍，域名和网址并不是一回事，域名注册好之后，只说明你对这个域名拥有了使用权，如果不进行域名解析，那么这个域名就不能发挥别的作用，经过解析的域名可以用来作为电子邮箱的后缀，也可以用来作为网址访问自己的网站，因此域名投入使用的必备环节是“域名解析”。
>> 　　我们知道域名是为了方便记忆而专门建立的一套地址转换系统，要访问一台互联网上的服务器，最终还必须通过**IP地址**来实现，域名解析就是将域名重新转换为IP地址的过程。一个域名只能对应一个IP地址，而多个域名可以同时被解析到一个IP地址。域名解析需要由专门的域名解析服务器(DNS)来完成。
>> 解析过程.比如,一个域名为: www.stasp.com,实现HTTP服务,如果想看到这个网站,要进行解析,首先在域名注册商那里通专门的DNS服务器解析解析到一个WEB服务器的一个固定IP上:211.214.1.***,然后,通过WEB服务器来接收这个域名,把www.stasp.com 这个域名映射到这台服务器上.那么,输入www.stasp.com 这个域名就可以实现访问网站内容了.即可以实现了域名解析全过程;
>> 人们习惯记忆域名，但机器间互相只认IP地址，域名与IP地址之间是一一对应的，它们之间的转换工作称为域名解析，域名解析需要由专门的域名解析服务器来完成，整个过程是自动进行的。　
>
>> http://baike.baidu.com/view/30676.htm
>
>> **DNS查找详细过程**
>
>>* 浏览器缓存 – 浏览器会缓存DNS记录一段时间。 有趣的是，操作系统没有告诉浏览器储存DNS记录的时间，这样不同浏览器会储存个自固定的一个时间（2分钟到30分钟不等）。
>>*  系统缓存 – 如果在浏览器缓存里没有找到需要的记录，浏览器会做一个系统调用（windows里是gethostbyname）。这样便可获得系统缓存中的记录。
>>*  路由器缓存 – 接着，前面的查询请求发向路由器，它一般会有自己的DNS缓存。
>>* ISP DNS 缓存 – 接下来要check的就是ISP缓存DNS的[服务器](http://www.chinahtml.com/server)。在这一般都能找到相应的缓存记录。
>>* 递归搜索 – 你的ISP的DNS[服务器](http://www.chinahtml.com/server)从跟域名[服务器](http://www.chinahtml.com/server)开始进行递归搜索，从.com顶级域名[服务器](http://www.chinahtml.com/server)到
>>* Facebook的域名[服务器](http://www.chinahtml.com/server)。一般DNS[服务器](http://www.chinahtml.com/server)的缓存中会 有.com域名[服务器](http://www.chinahtml.com/server)中的域名，所以到顶级[服务器](http://www.chinahtml.com/server)的匹配过程不是那么必要了。
>
>**谈谈你对域名缓存的了解？**
>
>>为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在域名服务器中广泛使用了高速缓存，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。
>>由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。
>>不仅在本地域名服务器中需要高速缓存，在主机中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。
>>
>>**域名解析过程**
>>
>>1.域名系统
>>
>>![img](https://images2017.cnblogs.com/blog/858807/201708/858807-20170820123427006-190298208.png)
>>
>>![img](https://images2017.cnblogs.com/blog/858807/201708/858807-20170820123443521-1502085421.png)
>>
>> 
>>
>> 2.域名服务器
>>
>>![img](https://images2017.cnblogs.com/blog/858807/201708/858807-20170820123624303-680937649.png)
>>
>>1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己**本地的hosts文件**是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。
>>2. 如果hosts里没有这个域名的映射，则查找**本地DNS解析器缓存**，是否有这个网址映射关系，如果有，直接返回，完成域名解析。
>>3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找T**CP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器**，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。
>>4. 4如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则**调用这个IP地址映射**，完成域名解析，此解析不具有权威性。
>>
>>5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，
>>
>>* **如果未用转发模式**，本地DNS就**把请求发至 “根DNS服务器”**，“根DNS服务器”收到请求后会判断这个域名(.com)是谁来授权管理，并会**返回一个负责该顶级域名服务器的一个IP**。**本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器**。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当**本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询**，直至找到www.qq.com主机。
>>
>>* **如果用的是转发模式**，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。
>>
>>* 不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。
>>
>>**什么是递归查询，迭代查询？**
>>
>>>1. **主机向本地域名服务器的查询一般都是采用递归查询**。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。
>>>
>>>2. **本地域名服务器向根域名服务器的查询的迭代查询**。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。
>>>
>>>3. **递归查询时，返回的结果只有两种:查询成功或查询失败.**
>>>
>>>   **迭代查询，又称作重指引,返回的是最佳的查询点或者主机地址**
>>>
>>>https://www.cnblogs.com/qingdaofu/p/7399670.html
>>

#### 3. 什么是沾包？如何处理？

> https://blog.csdn.net/weixin_45775963/article/details/107451035

1. **什么是TCP粘包**
   TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

2. **出现粘包的原因**

  出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

*  **发送方原因**：Nagle算法造成了发送方可能会出现粘包问题。TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），Nagle算法主要做两件事：只有上一个分组得到确认，才会发送下一个分组；收集多个小分组，在一个确认到来时一起发送。Negale 算法是指发送方发送的数据不会立即发出,而是先放在缓冲区, 等缓存区满了再发出。发送完一批数据后, 会等待接收方对这批数据的回应,然后再发送下一批数据。Negale 算法适用于发送方需要发送大批量数据, 并且接收方会及时作出回应的场合, 这种算法通过减少传输数据的次数来提高通信效率.

*  **接收方原因**：TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

3. **什么时候需要处理？**

* 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象，如果多个分组毫不相干，甚至是并列关系，这个时候就一定要处理粘包现象了。

4. **如何处理？**

* **发送方**：对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

* **接收方**：接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

* **应用层**：解决办法：循环处理，应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成。但是如何判断每条数据的长度呢？**格式化数据**：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。**发送长度**：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置

4. **TCP有粘包，UDP没有粘包**
    TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

  UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

#### 4. [session和cookie的区别](https://www.cnblogs.com/8023-CHD/p/11067141.html)

**一· 概念理解**

首先呢，要了解session和cookie的区别先要了解以下几个概念：

1、**无状态的HTTP协议**：

   协议，是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器。

HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。**这就意味着服务器无法从连接上跟踪会话**。

 2、**会话（Session）跟踪**：

　　会话，指用户登录网站后的一系列动作，比如浏览商品添加到购物车并购买。会话（Session）跟踪是Web程序中常用的技术，用来**跟踪用户的整个会话**。常用的会话跟踪技术是Cookie与Session。**Cookie通过在客户端记录信息确定用户身份**，**Session通过**在服务器端记录信息确定用户身份。

**二cookie**

   由于HTTP是一种无状态的协议，服务器单从网络连接上无从知道客户身份。用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。怎么办呢？就给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。这就是Cookie 的工作原理。

  Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端会把Cookie保存起来。

当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

 1、**会话Cookie**和**持久Cookie**

  若不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，关闭浏览器窗口，cookie就消失。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。

  若设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。存储在硬盘上的cookie可以在浏览器的不同进程间共享。这种称为持久Cookie。 

 2、Cookie具有不可跨域名性

就是说，浏览器访问百度不会带上谷歌的cookie;

**三. Session**

 Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录

 在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。

 每个用户访问服务器都会建立一个session，那服务器是怎么标识用户的唯一身份呢？事实上，用户与服务器建立连接的同时，服务器会自动为其分配一个SessionId。

 1、两个问题：

1）什么东西可以让你每次请求都把SessionId自动带到服务器呢？显然就是cookie了，如果你想为用户建立一次会话，可以在用户授权成功时给他一个唯一的cookie。当一个

用户提交了表单时，浏览器会将用户的SessionId自动附加在HTTP头信息中，（这是浏览器的自动功能，用户不会察觉到），当服务器处理完这个表单后，将结果返回给SessionId

所对应的用户。试想，如果没有 SessionId，当有两个用户同时进行注册时，服务器怎样才能知道到底是哪个用户提交了哪个表单呢。

2）储存需要的信息。服务器通过SessionId作为key，读写到对应的value，这就达到了保持会话信息的目的。

 2、session的创建：

当程序需要为某个客户端的请求创建一个session时，服务器首先检查这个客户端的请求里是否已包含了sessionId，如果已包含则说明以前已经为此客户端创建过session，服务

器就按照sessionId把这个session检索出来使用（检索不到，会新建一个），如果客户端请求不包含sessionId，则为此客户端创建一个session并且生成一个与此session相关

联的sessionId，sessionId的值是一个既不会重复，又不容易被找到规律以仿造的字符串，这个sessionId将被在本次响应中返回给客户端保存。

 3、禁用cookie：

　　如果客户端禁用了cookie，通常有两种方法实现session而不依赖cookie。

1）URL重写，就是把sessionId直接附加在URL路径的后面。

2）表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。比如： 

~~~java
<form name="testform" action="/xxx"> 
<input type="hidden" name="jsessionid" value="ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764"> 
<input type="text"> 
</form> 
~~~

 4、Session共享： 

对于多网站(同一父域不同子域)单服务器，我们需要解决的就是来自不同网站之间SessionId的共享。由于域名不同(aaa.test.com和bbb.test.com)，而SessionId又分别储存

在各自的cookie中，因此服务器会认为对于两个子站的访问,是来自不同的会话。解决的方法是通过修改cookies的域名为父域名达到cookie共享的目的,从而实现SessionId的共

享。带来的弊端就是，子站间的cookie信息也同时被共享了。 

**四. 总结**

1、**cookie数据存放在客户的浏览器上，session数据放在服务器上**。

2、**cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session**。

3、**session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie**。

4、**单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie**。

5、**可以考虑将登陆信息等重要信息存放为session，其他信息如果需要保留，可以放在cookie中**。

**五.应用场景**

- 登录网站，今输入用户名密码登录了，第二天再打开很多情况下就直接打开了。这个时候用到的一个机制就是cookie。
- session一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而服务器端如何判别呢，所以也需要存储一些信息就用到了session

#### 5. ip地址及子网掩码换算，子网划分教程

https://jingyan.baidu.com/article/ae97a646d936ddbbfd461d02.html

![ipå°ååå­ç½æ©ç æ¢ç®ï¼å­ç½ååæç¨](https://exp-picture.cdn.bcebos.com/5e615d715fdb3620927c133aabc5260f89358d99.jpg?x-bce-process=image%2Fresize%2Cm_lfit%2Cw_500%2Climit_1)

https://blog.csdn.net/xiaohxx/article/details/79427180?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

#### 【<  TCP专题之三次握手四次挥手>】

##### [1]   TCP报文的结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200405105138269.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUxODAzOA==,size_16,color_FFFFFF,t_70)

**TCP报文是TCP层传输的数据单元，也叫报文段。**

**1、端口号**：用来标识同一台计算机的不同的应用进程。

**1）源端口**：源端口和IP地址的作用是标识报文的返回地址。

**2）目的端口**：端口指明接收方计算机上的应用程序接口。

TCP报头中的源端口号和目的端口号同IP数据报中的源IP与目的IP唯一确定一条TCP连接。

**2、序号和确认号**：是TCP可靠传输的关键部分。**序号**是本报文段发送的数据组的第一个字节的序号。在TCP传送的流中，每一个字节一个序号。e.g.一个报文段的序号为300，此报文段数据部分共有100字节，则下一个报文段的序号为400。所以序号确保了TCP传输的有序性。确认号，即ACK，指明下一个期待收到的字节序号，表明该序号之前的所有数据已经正确无误的收到。确认号只有当ACK标志为1时才有效。比如建立连接时，SYN报文的ACK标志位为0。

**3、数据偏移／首部长度**：4bits。由于首部可能含有可选项内容，因此TCP报头的长度是不确定的，报头不包含任何任选字段则长度为20字节，4位首部长度字段所能表示的最大值为1111，转化为10进制为15，15*32/8 = 60，故报头最大长度为60字节。首部长度也叫数据偏移，是因为首部长度实际上指示了数据区在报文段中的起始偏移值。

**4、保留**：为将来定义新的用途保留，现在一般置0。

**5、控制位**：URG  ACK  PSH  RST  SYN  FIN，共6个，每一个标志位表示一个控制功能。

**1）URG**：紧急指针标志，为1时表示紧急指针有效，为0则忽略紧急指针。

**2）ACK**：确认序号标志，为1时表示确认号有效，为0表示报文中不含确认信息，忽略确认号字段。

**3）PSH**：push标志，为1表示是带有push标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队。

**4）RST**：重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请求。

**5）SYN**：同步序号，用于建立连接过程，在连接请求中，SYN=1和ACK=0表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即SYN=1和ACK=1。

**6）FIN**：finish标志，用于释放连接，为1时表示发送方已经没有数据发送了，即关闭本方数据流。

**6、窗口**：滑动窗口大小，用来告知发送端接受端的缓存大小，以此控制发送端发送数据的速率，从而达到流量控制。窗口大小时一个16bit字段，因而窗口大小最大为65535。

**7、校验和**：奇偶校验，此校验和是对整个的 *TCP* 报文段，包括 *TCP* 头部和 *TCP* 数据，以 *16* 位字进行计算所得。由发送端计算和存储，并由接收端进行验证。

**8、紧急指针**：只有当 *URG* 标志置 *1* 时紧急指针才有效。紧急指针是一个正的偏移量，和顺序号字段中的值相加表示紧急数据最后一个字节的序号。 *TCP* 的紧急方式是发送端向另一端发送紧急数据的一种方式。

**9、选项和填充**：最常见的可选字段是最长报文大小，又称为MSS（Maximum Segment Size），每个连接方通常都在通信的第一个报文段（为建立连接而设置SYN标志为1的那个段）中指明这个选项，它表示本端所能接受的最大报文段的长度。选项长度不一定是32位的整数倍，所以要加填充位，即在这个字段中加入额外的零，以保证TCP头是32的整数倍。

**10、数据部分**： *TCP* 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有 *TCP* 首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中，也会发送不带任何数据的报文段。

**SYN，ACK，FIN等详细介绍**：

*   **同步SYN**：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。
*   **确认ACK**：占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效。
*   **终止FIN**：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接。
*   **序列号seq**：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由**本地随机**产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。
*   **确认号ack**：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。

##### [2]  解释一下TCP三次握手四次挥手

> [link](https://blog.csdn.net/mxgsgtc/article/details/12718905?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare)

图片来源于微信公众号**：码农求职小助手**
![image-20200721194128725](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200721194128725.png)
答： 嗯(稍作思考)....

* 三次握手简单来说，在数据传输开始前：
  **第一次：客户端将SYN标记为置为1，随机产生一个值seq=x，并将数据包发送给服务端表示要请求连接，客户端状态由CLOSE阶段切换到SYN_SENT阶段，并等待服务端回应**。
   **第二次：服务器端接收之后，服务端会将标志位SYN和ACK都置为1，seq=y，ack=x+1，发送给客户端，表示同意连接。服务端从LISTEN状态切换到SYN-RCVD状态**。
  **第三次：客户端收到服务端的确认后，检查ack是否为x+1，若正确则将标志位ACK置为1，ack=y+1，并发送会服务端，此时客户端的状态切换为ESTABLISH状态，完成三次握手**。
  三次握手完毕后，客户端与服务器才正式开始传送数据。

>    **SYN攻击**：
>         在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：
>         \#netstat -nap | grep SYN_RECV

![image-20200721194310325](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200721194310325.png)

* 四次挥手简单来说，在数据传输结束后：
  **第一次挥手：客户端发送一个FIN包，序号seq=u，用来关闭数据传送，客户端由FIN_WAIT_1状态切换到ESTABLISH状态**。
  **第二次挥手：服务端收到FIN包后，发送一个ACK给服务端，ack=u+1，服务端由ESTABLISH状态切换到CLOSE_WAIT状态**。
  **第三次挥手：服务端发送一个FIN包，seq=w，状态由CLOSE_WAIT状态切换到LAST_ACK状态**。
  **第四次挥手：客户端收到FIN后，发送一个确认包，ack=w+1，并且进入TIME_WAIT状态，等待2MSL（MSL最长报文段寿命）后，进入CLOSE状态。服务端收到确认号直接进入CLOSE阶段**

> PS：ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。原文链接：[link](https://blog.csdn.net/qq_38950316/article/details/81087809).

##### [3]   为什么是三次握手，可以是两次吗？

**不可以**。假如没有第三次握手，服务端在某一时刻突然收到了一个来自被客户端卡了很久已经丢弃的SYN包，此时客户端是不想建立连接的，服务端的操作是返回SYN+ACK并且进入工作状态。客户端收到反馈后，无法告诉服务端这是错误的SYN的包，**会造成资源的浪费**。

##### [4]   为什么断开连接需要四次挥手？

答**：因为在客户端发送给服务端FIN包后，服务端返回的FIN和ACK包是分开发送的**。为什么要分开呢？因为客户端发送给服务端FIN包后，只表示客户端已经没有数据要发送了，**但是另一个方向上可能还会有数据传输进来**。所以第二次和第三次挥手分开发送，服务端先给出ACK确认信号，表示已经收到FIN请求，然后**当自己也可以结束的时候**，即真正结束数据传输的时候，再次发送FIN信号。**是为了为未传输完毕的数据预留时间**，所以需要挥手交互需要四次。

##### [5]  为什么 TIME-WAIT 状态必须等待 2MSL 的时间呢？

1. **为了保证 客户端 发送的最后一个 ACK 报文段能够到达 服务端。 客户端 发送的最后一个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的 服务端收不到对已发送的 FIN + ACK 报文段的确认。服务端 会超时重传这个 FIN报文段，而 客户端 就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着客户端重传一次确认，重新启动 2MSL 计时器。最后，客户端  和 服务端 都正常进入到 CLOSED 状态**。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段，这样，B 就无法按照正常步骤进入 CLOSED 状态。
2. **防止已失效的连接请求报文段出现在本连接中**。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。

>[什么是2MSL](http://blog.csdn.net/xiaofei0859/article/details/6044694)？
>
>MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为tcp报文（segment）是ip数据报（datagram）的数据部分，具体称谓请参见《数据在网络各层中的称呼》一文，而ip头中有一个TTL域，TTL是time to live的缩写，中文可以译为“**生存时间**”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。
>
>  2MSL即两倍的MSL，TCP的TIME_WAIT状态也称为2MSL等待状态，当TCP的一端发起主动关闭，在发出最后一个ACK包后，即第3次握手完成后发送了第四次握手的ACK包后就进入了TIME_WAIT状态，必须在此状态上停留两倍的MSL时间，等待2MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。在TIME_WAIT状态时两端的端口不能使用，要等到2MSL时间结束才可继续使用。当连接处于2MSL等待阶段时任何迟到的报文段都将被丢弃。不过在实际应用中可以通过设置SO_REUSEADDR选项达到不必等待2MSL时间结束再使用此端口。
>
>  TTL与MSL是有关系的但不是简单的相等的关系，MSL要大于等于TTL。

#### 【<TCP专题>】

##### [1] 讲一下TCP/IP协议？

TCP/IP协议模型在OSI七层模型的基础上，通过合并的方式，简化为四层，分别为**应用层，传输层，网络层以及链路层**。

我们通常的应用程序都工作在应用层，当各个应用之间通信时，传输层的TCP模块负责给HTTP数据添加TCP头部等信息；网络层的IP模块负责给HTTP数据添加IP头部等信息；链路层添加以太网首部等信息，并且通过电信号来传输数据包；然后数据包会依次经过对方的链路层，网络层，传输层以及应用层，实现数据的通信。

##### [2]  讲一下TCP和UDP协议的区别（5条）？

答：TCP和UDP协议都是**传输层**常见的协议，它们的主要区别如下所示：

1. **TCP提供面向连接的传输**，通信前要先建立连接（三次握手机制）； **UDP提供无连接的传输**，通信前不需要建立连接。
2. **TCP提供可靠的传输**（校验，重排序，应答，丢弃重复，超时重发，滑动窗口）； **UDP不能保证传输的可靠**。
3. **TCP面向字节流的传输**，因此它能将信息分割成组，并在接收端将其重组； UDP是**面向数据报的传输**，没有分组开销。
4. **TCP提供拥塞控制**； UDP则不提供。
5. 每一条TCP连接只能是**点到点**的；UDP支持**一对一，一对多，多对一和多对多**的交互通信；
6. 网络包中的TCP头部为**20-60**个字节；UDP头部只有**8**个字节。

> **数据报**是通过网络传输的数据的基本单元，包含一个报头（header）和数据本身，其中报头描述了数据的目的地以及和其它数据之间的关系。数据报是完备的、独立的数据实体，该实体携带要从源计算机传递到目的计算机的信息，该信息不依赖以前在源计算机和目的计算机以及传输网络间交换

> **总结**：TCP通信类似于打电话，接通了，确认身份后，开始通话；
> UDP通信类似于村喇叭，很多村民都能听到。

##### [3] **TCP协议是如何保证可靠传输的？**

1. **数据包校验**：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；

2. **对失序数据包重排序**：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；

3. **丢弃重复数据**：对于重复数据，能够丢弃重复数据；

4. **应答机制**：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个**确认**（这个确认不是立即发送，通常将推迟几分之一秒）；

5. **超时重发**：当 TCP 发出一个段后，它启动一个**定时器**，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；

6. **滑动窗口**：是一种流量控制技术。TCP连接每一方都有固定大小的缓冲空间，滑动窗口的大小意味这**接收方有多大的缓存区接受数据**。当接收缓冲池的大小发生变化时，要给对方发送更新窗口大小的通知，利用滑动窗口机制有效提高通信效率。

#### 【<TCP 流量控制和拥塞控制专题>】

##### [1]   什么是“拥塞”？

当提供给任何网络的负载能力超过它的处理能力时，拥塞便会产生。

##### [2]   TCP流量控制和拥塞控制有什么区别?

TCP协议有两个比较重要的控制算法，一个是**流量控制**，另一个就是**阻塞控制**。

TCP协议通过滑动窗口来进行流量控制，它是控制发送方的发送速度从而使接受者来得及接收并处理。而拥塞控制作用于整体网络，**它是防止过多的包被发送到网络中，避免出现网络负载过大，网络拥塞的情况**。

拥塞算法需要掌握其状态机和四种算法。拥塞控制状态机的状态有五种，分别是Open，Disorder，CWR，Recovery和Loss状态。四个算法为**慢启动，拥塞避免，拥塞发生时算法和快恢复**。

##### [3]   TCP拥塞控制四大算法?

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200414162303232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUxODAzOA==,size_16,color_FFFFFF,t_70)

拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）快重传，4）快速恢复。

1. 也就是CP连接刚建立使用**慢启动算法**，发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，其发送的数据包数量在每一个往返时间段都会呈指数形式上升，即cwnd会加倍。
2. 直到达到预设置的一个慢开始门限 ssthresh ，就会执行**拥塞避免算法**。拥塞避免规定数据包会从指数递增切换到加法递增。
3. 若发生拥塞，比较古老的方法是**超时重传算法**，它会在发送一个数据以后就开启一个计时器，在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。但是如果执行**快重传算法**，发送方如果收到**三个重复确认**，那么可以知道下一个报文段丢失，立即重传下一个报文段，而不用等计时器到时间。
4. 超时重传算法将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2。并且cwnd重置为1，但是使用**快速恢复算法**会将cwnd大小缩小为当前的一半，ssthresh设置为缩小后的cwnd大小。总结则是，超时重传算法会让一切重新开始，慢启动阀值折半且拥塞窗口置为1，进入慢启动。但是使用**快速恢复算法**则只需要将窗口和慢启动阀值折半，窗口重新进入线性增加状态即可。

>**详细过程**：
>发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。
>
>>**慢启动算法+拥塞避免**
>>
>>* 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...
>>* 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。
>>* 如果出现了**超时**，则令 ssthresh = cwnd / 2，然后重新执行慢开始。
>>
>>**快重传+快恢复**
>>
>>* 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。
>>* 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。
>>* 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
>>* 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

#### 【<HTTP专题>】

参考链接：[link1](https://developer.mozilla.org/zh-CN/docs/Web/HTTP)[link2](https://www.ietf.org)

##### [1]    HTTP是什么？

**超文本传输协议（HTTP）**是一个用于传输超媒体文档（例如 HTML）的[应用层](https://en.wikipedia.org/wiki/Application_Layer)协议。它是为 Web 浏览器与 Web 服务器之间的通信而设计的，但也可以用于其他目的。HTTP 遵循经典的[客户端-服务端模型](https://en.wikipedia.org/wiki/Client–server_model)，客户端打开一个连接以发出请求，然后等待它收到服务器端响应。HTTP 是[无状态协议](http://en.wikipedia.org/wiki/Stateless_protocol)，这意味着服务器不会在两个请求之间保留任何数据（状态）。该协议虽然通常基于 TCP/IP 层，但可以在任何可靠的[传输层](https://zh.wikipedia.org/wiki/传输层)上使用；也就是说，不像 UDP，它是一个不会静默丢失消息的协议。[RUDP](https://en.wikipedia.org/wiki/Reliable_User_Datagram_Protocol)——作为 UDP 的可靠化升级版本——是一种合适的替代选择。

##### [2]    HTTP概述

<img src="https://mdn.mozillademos.org/files/13673/HTTP%20&amp;%20layers.png" alt="HTTP as an application layer protocol, on top of TCP (transport layer) and IP (network layer) and below the presentation layer." style="zoom: 25%;" />

**HTTP是一种能够获取如 HTML 这样的网络资源的 [protocol](https://developer.mozilla.org/en-US/docs/Glossary/protocol)(通讯协议)**。它是在 Web 上进行数据交换的基础，是一种 client-server 协议，也就是说，请求通常是由像浏览器这样的接受方发起的。一个完整的Web文档通常是由不同的子文档拼接而成的，像是文本、布局描述、图片、视频、脚本等等。

##### [3]    HTTP 的基本性质

1. **HTTP 是简单的**。虽然下一代HTTP/2协议将HTTP消息封装到了帧（frames）中，HTTP大体上还是被设计得简单易读。HTTP报文能够被人读懂，还允许简单测试，降低了门槛，对新人很友好。

2. **HTTP 是可扩展的**。在 HTTP/1.0 中出现的 [HTTP headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers) 让协议扩展变得非常容易。只要服务端和客户端就新 headers 达成语义一致，新功能就可以被轻松加入进来。

3. **HTTP 是无状态，有会话的**。HTTP是无状态的：在同一个连接中，两个执行成功的请求之间是没有关系的。这就带来了一个问题，用户没有办法在同一个网站中进行连续的交互，比如在一个电商网站里，用户把某个商品加入到购物车，切换一个页面后再次添加了商品，这两次添加商品的请求之间没有关联，浏览器无法知道用户最终选择了哪些商品。而使用HTTP的头部扩展，HTTP Cookies就可以解决这个问题。把Cookies添加到头部中，创建一个会话让每次请求都能共享相同的上下文信息，达成相同的状态。**注意，HTTP本质是无状态的，使用Cookies可以创建有状态的会话**。

4. **HTTP 和连接**。一个连接是由传输层来控制的，这从根本上不属于HTTP的范围。HTTP并不需要其底层的传输层协议是面向连接的，只需要它是可靠的，或不丢失消息的（至少返回错误）。在互联网中，有两个最常用的传输层协议：TCP是可靠的，而UDP不是。因此，HTTP依赖于面向连接的TCP进行消息传递，但连接并不是必须的。

   在客户端（通常指浏览器）与服务器能够交互（客户端发起请求，服务器返回响应）之前，必须在这两者间建立一个 TCP 链接，打开一个 TCP 连接需要多次往返交换消息（因此耗时）。HTTP/1.0 默认为每一对 HTTP 请求/响应都打开一个单独的 TCP 连接。当需要连续发起多个请求时，这种模式比多个请求共享同一个 TCP 链接更低效。

   为了减轻这些缺陷，HTTP/1.1引入了流水线（被证明难以实现）和持久连接的概念：底层的TCP连接可以通过[`Connection`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Connection)头部来被部分控制。HTTP/2则发展得更远，通过在一个连接复用消息的方式来让这个连接始终保持为暖连接。 

   为了更好的适合HTTP，设计一种更好传输协议的进程一直在进行。Google就研发了一种以UDP为基础，能提供更可靠更高效的传输协议[QUIC](https://en.wikipedia.org/wiki/QUIC)。

##### [4]    HTTP 报文

HTTP/1.1以及更早的HTTP协议报文都是语义可读的。在HTTP/2中，这些报文被嵌入到了一个新的二进制结构，帧。帧允许实现很多优化，比如报文头部的压缩和复用。即使只有原始HTTP报文的一部分以HTTP/2发送出来，每条报文的语义依旧不变，客户端会重组原始HTTP/1.1请求。因此用HTTP/1.1格式来理解HTTP/2报文仍旧有效。

有两种HTTP报文的类型，**请求与响应**，每种都有其特定的格式。

1. **请求**

   <img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200511111226252.png" alt="image-20200511111226252" style="zoom:50%;" />

   请求由以下元素组成：

   - 一个HTTP的[method](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods)，经常是由一个动词像[`GET`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET), [`POST`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/POST) 或者一个名词像[`OPTIONS`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/OPTIONS)，[`HEAD`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/HEAD)来定义客户端的动作行为。通常客户端的操作都是获取资源（GET方法）或者发送[HTML form](https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Forms)表单值（POST方法），虽然在一些情况下也会有其他操作。
   - 要获取的资源的路径，通常是上下文中就很明显的元素资源的URL，它没有[protocol](https://developer.mozilla.org/en-US/docs/Glossary/protocol)（`http://`），[domain](https://developer.mozilla.org/en-US/docs/Glossary/domain)（`developer.mozilla.org`），或是TCP的[port](https://developer.mozilla.org/en-US/docs/Glossary/port)（HTTP一般在80端口）。
   - HTTP协议版本号。
   - 为服务端表达其他信息的可选头部[headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers)。
   - 对于一些像POST这样的方法，报文的body就包含了发送的资源，这与响应报文的body类似。

2. **响应**

   <img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200511111332621.png" alt="image-20200511111332621" style="zoom:50%;" />

响应报文包含了下面的元素：

- HTTP协议版本号。
- 一个状态码（[status code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)），来告知对应请求执行成功或失败，以及失败的原因。
- 一个状态信息，这个信息是非权威的状态码描述信息，可以由服务端自行设定。
- HTTP [headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers)，与请求头部类似。
- 可选项，比起请求报文，响应报文中更常见地包含获取的资源body。

##### [5]   HTTP 请求方法

HTTP 定义了一组**请求方法**, 以表明要对给定资源执行的操作。指示针对给定资源要执行的期望动作. 虽然他们也可以是名词, 但这些请求方法有时被称为HTTP动词. 

```
GET
```

GET方法请求一个指定资源的表示形式. 使用GET的请求应该只被用于获取数据.

```
HEAD
```

HEAD方法请求一个与GET请求的响应相同的响应，但没有响应体.

```
POST
```

POST方法用于将实体提交到指定的资源，通常导致在服务器上的状态变化或副作用. 

```
PUT
```

PUT方法用请求有效载荷替换目标资源的所有当前表示。

```
DELETE
```

DELETE方法删除指定的资源。

```
CONNECT
```

CONNECT方法建立一个到由目标资源标识的服务器的隧道。

```
OPTIONS
```

OPTIONS方法用于描述目标资源的通信选项。

```
TRACE
```

TRACE方法沿着到目标资源的路径执行一个消息环回测试。

```
PATCH
```

PATCH方法用于对资源应用部分修改。

##### [6]   HTTP 响应代码

HTTP 响应状态代码指示特定 [HTTP](https://developer.mozilla.org/zh-cn/HTTP) 请求是否已成功完成。响应分为五类：信息响应(`100`–`199`)，成功响应(`200`–`299`)，重定向(`300`–`399`)，客户端错误(`400`–`499`)和服务器错误 (`500`–`599`)。状态代码由 [section 10 of RFC 2616](https://tools.ietf.org/html/rfc2616#section-10)定义。

###### 信息响应（100-199）

- [`100 Continue`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/100)

  这个临时响应表明，迄今为止的所有内容都是可行的，客户端应该继续请求，如果已经完成，则忽略它。

- [`101 Switching Protocol`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/101)

  该代码是响应客户端的 [`Upgrade`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Upgrade) 标头发送的，并且指示服务器也正在切换的协议。

- [`102 Processing`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/102) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  此代码表示服务器已收到并正在处理该请求，但没有响应可用。

- [`103 Early Hints`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/103) 

  此状态代码主要用于与[`Link`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Link) 链接头一起使用，以允许用户代理在服务器仍在准备响应时开始预加载资源。

###### 成功响应（200-299）

- [`200 OK`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200)

  请求成功。成功的含义取决于HTTP方法：GET：资源已被提取并在消息正文中传输。HEAD：实体标头位于消息正文中。POST：描述动作结果的资源在消息体中传输。TRACE：消息正文包含服务器收到的请求消息

- [`201 Created`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/201)

  该请求已成功，并因此创建了一个新的资源。这通常是在POST请求，或是某些PUT请求之后返回的响应。

- [`202 Accepted`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/202)

  请求已经接收到，但还未响应，没有结果。意味着不会有一个异步的响应去表明当前请求的结果，预期另外的进程和服务去处理请求，或者批处理。

- [`203 Non-Authoritative Information`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/203)

  服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超集。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。

- [`204 No Content`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/204)

  服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。

- [`205 Reset Content`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/205)

  服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。

- [`206 Partial Content`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/206)

  服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。

- [`207 Multi-Status`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/207) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。

- [`208 Already Reported`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/208) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  在 DAV 里面使用: propstat 响应元素以避免重复枚举多个绑定的内部成员到同一个集合。

- [`226 IM Used`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/226) ([HTTP Delta encoding](https://tools.ietf.org/html/rfc3229))

  服务器已经完成了对资源的 GET 请求，并且响应是对当前实例应用的一个或多个实例操作结果的表示。

###### 重定向（300-399）

- [`300 Multiple Choice`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/300)

  被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。

- [`301 Moved Permanently`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/301)

  **被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。**

- [`302 Found`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/302)

  **请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。**

  **重定向是网页制bai作中的一个知识，几个例子跟你说du明，假设你现在所处的位置是zhi一个论dao坛的登录页面，你填写了帐号，密码，点击登陆，如果你的帐号密码正确，就自动跳转到论坛的首页，不正确就返回登录页；这里的自动跳转，就是重定向的意思。或者可以说，重定向就是，在网页上设置一个约束条件，条件满足，就自动转入到其它网页、网址**

  **301和302区别**：

  https://www.cnblogs.com/tongongV/p/10944414.html

- [`303 See Other`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/303)

  对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。

- [`304 Not Modified`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/304)

  如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304 响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。

- `305 Use Proxy` 

  被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。

- `306 unused`

  在最新版的规范中，306 状态码已经不再被使用。

- [`307 Temporary Redirect`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/307)

  请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。

- [`308 Permanent Redirect`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/308)

  这意味着资源现在永久位于由 `Location:` HTTP Response 标头指定的另一个 URI。 这与 `301 Moved Permanently HTTP` 响应代码具有相同的语义，但用户代理不能更改所使用的 HTTP 方法：如果在第一个请求中使用 `POST`，则必须在第二个请求中使用 `POST`。

###### 客户端响应（400-499）

- [`400 Bad Request`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/400)

  1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。

  2、请求参数有误。

- [`401 Unauthorized`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/401)

  当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。

- `402 Payment Required`

  此响应码保留以便将来使用，创造此响应码的最初目的是用于数字支付系统，然而现在并未使用。

- [`403 Forbidden`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/403)

  服务器已经理解请求，但是拒绝执行它。与 401 响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个 404 响应，假如它不希望让客户端获得任何信息。

- [`404 Not Found`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/404)

  **请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。**

- [`405 Method Not Allowed`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/405)

  请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。

- [`406 Not Acceptable`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/406)

  请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。

- [`407 Proxy Authentication Required`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/407)

  与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。

- [`408 Request Timeout`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/408)

  请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。

- [`409 Conflict`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/409)

  由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。

- [`410 Gone`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/410)

  被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用 404 状态码。除非额外说明，否则这个响应是可缓存的。

- [`411 Length Required`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/411)

  服务器拒绝在没有定义 `Content-Length` 头的情况下接受请求。在添加了表明请求消息体长度的有效 `Content-Length` 头之后，客户端可以再次提交该请求。

- [`412 Precondition Failed`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/412)

  服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。

- [`413 Payload Too Large`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/413)

  服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。如果这个状况是临时的，服务器应当返回一个 `Retry-After` 的响应头，以告知客户端可以在多少时间以后重新尝试。

- [`414 URI Too Long`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/414)

  请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括：本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。

- [`415 Unsupported Media Type`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/415)

  对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。

- [`416 Range Not Satisfiable`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/416)

  如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。

- [`417 Expectation Failed`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/417)

  此响应代码意味着服务器无法满足 [`Expect`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Expect) 请求标头字段指示的期望值。

- [`418 I'm a teapot`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/418)

  服务器拒绝尝试用 `“茶壶冲泡咖啡”`。

- [`421 Misdirected Request`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/421)

  该请求针对的是无法产生响应的服务器。 这可以由服务器发送，该服务器未配置为针对包含在请求 URI 中的方案和权限的组合产生响应。

- [`422 Unprocessable Entity`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/422) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  请求格式良好，但由于语义错误而无法遵循。

- [`423 Locked`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/423) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  正在访问的资源被锁定。

- [`424 Failed Dependency`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/424) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  由于先前的请求失败，所以此次请求失败。

- [`425 Too Early`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/425)

  服务器不愿意冒着风险去处理可能重播的请求。

- [`426 Upgrade Required`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/426)

  服务器拒绝使用当前协议执行请求，但可能在客户机升级到其他协议后愿意这样做。 服务器在 426 响应中发送 [`Upgrade`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Upgrade) 头以指示所需的协议。

- [`428 Precondition Required`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/428)

  原始服务器要求该请求是有条件的。 旨在防止“丢失更新”问题，即客户端获取资源状态，修改该状态并将其返回服务器，同时第三方修改服务器上的状态，从而导致冲突。

- [`429 Too Many Requests`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/429)

  用户在给定的时间内发送了太多请求（“限制请求速率”）。

- [`431 Request Header Fields Too Large`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/431)

  服务器不愿意处理请求，因为它的 请求头字段太大（ Request Header Fields Too Large）。 请求可以在减小请求头字段的大小后重新提交。

- [`451 Unavailable For Legal Reasons`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/451)

  用户请求非法资源，例如：由政府审查的网页。

###### 服务端响应（500-599）

- [`500 Internal Server Error`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/500)

  **服务器遇到了不知道如何处理的情况。**

- [`501 Not Implemented`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/501)

  此请求方法不被服务器支持且无法被处理。只有`GET`和`HEAD`是要求服务器支持的，它们必定不会返回此错误代码。

- [`502 Bad Gateway`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/502)

  此错误响应表明服务器作为网关需要得到一个处理这个请求的响应，但是得到一个错误的响应。

- [`503 Service Unavailable`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/503)

  服务器没有准备好处理请求。 常见原因是服务器因维护或重载而停机。 请注意，与此响应一起，应发送解释问题的用户友好页面。 这个响应应该用于临时条件和 `Retry-After`：如果可能的话，HTTP头应该包含恢复服务之前的估计时间。 网站管理员还必须注意与此响应一起发送的与缓存相关的标头，因为这些临时条件响应通常不应被缓存。

- [`504 Gateway Timeout`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/504)

  当服务器作为网关，不能及时得到响应时返回此错误代码。

- [`505 HTTP Version Not Supported`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/505)

  服务器不支持请求中所使用的HTTP协议版本。

- [`506 Variant Also Negotiates`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/506)

  服务器有一个内部配置错误：对请求的透明内容协商导致循环引用。

- [`507 Insufficient Storage`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/507)

  服务器有内部配置错误：所选的变体资源被配置为参与透明内容协商本身，因此不是协商过程中的适当端点。

- [`508 Loop Detected`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/508) ([WebDAV](https://developer.mozilla.org/en-US/docs/Glossary/WebDAV))

  服务器在处理请求时检测到无限循环。

- [`510 Not Extended`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/510)

  客户端需要对请求进一步扩展，服务器才能实现它。服务器会回复客户端发出扩展请求所需的所有信息。

- [`511 Network Authentication Required`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/511)

  511 状态码指示客户端需要进行身份验证才能获得网络访问权限。

##### [7]   谈下 HTTP 1.0 和 1.1、2.0的主要变化？

1. HTTP1.0 经过多年发展，在 1.1 提出了改进。首先是提出了**长连接**，HTTP 可以在一次 TCP 连接中不断发送请求。
2. HTTP2.0 支持**多路复用**，同一个连接可以并发处理多个请求，方法是把 HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个 HTTP请求顺序到达；

##### [8]   讲一下HTTP和HTTPS协议的区别？

> 已经订正**参考文章**：[link1](https://blog.csdn.net/xiaoming100001/article/details/81109617)，[link2](https://blog.csdn.net/qq_38289815/article/details/80969419?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)

* **HTTP数据时明文传输，HTTPS是基于SSL的密文传输**；
* HTTPS一般是要需要区证书，是收费的；
* HTTP默认使用80端口，HTTPS默认使用443端口。

##### [9] 简单介绍一下SSL？ [link](https://baike.baidu.com/item/%E5%AE%89%E5%85%A8%E5%A5%97%E6%8E%A5%E5%B1%82/9442234?fr=aladdin)

**SSL(secure socket layer)是在应用层(http/ftp)和传输层(tcp/ip)之间的一个中间层，负责处理证书，会话创建，加解密等一系列的工作，这样对应用层来说，底下如何加密如何解密时完全透明的。**

记录协议为不同的更高层协议提供基本的安全服务，其特点是为web客户/服务器的交互提供传输服务的[超文本](https://baike.baidu.com/item/超文本)[传输协议](https://baike.baidu.com/item/传输协议)（HTTP）可在SSL上面运行。三个更高层协议被定义成SSL的一部分：握手协议、修改密文规约协议和告警协议。

SSL中两个重要的概念是**SSL会话**和**SSL连接**，规约如下：

（1）连接：连接是提供恰当类型服务的传输，对于SSL这样的连接是点对点的关系。连接是短暂的，每个连接与一个会话相联系。

（2）会话：SSL的会话是客户和服务器之间的关联，会话通过[握手协议](https://baike.baidu.com/item/握手协议)来创建。会话定义了加密安全参数的一个集合，该集合可以被多个连接所共享。会话可用来避免为每个连接进行昂贵的新安全参数的协商。(Secure Sockets Layer）安全套接层，**主要提供以下安全服务**。

（1）信息保密，通过使用[公开密钥](https://baike.baidu.com/item/公开密钥)和对称密钥技术以达到信息保密。SSL客户机和服务器之间的所有业务都使用在SSL握手过程中建立的[密钥](https://baike.baidu.com/item/密钥)和算法进行加密。这样就防止了某些用户通过使用IP数据包[嗅探](https://baike.baidu.com/item/嗅探)工具非法窃听。尽管数据包嗅探仍能捕捉到通信的内容，但却无法破译。

（2）信息完整性，确保SSL业务全部达到目的。应确保服务器和客户机之间的信息内容免受破坏。SSL利用机密共享和[hash函数](https://baike.baidu.com/item/hash函数)组提供信息完整性服务。

（3）双向认证，客户机和服务器相互识别的过程。它们的识别号用公开密钥编码，并在SSL握手时交换各自的识别号。为了验证证明持有者是其合法用户（而不是冒名用户），SSL要求证明持有者在握手时对交换数据进行数字式标识。证明持有者对包括证明的所有信息数据进行标识，以说明自己是证明的合法拥有者。这样就防止了其他用户冒名使用证明。证明本身并不提供认证，只有证明和密钥一起才起作用。

（4）SSL的安全性服务对终端用户来讲做到尽可能透明。一般情况下，用户只需单击桌面上的一个按钮或联接就可以与SSL的[主机](https://baike.baidu.com/item/主机)相连。与标准的HTTP连接申请不同，一台支持SSL的典型网络主机接受SSL连接的默认端口是443，而不是80。

**SSL协议**：

SSL被设计成使用TCP来提供一种可靠的端到端的安全服务，不是单个协议，而是二层协议，低层是**SSL记录层**，用于封装不同的上层协议，另一层是被封装的协议，即**SSL[握手协议](https://baike.baidu.com/item/握手协议)**，它可以让服务器和客户机在传输应用数据之前，协商[加密算法](https://baike.baidu.com/item/加密算法)和加密密钥，客户机提出自己能够支持的全部加密算法，服务器选择最适合它的算法。

记录协议为不同的更高层协议提供基本的安全服务，其特点是为web客户/服务器的交互提供传输服务的[超文本](https://baike.baidu.com/item/超文本)[传输协议](https://baike.baidu.com/item/传输协议)（HTTP）可在SSL上面运行。三个更高层协议被定义成SSL的一部分：握手协议、修改密文规约协议和告警协议。

SSL中两个重要的概念是SSL会话和SSL连接，规约如下：

（1）连接：连接是提供恰当类型服务的传输，对于SSL这样的连接是点对点的关系。连接是短暂的，每个连接与一个会话相联系。

（2）会话：SSL的会话是客户和服务器之间的关联，会话通过[握手协议](https://baike.baidu.com/item/握手协议)来创建。会话定义了加密安全参数的一个集合，该集合可以被多个连接所共享。会话可用来避免为每个连接进行昂贵的新安全参数的协商。

##### [10]  HTTP中的Get，Post，Put具体指什么？ 

**答：它们都是HTTP中的请求方法**：

1. GET(获得)方法：对这个资源的查操作。
2. PUT(改)和POST（更新）都有更改指定URI的语义。

>【拓展问题】
>
>1. **Put和Post 请求有什么区别？**
>
>>**Put请求：如果两个请求相同，后一个请求会把第一个请求覆盖掉**。（所以PUT用来改资源）
>>**Post请求：后一个请求不会把第一个请求覆盖掉**。（所以Post用来增资源）
>>
>>>POST和PUT请求之间的根本区别反映在Request-URI的不同含义中。POST请求中的URI标识将处理封闭实体的资源。该资源可能是数据接受过程，某个其他协议的入口，也可能是接受注释的单独实体。相比之下，PUT请求中的URI标识了请求中包含的实体 - 用户代理知道哪个URI是预期的，服务器不能尝试将请求应用到其他资源。如果服务器希望请求被应用到不同的URI，它必须发送301（永久移动）响应; 用户代理可以自行决定是否重定向请求。
>>>
>>>**PUT**把一个文件或资源放在一个特定的URI上，并且正好在那个URI上。如果该URI已经有文件或资源，则PUT将替换该文件或资源。如果没有文件或资源，PUT创建一个。**PUT是幂等**的，但矛盾的是PUT响应不可缓存。
>>>
>>>**POST**将数据发送到特定的URI，并期望该URI处的资源处理该请求。此时，Web服务器可以确定如何处理指定资源上下文中的数据。**POST方法不是幂等**的，但只要服务器设置了适当的Cache-Control和Expires头文件，POST响应就是可缓存的。
>
>2. **GET和Post 请求有什么区别？**
>
>>1. Get一般用来从服务器上**查询信息**；Post一般用来**插入信息**；对于服务器讲：get是安全(不更改信息)、幂等(作用1次和n次效果相同); post不安全、不幂等;  ，get是安全(不更改信息)、幂等(作用1次和n次效果相同); post不安全、不幂等;   
>>
>>2. 对于客户端来讲：Get方法将参数直接拼接在了URL后边，**明文显示**，可以通过浏览器地址栏直接访问；Post请求用于提交表单，**数据不是明文的**，安全性更高；
>>3. Get请求**有长度限制**，Post请求**没有长度限制**。
>
>https://www.zhihu.com/question/28586791?sort=created

##### [11] **GET和Post 请求有什么区别？**

本质区别：GET 只是一次 HTTP请求，POST 先发请求头再发请求体，实际上是两次请求。

1. 从功能上讲，GET 一般用来从**服务器上获取资源**，POST 一般用来**更新服务器上的资源**；
2. 从 REST 服务角度上说，GET 是幂等的，即读取同一个资源，总是得到相同的数据，而 POST 不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET 不会改变服务器上的资源，而 POST 会对服务器资源进行改变；
3. 从请求参数形式上看，GET 请求的数据会附在 URL 之后，即将请求数据放置在 HTTP 报文的 请求头 中，以 ? 分割 URL 和传输数据，参数之间以 & 相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用 BASE64 加密，得出如：%E4%BD%A0%E5%A5%BD，其中 ％XX 中的 XX 为该符号以 16 进制表示的 ASCII)；而 POST 请求会把提交的数据则放置在是 HTTP 请求报文的 请求体 中；
4. 就安全性而言，POST 的安全性要比 GET 的安全性高，因为 GET 请求提交的数据将明文出现在 URL 上，而且 POST 请求参数则被包装到请求体中，相对更安全；
5. 从请求的大小看，GET 请求的长度受限于浏览器或服务器对 URL 长度的限制，允许发送的数据量比较小，而 POST 请求则是没有大小限制的。

##### [12]   HTTPS建立连接的过程？

> 已经订正，参考文章：[link](https://www.cnblogs.com/liyuhui-Z/p/7844880.html)
>
> **HTTPS 的握手流程？为什么密钥的传递需要使用非对称加密？双向认证了解么？[link](https://www.jianshu.com/p/d9e4c848ad10)**
>
> https://www.cnblogs.com/Bonker/p/8471446.html

**简介**：HTTPS是在HTTP的基础上和ssl/tls证书结合起来的一种协议,保证了传输过程中的安全性,减少了被恶意劫持的可能.很好的解决了解决了http的三个缺点（被监听、被篡改、被伪装）

**对称加密和非对称加密**

- 对称加密又称公开密钥加密，加密和解密都会用到同一个密钥，如果密钥被攻击者获得，此时加密就失去了意义。
- 非对称加密又称共享密钥加密，使用一对非对称的密钥，一把叫做私有密钥，另一把叫做公有密钥；公钥加密只能用私钥来解密，私钥加密只能用公钥来解密。

但是非对称加密加解密比较复杂，加解密没有对称加密快；HTTP 权衡两种加密方式，采用混合加密机制，在传输对称加密密钥的时候使用非对称加密，然后在通信交换报文阶段则使用对称加密方式。
链接：https://www.jianshu.com/p/d9e4c848ad10

**建立连接(顺便复习下输入网站到显示网页的过程)**

- HTTP和HTTPS都需要在TCP建立连接的基础上来进行数据传输
- 当客户在浏览器中输入网址的并且按下回车,浏览器会在浏览器DNS缓存,本地DNS缓存,和Hosts中寻找对应的记录,如果没有获取到则会请求DNS服务来获取对应的ip
- 当获取到ip后,tcp连接会进行三次握手建立连接

**HTTP请求过程**

- 建立连接完毕以后，客户端会发送响应给服务端
- 服务端接受请求并且做出响应发送给客户端
- 客户端收到响应并且解析响应响应给客户

**HTTPS请求过程**

![img](https://images2017.cnblogs.com/blog/1260476/201711/1260476-20171116160813812-635766483.png)

1. 客户端发起一个https的请求，把自身支持的一系列Cipher Suite（密钥算法套件，简称Cipher）（自己支持的一套加密算法和哈希算法）,SSL，TLS发送给服务端

2. 服务端，接收到客户端所有的Cipher后与自身支持的对比，从中挑选出一套自己支持的加密算法和哈希算法，如果不支持则连接断开

3. 然后把自己的信息以证书的形式返回给客户端 证书内容有：湾站地址、密匙公钥、证书颁发机构、失效日期等

4. 客户端收到服务端响应后会做以下几件事:

* 验证证书的合法性：验证证书的合法性，证书中包含的网站地址是否与正在访问的地址一致、证书是否过期等

证书验证通过后，在浏览器的地址栏会加上一把小锁(如楼主使用的Chrome浏览器)

* 生成随机密码：如果证书验证通过，或者用户接受了不受信任证书，然后浏览器会生成一串随机数，然后用证书中的公钥加密。
* HASH握手信息：用最开始约定好的HASH方式，把握手消息取HASH值， 然后用 随机数加密 “握手消息+握手消息HASH值(签名)” 并一起发送给服务端，为了**保证数据完整性。**

>在这里之所以要取握手消息的HASH值，主要是把握手消息做一个签名，用于验证握手消息在传输过程中没有被篡改过。

5. 服务端拿到客户端传来的密文，用自己的私钥来解密握手消息取出随机数密码，再用随机数密码 解密 握手消息与HASH值，并与传过来的HASH值做对比确认是否一致，如果一致则说明收到非对称加密的密钥是正确的，可以开始传输，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。

> 然后用随机密码加密一段握手消息(握手消息+握手消息的HASH值 )给客户端客户端用随机数解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，

> 这里使用了对称加密和非对称加密相结合的方式，保证了服务端向客户端发送消息的可靠性。
>
> **握手消息+握手消息HASH值(签名)?**
>
> 签名可以验证握手信息的正确性。
>
> **为什么不直接使用非对称加密或对称加密？**
>
> 为什么不使用非对称加密，客户端持有私钥，然后将公钥发送给服务端即可？因为非对称他的速度要慢很多（使用模运算，幂运算）。那为什么不直接使用对称加密？因为使用对称加密的话，那么密钥在传输过程中容易泄露。所以采用用非对称加密来加密对称加密中的密钥，可以保证安全和效率！！！妙啊！！！
>
> **为什么不直接使用对称加密？**
>
> **非对称加密算法**：RSA，DSA/DSS 在客户端与服务端相互验证的过程中用的是对称加密
>
> **对称加密算法**：AES，RC4，3DES 客户端与服务端相互验证通过后，以随机数作为密钥时，就是对称加密
>
> **HASH算法**：MD5，SHA1，SHA256 在确认握手消息没有被篡改时
>
> **为什么说RSA的非对称加密比AES对称加密速度慢？**
> 链接：https://www.zhihu.com/question/350824284/answer/866215364
>
> 首先说，除去人为因素的干预下（比如代码写得太烂，对比平台不公平等），现有的技术水平下，RSA无论是加密还是解密，一般是要比同长度的AES慢的。选择特定参数，比如e=65537，是会使得加密比解密快很多，但与AES仍然不是一个量级。事实上，RSA-OAEP在RSA加密前就需要两个Hash运算：直观上，这两个HASH运算与AES就是一个级别的复杂度，甚至用时会超过AES。
>
> 造成这种现象的本质，在于基础运算的不同。RSA的基本运算是模幂，模的部分有优化算法处理，暂且不谈，我们只看幂运算本身：幂运算的基础单位是乘法，而乘法的基础单位是加法。这个加法，就是我们最熟悉，最常见的整数加。尽管如此，如果学过数字逻辑或者硬件设计的话，应该听说过这个“加法”在电路上比异或（XOR）要麻烦的多。有各种超前进位，并行进位的加法器设计，但没听说有什么异或器设计，是不是？
>
> 我们以5+9和5 xor 9的二进制运算为例：
>
> <img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200721202635691.png" alt="image-20200721202635691" style="zoom:50%;" />
>
> 如果手算一下上面这个过程，你会明显看到，XOR的每个比特运算完全独立，与前后的比特无关；而加法的每个比特均需要考虑低位的进位。这样，计算最高位时，原则上需要等待低位的所有比特计算完毕，而异或并没有这个限制。这个现象称为进位链（carry chain）: 尽管可以用各种技术降低它的影响，但从根本上，它使得加法很难与异或得到相同的效率。
>
> 现有的处理器可以提供单周期的加法或者乘法操作，但这里的前提是: 1) 付出了额外的电路资源 2）固定了位宽，比如32bit或者64bit；3）根据木桶短板的方式拉低了主频，比如单做xor可能可以提高主频，但为了考虑加法，降低了实际提供的主频。也就是说，对于任意长度电路计算，异或仍要比加密高效得多。
>
> RSA目前的推荐长度至少2048，即使用中国剩余定理，也需要1024bit的幂运算，即大量的1024bit的加法。考虑一下1024bit的进位链对于最高位的压力，就很好理解它在速度上的劣势了。 
>
> 相反，如果是1024bit的AES，分组可能就是先拆分成16个128-bit AES。AES的基础运算实际有3种，Sbox，XOR以及移位。在现有的CMOS数字逻辑里，移位代价极低。异或前面说过，代价较低。唯一代价较高的运算是Sbox： 然而，尽管8bit的Sbox可能比8-bit的加法器更慢，但AES也只使用8-bit的Sbox而已。每轮的16个Sbox之间并没有关系，完全可以并行。此外，尽管操作复杂，由于空间很小，只有256种可能，完全可以预计算结果，进行查表处理。这也是Sbox最常见的处理方法：尽管存储器的读取速度依然比CPU低一个量级，相比于1024bit的进位链，依然有很大的优势。反过来，1024bit的加法空间太大，显然是没有办法进行预计算查表处理的。
>
> 但是，从上面这个论述中也能看到，两者实际达到的效果也有不小的差距。安全性论述起来很复杂，但简单来说，RSA可以提供很多复杂的应用，而AES，即使套用了很多复杂的工作模式，也很难达到相同的覆盖面。许多公钥系统的价值更多体现在它能提供的特定安全功能上，而不是能快速完成文本加密。

### 【<常见加密算法及实现>】

[link](https://blog.csdn.net/weixin_33912445/article/details/88018891?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare)
**前言**
**数字签名**、**信息加密** 是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、`oauth` 等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的 **签名加密算法** 来达到业务目标。这里简单的给大家介绍几种常见的签名加密算法和一些典型场景下的应用。
**正文**

##### 1. 数字签名

**数字签名**，简单来说就是通过提供 **可鉴别** 的 **数字信息** 验证 **自身身份** 的一种方式。一套 **数字签名** 通常定义两种 **互补** 的运算，一个用于 **签名**，另一个用于 **验证**。分别由 **发送者** 持有能够 **代表自己身份**的 **私钥** (私钥不可泄露),由 **接受者** 持有与私钥对应的 **公钥** ，能够在 **接受** 到来自发送者信息时用于 **验证** 其身份。

> **注意**：图中 **加密过程** 有别于 **公钥加密**，更多 [介绍戳这里](https://link.juejin.im/?target=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F25912483)。**签名** 最根本的用途是要能够唯一 **证明发送方的身份**，防止 **中间人攻击**、`CSRF` **跨域身份伪造**。基于这一点在诸如 **设备认证**、**用户认证**、**第三方认证** 等认证体系中都会使用到 **签名算法** (彼此的实现方式可能会有差异)。

##### 2. 加密和解密

###### 2.1. 加密

**数据加密** 的基本过程，就是对原来为 **明文** 的文件或数据按 **某种算法** 进行处理，使其成为 **不可读** 的一段代码，通常称为 **“密文”**。通过这样的途径，来达到 **保护数据** 不被 **非法人窃取**、阅读的目的。

###### 2.2. 解密

**加密** 的 **逆过程** 为 **解密**，即将该 **编码信息** 转化为其 **原来数据** 的过程。

##### 3. 对称加密和非对称加密

加密算法分 **对称加密** 和 **非对称加密**，其中对称加密算法的加密与解密 **密钥相同**，非对称加密算法的加密密钥与解密 **密钥不同**，此外，还有一类 **不需要密钥** 的 **散列算法**。

> 常见的 **对称加密** 算法主要有 `DES`、`3DES`、`AES` 等，常见的 **非对称算法** 主要有 `RSA`、`DSA`等，**散列算法** 主要有 `SHA-1`、`MD5` 等。

###### 3.1. 对称加密

**对称加密算法** 是应用较早的加密算法，又称为 **共享密钥加密算法**。在 **对称加密算法** 中，使用的密钥只有一个，**发送** 和 **接收** 双方都使用这个密钥对数据进行 **加密** 和 **解密**。这就要求加密和解密方事先都必须知道加密的密钥。

1. 数据加密过程：在对称加密算法中，**数据发送方** 将 **明文** (原始数据) 和 **加密密钥** 一起经过特殊 **加密处理**，生成复杂的 **加密密文** 进行发送。
2. 数据解密过程**：数据接收方** 收到密文后，若想读取原数据，则需要使用 **加密使用的密钥** 及相同算法的 **逆算法** 对加密的密文进行解密，才能使其恢复成 **可读明文**。

###### 3.2. 非对称加密

**非对称加密算法**，又称为 **公开密钥加密算法**。它需要两个密钥，一个称为 **公开密钥** (`public key`)，即 **公钥**，另一个称为 **私有密钥** (`private key`)，即 **私钥**。
因为 **加密** 和 **解密** 使用的是两个不同的密钥，所以这种算法称为 **非对称加密算法**。

1. 如果使用 **公钥** 对数据 **进行加密**，只有用对应的 **私钥** 才能 **进行解密**。
2. 如果使用 **私钥** 对数据 **进行加密**，只有用对应的 **公钥** 才能 **进行解密**。

> **例子**：甲方生成 **一对密钥** 并将其中的一把作为 **公钥** 向其它人公开，得到该公钥的 **乙方** 使用该密钥对机密信息 **进行加密** 后再发送给甲方，甲方再使用自己保存的另一把 **专用密钥** (**私钥**)，对 **加密** 后的信息 **进行解密**。

##### 4. 常见的签名加密算法

###### 4.1. MD5算法

`MD5` 用的是 **哈希函数**，它的典型应用是对一段信息产生 **信息摘要**，以 **防止被篡改**。严格来说，`MD5`不是一种 **加密算法** 而是 **摘要算法**。无论是多长的输入，`MD5` 都会输出长度为 `128bits` 的一个串 (通常用 `16` **进制** 表示为 `32` 个字符)。

###### 4.2. SHA1算法

`SHA1` 是和 `MD5` 一样流行的 **消息摘要算法**，然而 `SHA1` 比 `MD5` 的 **安全性更强**。对于长度小于 `2 ^ 64` 位的消息，`SHA1` 会产生一个 `160` 位的 **消息摘要**。基于 `MD5`、`SHA1` 的信息摘要特性以及 **不可逆**(一般而言)，可以被应用在检查 **文件完整性** 以及 **数字签名** 等场景。

> **测试结论**：`HMAC` 算法实例在 **多线程环境** 下是 **不安全的**。但是需要在 **多线程访问** 时，进行同步的辅助类，使用 `ThreadLocal` 为 **每个线程缓存** 一个实例可以避免进行锁操作。

###### 4.4. AES/DES/3DES算法

`AES`、`DES`、`3DES` 都是 **对称** 的 **块加密算法**，**加解密** 的过程是 **可逆的**。常用的有 `AES128`、`AES192`、`AES256` (默认安装的 `JDK` 尚不支持 `AES256`，需要安装对应的 `jce` 补丁进行升级 `jce1.7`，`jce1.8`)。
**4.4.1. DES算法**
`DES` 加密算法是一种 **分组密码**，以 `64` 位为 **分组对数据** 加密，它的 **密钥长度** 是 `56` 位，**加密解密** 用 **同一算法**。
`DES` 加密算法是对 **密钥** 进行保密，而 **公开算法**，包括加密和解密算法。这样，只有掌握了和发送方 **相同密钥** 的人才能解读由 `DES`加密算法加密的密文数据。因此，破译 `DES` 加密算法实际上就是 **搜索密钥的编码**。对于 `56` 位长度的 **密钥** 来说，如果用 **穷举法** 来进行搜索的话，其运算次数为 `2 ^ 56`次。
**4.4.2. 3DES算法**
是基于 `DES` 的 **对称算法**，对 **一块数据** 用 **三个不同的密钥** 进行 **三次加密**，**强度更高**。
**4.4.3. AES算法**
`AES` 加密算法是密码学中的 **高级加密标准**，该加密算法采用 **对称分组密码体制**，密钥长度的最少支持为 `128` 位、 `192` 位、`256` 位，分组长度 `128` 位，算法应易于各种硬件和软件实现。这种加密算法是美国联邦政府采用的 **区块加密标准**。

`AES` 本身就是为了取代 `DES` 的，`AES` 具有更好的 **安全性**、**效率** 和 **灵活性**。

###### 4.5. RSA算法

`RSA` 加密算法是目前最有影响力的 **公钥加密算法**，并且被普遍认为是目前 **最优秀的公钥方案** 之一。`RSA` 是第一个能同时用于 **加密** 和 **数字签名** 的算法，它能够 **抵抗** 到目前为止已知的 **所有密码攻击**，已被 `ISO` 推荐为公钥数据加密标准。

> `RSA` **加密算法** 基于一个十分简单的数论事实：将两个大 **素数** 相乘十分容易，但想要对其乘积进行 **因式分解** 却极其困难，因此可以将 **乘积** 公开作为 **加密密钥**。

###### 4.6. ECC算法

`ECC` 也是一种 **非对称加密算法**，主要优势是在某些情况下，它比其他的方法使用 **更小的密钥**，比如 `RSA` **加密算法**，提供 **相当的或更高等级** 的安全级别。不过一个缺点是 **加密和解密操作** 的实现比其他机制 **时间长** (相比 `RSA` 算法，该算法对 `CPU` 消耗严重)。

# 操作系统

#### 1. 讲一下并发和并行？

**并行**是指两个或者多个事件在同一时刻发生：

![img](https://upload-images.jianshu.io/upload_images/7557373-72912ea8e89c4007.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/313/format/webp)

而**并发**是指两个或多个事件在同一时间线内间隔发生：

![img](https://upload-images.jianshu.io/upload_images/7557373-da64ffd6d1effaac.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/295/format/webp)



**单核 cpu 下，线程实际还是串行执行的**。操作系统中有一个组件叫做任务调度器，将 cpu 的时间片（windows下时间片最小约为 15 毫秒）分给不同的程序使用，只是由于 cpu 在线程间（时间片很短）的切换非常快，人类感觉是同时运行的 。总结为一句话就是： 微观串行，宏观并行 。

**并行在多处理器系统中存在**，而并发可以在单处理器和多处理器系统中都存在，**并发能够在单处理器系统中存在是因为并发是并行的假象**，并行要求程序能够同时执行多个操作，而并发只是要求程序假装同时执行多个操作（每个小时间片执行一个操作，多个操作快速切换执行）。

>[link](https://www.jianshu.com/p/cbf9588b2afb)
>
>**同一时间/间隔**：其实应该这么断句，同一时间/ 间隔发生。同一时间是一起的，间隔发生是一起的。同一时间的意思就是同一条时间段上，间隔发生的意思就是，在这同一个时间段上，有不同的事件间隔发生。
>
>**补充解释**：
>
>并行是在不同实体上的多个事件，并发是在同一实体上的多个事件。
>
>并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的。
>
>并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。
>
>并发（concurrent）是同一时间应对（dealing with）多件事情的能力
>
>并行（parallel）是同一时间动手做（doing）多件事情的能力

#### 2. 同步、异步、阻塞、非阻塞

https://blog.csdn.net/historyasamirror/article/details/5778378

**同步 & 异步：同步与异步是针对多个事件(线程/进程)来说的。**

**同步**：如果事件A需要等待事件B的完成才能完成，这种串行执行机制可以说是同步的，这是一种**可靠的**任务序列，要么都成功，要么都失败。
**异步**：如果事件B的执行不需要依赖事件A的完成结果，这种并行的执行机制可以说是异步的。事件B不确定事件A是否真正完成，所以是**不可靠**的任务序列。
**区别**：同步异步可以理解为多个事件的执行方式和执行时机如何，是串行等待还是并行执行。同步中依赖事件等待被依赖事件的完成，然后触发自身开始执行，异步中依赖事件不需要等待被依赖事件，可以和被依赖事件并行执行，被依赖事件执行完成后，可以通过回调、通知等方式告知依赖事件。

**阻塞 & 非阻塞：阻塞与非阻塞是针对单一事件(线程/进程)来说的。**

**阻塞**：如果一个事件在发起一个调用之后，在调用结果返回之前，该事件会被一直挂起，处于等待状态。
**非阻塞**：如果一个事件在发起调用以后，无论该调用当前是否得到结果，都会立刻返回，不会阻塞当前事件。
**区别**：阻塞与非阻塞可以理解为单个事件在发起其他调用以后，自身的状态如何，是苦苦等待还是继续干自己的事情。**非阻塞虽然能提高CPU利用率，但是也带来了系统线程切换的成本，需要在CPU执行时间和系统切换成本之间好好估量一下。**

>##### [1] 同步/异步/阻塞/非阻塞 IO 的区别？
>
>https://www.zhihu.com/question/19732473
>
>**同步（Synchronous）**：当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。
>
>**异步( Asynchronous)**：当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。
>
>**阻塞( Blocking )**：是指调用结果返回前，当前线程会被挂起，即阻塞。
>
>**非阻塞( Nonblocking)**：是指即使调用结果没返回，也不会阻塞当前线程。

#### 3. 	BIO，NIO，AIO，多路复用IO？

> 原文链接：https://blog.csdn.net/historyasamirror/article/details/5778378
>
> **1. 什么是IO？**在计算机系统中I/O就是输入（Input）和输出(Output)的意思，只要具有输入输出类型的交互系统都可以认为是I/O系统。
>
> **2. 如何理解IO过程？**
>
> 对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的进程(process )(or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：
>
> 1. 进程调用系统内核并**等待**数据准备 (Waiting for the data to be ready)
>2. **系统内核准备好数据**，将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)
>    记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。

1. **BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。**当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。

![åæ­¥é»å¡I/Oæ¨¡å.png-31.4kB](http://static.zybuluo.com/rainybowe/brbkxdcpdl2dochf2ukt9ysz/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png)

2. **NIO (New I/O)**: NIO是一种**同步非阻塞**的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 `Socket` 和 `ServerSocket` 相对应的 `SocketChannel` 和 `ServerSocketChannel` 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。

![æªå½åæä»¶ (1).png-53.8kB](http://static.zybuluo.com/rainybowe/0agaz3rfsrlgxr5b5jtt4k1c/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6%20(1).png)



3. **AIO (Asynchronous I/O)**: AIO 也就是 **NIO 2**。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是**异步非阻塞**的IO模型。异步 IO 是基于事件和**回调机制**实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，**IO操作本身是同步**的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。

<img src="http://static.zybuluo.com/rainybowe/rhcelws3p3yjggxisd5xebz0/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6%20(2).png" alt="æªå½åæä»¶ (2).png-33.2kB" />

 

4. **IO多路复用(IO multiplexing)**IO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event driven IO。我们都知道，select/epoll的好处就在于**单个process就可以同时处理多个网络连接的IO。**它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

   **当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回**。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。
   这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用**select的优势在于它可以同时处理多个connection**。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。**select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。**）
   在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如下图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。


<img src="https://s4.51cto.com/images/blog/201810/25/de23ebe25e2596bece3c2b3deab2ba25.jpg?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=" alt="I/Oå¤ç¨æ¨¡åè¯¦è§£(ç½ç»æ»ç»)" style="zoom: 80%;" />

5. **信号驱动IO**

   应用进程使用 sigaction 系统调用，内核立即返回，**应用进程可以继续执行**，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。信号驱动 I/O 的 CPU 利用率很高。

   ![img](https://img-blog.csdnimg.cn/20190601225933487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Vlc3RjcHJpbmNl,size_16,color_FFFFFF,t_70)

**附区别对比1**：

<img src="https://static.oschina.net/uploads/img/201712/30004001_IsSF.png" alt="2" style="zoom:67%;" />

**附区别对比2**：

![img](https:////upload-images.jianshu.io/upload_images/4098122-24b032aed0292270.png?imageMogr2/auto-orient/strip|imageView2/2/w/1104/format/webp)



#### 4. 讲一下线程和进程的区别和联系？

> [link1](http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html)，[link2](https://blog.csdn.net/daaikuaichuan/article/details/82951084)
>
> **进程**
>
> 程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至 CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。进程就可以视为程序的一个实例。大部分程序可以同时运行多个实例进程（例如记事本、画图、浏览器等），也有的程序只能启动一个实例进程（例如网易云音乐、360 安全卫士等）
>
> **线程**
>
> 一个进程之内可以分为一到多个线程。一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给 CPU 执行Java 中，**线程作为最小调度单位，进程作为资源分配的最小单位**。 在 windows 中进程是不活动的，只是作为线程的容器。

1. **操作系统中的一个“执行中的程序”就是进程，它是操作系统资源分配的最小的单位。而线程是进程的一个子集它是CPU调度和执行的最小单位**。
2. 线程相对进程更轻量，特别是上下文切换，进程要比线程消耗更多的计算机资源。
   * **进程切换时**，涉及到当前进程的CPU环境的保存和新被调度运行进程的CPU环境的设置；
   * **线程切换时**，仅需要保存和设置少量的寄存器内容，不涉及存储管理方面的操作。

3. **数据共享方面，同一进程下不同线程间数据很易共享，不同进程的线程间数据很难共享**
   * 线程通信相对简单，因为它们共享进程内的内存
   * 进程间通信较为复杂，同一台计算机的进程通信称为 IPC（Inter-process communication），不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP

**【拓展】什么是协程？**

**协程**（Coroutines）是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个**协程**。

**协程**不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。

**协程**不是进程也不是线程，而是一个**特殊的函数**，这个函数可以在某个地方挂起，并且可以重新在挂起处外继续运行。所以说，**协程**与进程、线程相比并不是一个维度的概念。

一个进程可以包含多个线程，一个线程也可以包含多个**协程**。简单来说，一个线程内可以由多个这样的特殊函数在运行，但是有一点必须明确的是，一个线程的多个**协程**的运行是串行的。如果是多核CPU，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内**协程**却绝对是串行的，无论CPU有多少个核。毕竟**协程**虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但这些函数都是串行运行的。当一个**协程**运行时，其它**协程**必须挂起。

进程、线程、**协程**的对比

- **协程**既不是进程也不是线程，**协程**仅仅是一个特殊的函数，**协程**它进程和进程不是一个维度的。
- 一个进程可以包含多个线程，一个线程可以包含多个**协程**。
- 一个线程内的多个**协程**虽然可以切换，但是多个**协程**是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。
- **协程**与进程一样，切换是存在上下文切换问题的。

**上下文切换**

- 进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括页全局目录、内核栈、硬件上下文，切换内容保存在内存中。进程切换过程是由“用户态到内核态到用户态”的方式，切换效率低。
- 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括内核栈和硬件上下文。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， 切换效率中等。
- **协程**的切换者是用户（编程者或应用程序），切换时机是用户自己的程序所决定的。**协程**的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。**协程**的切换过程只有用户态，即没有陷入内核态，因此切换效率高。

 #### 4. 讲一下线程状态并且解释一下？

操作系统层面下，分为**五种**状态：

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200624161235829.png" alt="image-20200624161235829" style="zoom:67%;" />

1. **新建**(NEW)：新创建了一个线程对象，还未与操作系统线程关联。
2. **可运行**(RUNNABLE)：线程对象创建后，其他线程(比如main线程）**调用了线程对象的start()方法**。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。
3. **运行**(RUNNING)：可运行状态(runnable)的线程**获得了cpu 时间片**[^1]（timeslice） ，执行程序代码。
4. **阻塞**(BLOCKED)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：
   (一). **等待阻塞**：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
   (二). **同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
   (三). **其他阻塞**：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。
5. **死亡**(DEAD)：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

[^1]:  时间片即CPU分配给各个程序的时间，每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。

#### 5. 讲一下进程间通讯方式？

>参考网站:https://blog.csdn.net/weixin_43730678/article/details/89061538

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200812101254723.png" alt="image-20200812101254723" style="zoom:67%;" />

Linux 内核提供了不少进程间通信的机制

1. **无名管道**(PIPE)：管道是一种**半双工**的通信方式（数据只能单向流动），而且只能在具有亲缘关系的进程（即只能在父子进程和兄弟进程之间通讯）间使用。进程的亲缘关系通常是指**父子进程关系**。

2. **命名管道**(FIFO)：有名管道也是半双工的通信方式，但是它**允许无亲缘关系进程间**的通信，通信数据都遵循**先进先出**原则。**所谓的管道，就是内核里面的一串缓存**。

> 由于管道是单双工的，所以管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。

3. **消息队列**MessageQueue：消息队列是消息的链接表，存放在内核中并有消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。但是缺点是，**一是通信不及时，二是附件也有大小限制**。

4. **共享内存**SharedMemory：**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。因为数据不需要在进程之间复制，所以他是最快的IPC。

5. **信号量**（semaphore）信号量是个计数器记录临界资源的个数，用于多进程对共享数据的访问。进程访问临界资源时控制，用来实现进程的同步控制。**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

6. **信号**（signal）信号是比较复杂的通信方式，用于**通知接受进程有某种事件发生**，除了用于进程间通信外，进程还可以发送信号给进程本身.**对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

7. **套接字(Socke)**：**用于跨网络与不同主机上的进程之间通信。socket 的系统调用为：**

   ~~~linux
   int socket(int domain, int type, int protocal)，
   ~~~

   三个参数分别代表：

   - domain 参数用来指定**协议族**，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；
   - type 参数用来指定**通信特性**，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM  表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；
   - protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；

   根据创建 socket 类型的不同，通信的方式也就不同：

   - 实现 **TCP** 字节流通信：socket 类型是 AF_INET 和 SOCK_STREAM；
   - 实现 **UDP** 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；
   - 实现**本地进程**间通信：「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；

>> **重要：详细解释**：https://mp.weixin.qq.com/s/mblyh6XrLj1bCwL0Evs-Vg
>
>**1. 管道背后原理是什么？**
>
>匿名管道的创建，需要通过下面这个系统调用：
>
>~~~linux
>int pipe(int fd[2])
>~~~
>
>这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符`fd[0]`，另一个是管道的写入端描述符 `fd[1]`。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。
>
><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQmsrxa4AwDelPGglhe3DMPTKEpmGW7icSDnozDo7plETZlTWQJmcDVug/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom:50%;" />
>
>其实，**所谓的管道，就是内核里面的一串缓存**。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。
>
>看到这，你可能会有疑问了，这两个描述符都是在一个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程的呢？
>
>我们可以使用 `fork` 创建子进程，**创建的子进程会复制父进程的文件描述符**，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。
>
><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQVOgyU702gpwGJppjZCBXI4XDFNwBYR2wxG2MgKvfJvfjzfmKicjg01A/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom:50%;" />
>
>管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：
>
>- 父进程关闭读取的 fd[0]，只保留写入的 fd[1]；
>- 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；
>
><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZckxn1SzJ697nE1m1wJzmPQgD8dzOZUnAfmVVndTmtGgZRNZsBFEYghLPBjicziam2E1iapicANMYRXbg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom:50%;" />
>
>所以说如果需要双向通信，则应该创建两个管道。
>
>到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。
>
>在 shell 里面执行 `A | B`命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。
>
><img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200812102917357.png" alt="image-20200812102917357" style="zoom:50%;" />
>
>所以说，在 shell 里通过「`|`」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。
>
>我们可以得知，**对于匿名管道，它的通信范围是存在父子关系的进程**。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。
>
>另外，**对于命名管道，它可以在不相关的进程间也能相互通信**。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。
>
>不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。
>
>**2. 信号量底层是怎么实现的？**
>
>信号量表示资源的数量，控制信号量的方式有两种原子操作：
>
>- 一个是 **P 操作**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
>- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；
>
>**3. 信号和信号量有什么区别？**
>
>**信号**：是由用户、系统或者进程发送给目标进程的信息，**以通知目标进程某个状态的改变或系统异常**。
>**信号量**：信号量是一个特殊的变量，它的本质是**计数器**，信号量里面记录了临界资源的数目，有多少数目，信号量的值就为多少，进程对其访问都是原子操作（pv操作，p：占用资源，v：释放资源）。它的作用就是，调协进程对共享资源的访问，让一个临界区同一时间只有一个进程在访问它。
>
>所以它们两的区别也就显而易见了，信号是通知进程产生了某个事件，信号量是用来同步进程的（用来调协进程对共享资源的访问的）

#### 6. 进程的调度算法有哪些（进程切换策略）？

* **先来先服务调度算法**：先来先服务调度算法是一种最简单的调度算法，也称为**先进先出**或严格排队方案。当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。该算法既可以用于作业调度，也可以用于进程调度。先来先去服务比较适合于常作业（进程），而不利于段作业（进程）。

* **时间片轮转调度算法**：时间片轮转调度算法主要适用于**分时系统**。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中第一个进程执行，**即先来先服务的原则，但仅能运行一个时间片**。

* **短作业优先调度算法**：短作业优先调度算法是指**对短作业优先调度**的算法，从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。 短作业优先调度算法是一个非抢占策略，他的原则是下一次选择预计处理时间最短的进程，因此短进程将会越过长作业，跳至队列头。

* **最短剩余时间优先调度算法**：最短剩余时间是针对最短进程优先**增加了抢占机制**的版本。在这种情况下，进程调度总是选择预期剩余时间最短的进程。当一个进程加入到就绪队列时，他可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就能可能抢占当前正在运行的进程。像最短进程优先一样，调度程序正在执行选择函数是必须有关于处理时间的估计，并且存在长进程饥饿的危险。

* **高响应比优先调度算法**：高响应比优先调度算法主要用于作业调度，该算法是对先来先服务调度算法和短作业优先调度算法的一种综合平衡，**同时考虑每个作业的等待时间和估计的运行时间**。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。

  > 响应比 =（等待时间+要求服务时间）/ 要求服务时间，即RR=（w+s）/s=1+w/s，因此响应比一定是大于等于1的。

* **优先级调度算法**：优先级调度算法每次从后备作业队列中**选择优先级最高**的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。

> **先时短最高优**

#### 7. 线程同步的四种方式

> 原文链接：https://blog.csdn.net/qq_40261882/article/details/100538711

1、**临界区**： 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。

总结下关键段：
1）关键段共初始化化、销毁、进入和离开关键区域四个函数。
2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。
3）推荐关键段与旋转锁配合使用。

2、**互斥对象**： 互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。

总结下互斥量Mutex：
1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。
2）互斥量能够用于多个进程之间线程互斥问题，并且能完美的解决某进程意外终止所造成的“遗弃”问题。

3、**信号量**： 信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目

在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最 大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小 到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离 开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。在任何时候当前可用资源计数决不可能大于最大资源计数。

4、**事件对象**： 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作

总结下事件Event
1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。
2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。
3）事件可以解决线程间同步问题，因此也能解决互斥问题。

#### 8.  **物理地址、逻辑地址、虚拟内存的概念**

1. **物理地址**：它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取，是内存单元真正的地址。

2. **逻辑地址**：是指计算机用户看到的地址。例如：当创建一个长度为 100 的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为 4 个字节，故第二个元素的地址时起始地址加 4，以此类推。事实上，逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址（在内存条中所处的位置），并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维。

3. **虚拟内存**：是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

#### 9. 分页与分段的区别？

1. 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的；

2. 段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定；

3. 段向用户提供二维地址空间；页向用户提供的是一维地址空间；

4. 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。

#### 10. 页面置换算法？

>https://www.cnblogs.com/fkissx/p/4712959.html

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

**1．最佳置换算法（OPT）**（理想置换算法）：从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。于所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。 

**2．先进先出置换算法（FIFO）**：是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。 

**3．最近最久未使用（LRU）算法**：这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。所以，这种算法的实质是：当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。 

**4. 时钟(CLOCK)置换算法**：LRU算法的性能接近于OPT,但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，**试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体**。
简单的CLOCK算法是给每一帧关联一个附加位，称为**使用位**。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为**最近未用**(Not Recently Used, NRU)算法。

CLOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个**修改位**，则得到改进型的CLOCK置换算法。

LOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的CLOCK置换算法。这样，每一帧都处于以下四种情况之一：

1. 最近未被访问，也未被修改(u=0, m=0)。

2. 最近被访问，但未被修改(u=1, m=0)。

3. 最近未被访问，但被修改(u=0, m=1)。

4. 最近被访问，被修改(u=1, m=1)。
   

   
   **算法执行如下操作步骤：**

1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。
2. 如果第1)步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。
3. 如果第2)步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为0。重复第1步，并且如果有必要，重复第2步。这样将可以找到供替换的帧。

>**另外还有：**
>
>- [1. 最优页面置换算法](https://blog.csdn.net/qq_41209741/article/details/99586257#1__3)
>- [2. 最近未使用页面置换算法（NRU）(Not Recently Used)](https://blog.csdn.net/qq_41209741/article/details/99586257#2_NRUNot_Recently_Used_6)
>- [3. 先进先出页面置换算法（FIFO）](https://blog.csdn.net/qq_41209741/article/details/99586257#3_FIFO_16)
>- [4. 第二次机会页面置换算法（SC）（Second Chance）](https://blog.csdn.net/qq_41209741/article/details/99586257#4_SCSecond_Chance_18)
>- [5. 时钟页面置换算法（CLOCK）](https://blog.csdn.net/qq_41209741/article/details/99586257#5_CLOCK_21)
>- [6. 最近最少使用页面置换算法（LRU）（Least Recently Used）](https://blog.csdn.net/qq_41209741/article/details/99586257#6_LRULeast_Recently_Used_24)
>- [7. 最不常用页面置换算法（NFU）（Not Frequently Used）](https://blog.csdn.net/qq_41209741/article/details/99586257#7_NFUNot_Frequently_Used_29)
>- [8. 老化算法](https://blog.csdn.net/qq_41209741/article/details/99586257#8__32)
>- [9. 工作集页面置换算法](https://blog.csdn.net/qq_41209741/article/details/99586257#9__35)
>- [10. 工作集时钟页面置换算法](https://blog.csdn.net/qq_41209741/article/details/99586257#10__52)

#### [<死锁专题>]

##### 1. 什么是死锁？

死锁，是指多个进程**在运行过程中因争夺资源而造成的一种僵局**，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 如下图所示：如果此时有一个线程 A，已经持有了锁 A，但是试图获取锁 B，线程 B 持有锁 B，而试图获取锁 A，这种情况下就会产生死锁。

##### 2. 死锁产生的必要条件？

1. **互斥条件**：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
2. **请求和保持条件**：当进程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不剥夺条件**：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
4. **环路等待条件**：在发生死锁时，必然存在一个进程--资源的环形链。

##### 3.  解决死锁的基本方法？

1. ##### 预防死锁----- 设计一种系统，确保系统永远不会进入死锁状态

   **破坏请求条件**：一次性分配所有资源，这样就不会再有请求了；

   **破坏保持条件**：只要有一个资源得不到分配，也不给这个进程分配其他的资源：

   **破坏不可剥夺条件**：当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源；

   **破坏环路等待条件**：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反。

   

2. ##### 避免死锁----- 在使用前进行判断，只允许不会产生死锁的进程申请资源

   **银行家算法**：当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。
   当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源。若没超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若满足则按当前的申请量分配资源，否则也要推迟分配。

   * **安全序列**：是指系统能按某种进程推进顺序（P1, P2, P3, ..., Pn），为每个进程 Pi 分配其所需要的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序地完成。这种推进顺序就叫安全序列【银行家算法的核心就是找到一个安全序列】。
   * **系统安全状态** ：如果系统能找到一个安全序列，就称系统处于安全状态，否则，就称系统处于不安全状态。

3. ##### 检测死锁

4. ##### 解除死锁

   **资源剥夺**：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源）；

   **撤销进程**：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行）；

   **进程回退**：让一个或多个进程回退到足以避免死锁的地步。进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

##### 4. 描述一种可能发生死锁的情况

~~~java
lock(m1) lock(m2) unlock(m1) lock(m1) unlock(m2) unlock(m1)
~~~

链接：https://www.nowcoder.com/questionTerminal/c572bb54bf4a44dea62d28fa0ae7e8f0

链接：https://www.nowcoder.com/questionTerminal/c572bb54bf4a44dea62d28fa0ae7e8f0
lock(m1) lock(m2) unlock(m1) lock(m1) unlock(m2) unlock(m1) 假设A线程执行完第一步即将执行第二步： A线程：lock(m1) -> lock(m2)  B线程执行完第三步，即将执行第四步   B线程：lock(m1) lock(m2) unlock(m1) ->lock(m1) 即 lock(m2) -> lock(m1) 线程A锁住了m1对象，然后尝试对m2对象进行加锁，同时线程B已经锁住了m2对象，接着尝试对m1对象进行加锁。 

~~~java
public class DeadLockSample extends Thread {
  private String first;
  private String second;
  public DeadLockSample(String name, String first, String second) {
    super(name);
    this.first = first;
    this.second = second;
  }

  public void run() {
    synchronized (first) {
      System.out.println(this.getName() + " obtained: " + first);
      try {
        Thread.sleep(1000L);
        synchronized (second) {
          System.out.println(this.getName() + " obtained: " + second);
        }
      } catch (InterruptedException e) {
        // Do Nothing
      }
    }
  }

  public static void main(String[] args) throws InterruptedException {
    String lockA = "lockA";
    String lockB = "lockB";
    DeadLockSample t1 = new DeadLockSample("Thread1", lockA, lockB);
    DeadLockSample t2 = new DeadLockSample("Thread2", lockB, lockA);
    t1.start();
    t2.start();
    t1.join();
    t2.join();
  }
}
~~~



# 设计模式

#### 1. 你知道那些常用的设计模式？

**1. 单例模式**：单例模式保证系统内存中该类只有一个对象。

> **优势**：可以防止频繁的创建和销毁对象造成的资源浪费，以此来提高系统性能。
>
> **实现方式**：懒汉模式创建和饿汉模式创建。
>
> **应用场景**：我们JDK中，java.lang.Runtime就是百科全书的单例模式（饿汉式）,spring里面就是用了单例模式

**2.工厂模式**：将实例化对象的代码提取出来，放到一个类里面统一管理，由子类决定是否实例化。

>[link](https://gitee.com/moxi159753/LearningNotes/tree/master/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F)

> **优势**：工厂方法模式具有很好的封装性。客户端不需要知道创建对象的过程，只需要知道要创建的是哪个具体的产品即可。
>
> **实现方式**：简单工厂模式，工厂方法模式，抽象工厂模式。
>
> **简单工厂模式**：将被使用方的创建过程封装到一个类中,这样就在使用方和被使用方之间做了一个缓冲,也就是使用方和被使用方做了一个解耦,提高了软件的可扩展性和可维护性和可复用性.
>
> **工厂方法模式**：将简单工厂的创建对象的方法写成一个抽象方法,也就是在工厂类或者接口中不知道如何创建该对象,创建具体对象交给工厂类的子类或者实现类去做.
>
> **抽象工厂模式**：抽象工厂模式为创建一组相关或相互依赖的对象提供一个接口，而且无须指定它们的具体类。抽象工厂模式是工厂方法模式的升级版本，在有多个业务品种、业务分类时，通过抽象工厂模式产生需要的对象是一种非常好的解决方式。,抽象工厂方法不再是单独的接口,而是生产一类产品的接口,可以生产多个相关联产品。
>
> **抽象工厂模式和工厂方法模式的区别**：
>
> 如果产品单一，适合使用工厂模式。但是如果有多个业务品种、业务分类时，需要使用抽象工厂模式。也就是说，工厂模式针对的是一个产品等级结构 ，抽象工厂模式针对的是面向多个产品等级结构的。

**3. 代理模式**：将原类进行封装，客户端不能直接找到原类，必须通过代理角色。即代理是原类的一个替身，客户端要找原类，必须找代理才可以搞定。明星和经纪人的关系就是一种代理模式。

>**优势**：为一个对象提供一个替身,以控制对这个对象的访问.即通过代理对象访问目标对象.这样做的好处 是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能.
>
>**实现方式**：静态代理和动态代理。
>
>**应用场景**：动态代理在实现阶段不用关心代理谁，而在运行阶段才指定代理哪一个对象。相对来说，自己写代理类的方式就是静态代理。

**4. 装饰器模式**

>**优势**：动态的将新功能附加到对象上.在对象功能扩展方面,它比继承更有弹性,装饰者模式也体现了 开闭原则(ocp)
>
>**实现方式**：静态代理和动态代理。
>
>**应用场景**：String 常量池,数据库连接池

**5. 享元模式**：系统中有大量对象，这些对象消耗大量内存，并且对象的状态大部分可以外部化时，我们就可以考虑选用享元模式。在享元模式这样理解,“享”就表示共享,“元”表示对象 

>**优势**：享元模式大大减少了对象的创建,降低了程序内存的占用,提高效率。
>
>**实现方式**：静态代理和动态代理。
>
>**应用场景**：String 常量池,数据库连接池

**6. 模板模式**：定义一个操作中的算法的骨架,而将一些步骤延迟到子类中,使得子类可以不改变一 个算法的结构,就可以重定义该算法的某些特定步骤。

>**优势**：实现了最大化代码复用。
>
>**实现方式**：它的子类可以按需要重写方法实现,但调用将以抽象类中定义的方式进行. 
>
>**应用场景**：当要完成在某个过程,该过程要执行一系列步骤 ,这一系列的步骤基本相同,但其 个别步骤在实现时 可能不同,通常考虑用模板方法模式来处理

**7. 策略模式**：定义算法族(策略组),分别封装起来,让他们之间可以互相替换,此模式 让算法的变化独立于使用算法的客户

>**优势**：体现了“对修改关闭,对扩展开放”原则,客户端增加行为不用修改原有代码,只要添加一种策略(或者行为) 即可,避免了使用多重转移语句
>
>**实现方式**：策略模式将算法封装在独立的 Strategy 类中使得你可以独立于其 Context 改 变它,使它易于切换,易于理解,易于扩展
>
>**应用场景**： JDK的数组的比较器就使用了策略模式

**8. 原型模式**：用原型实例指定创建对象的种类,并且通过拷贝这些原型,创建新的对象 

>**优势**：允许一个对象再创建另外一个可定制的对象,无需知道如何创建的细节
>
>**实现方式**：通过将一个原型对象传给那个要发动创建的对象,这个要发动创建的对象通过请求原型对象拷贝它 们自己来实施创建,即 对象.clone()
>
>**应用场景**：Spring 中原型 bean 的创建,就是原型模式的应用

#### 2. 设计模式的六大原则?

> https://www.jianshu.com/p/807bc228dbc2
>
> https://www.cnblogs.com/pony1223/p/7594803.html
>
> 设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。只有精通了设计模式，才敢说真正理解了软件工程。可以说，设计模式是每一个架构师所必备的技能之一。想要精通设计模式，必须要先搞清楚设计模式的六大原则。
>
> 学习设计模式可以降低对象之间的耦合，增加程序的可复用性、可扩展性、可维护性。优秀的设计模式就是基于这些原则去实现的。

**1、单一职责原则（Single Responsibility Principle，简称SRP ）**

- **核心思想**：应该有且仅有一个原因引起类的变更
- **问题描述**：假如有类Class1完成职责T1，T2，当职责T1或T2有变更需要修改时，有可能影响到该类的另外一个职责正常工作。
- **好处**：类的复杂度降低、可读性提高、可维护性提高、扩展性提高、降低了变更引起的风险。
- **需注意**：单一职责原则提出了一个编写程序的标准，用“职责”或“变化原因”来衡量接口或类设计得是否优良，但是“职责”和“变化原因”都是不可以度量的，因项目和环境而异。

------

**2、里氏替换原则（Liskov Substitution Principle,简称LSP）**

- **核心思想**：在使用基类的的地方可以任意使用其子类，能保证子类完美替换基类。
- **通俗来讲**：只要父类能出现的地方子类就能出现。反之，父类则未必能胜任。
- **好处**：增强程序的健壮性，即使增加了子类，原有的子类还可以继续运行。
- **需注意**：如果子类不能完整地实现父类的方法，或者父类的某些方法在子类中已经发生“畸变”，则建议断开父子继承关系 采用依赖、聚合、组合等关系代替继承。

------

**3、依赖倒置原则（Dependence Inversion Principle,简称DIP）**

- **核心思想**：高层模块不应该依赖底层模块，二者都该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象；
- **说明**：高层模块就是调用端，低层模块就是具体实现类。抽象就是指接口或抽象类。细节就是实现类。
- **通俗来讲**：依赖倒置原则的本质就是通过抽象（接口或抽象类）使个各类或模块的实现彼此独立，互不影响，实现模块间的松耦合。
- **问题描述**：类A直接依赖类B，假如要将类A改为依赖类C，则必须通过修改类A的代码来达成。这种场景下，类A一般是高层模块，负责复杂的业务逻辑；类B和类C是低层模块，负责基本的原子操作；假如修改类A，会给程序带来不必要的风险。
- **解决方案**：将类A修改为依赖接口interface，类B和类C各自实现接口interface，类A通过接口interface间接与类B或者类C发生联系，则会大大降低修改类A的几率。
- **好处**：依赖倒置的好处在小型项目中很难体现出来。但在大中型项目中可以减少需求变化引起的工作量。使并行开发更友好。

------

**4、接口隔离原则（Interface Segregation Principle,简称ISP）**

- **核心思想**：类间的依赖关系应该建立在最小的接口上
- **通俗来讲**：我觉得这里的**隔离**翻译为**分离**是更确切的。建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。
- **问题描述**：类A通过接口interface依赖类B，类C通过接口interface依赖类D，如果接口interface对于类A和类B来说不是最小接口，则类B和类D必须去实现他们不需要的方法。
- **需注意**：
- **接口尽量小，但是要有限度**。对接口进行细化可以提高程序设计灵活性，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度
- **提高内聚，减少对外交互**。使接口用最少的方法去完成最多的事情
- **为依赖接口的类定制服务**。只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。

------

**5、迪米特法则（Law of Demeter,简称LoD）**

- **核心思想**：类间解耦。
- **通俗来讲**： 一个类对自己依赖的类知道的越少越好。自从我们接触编程开始，就知道了软件编程的总的原则：低耦合，高内聚。无论是面向过程编程还是面向对象编程，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。低耦合的优点不言而喻，但是怎么样编程才能做到低耦合呢？那正是迪米特法则要去完成的。

------

**6、开放封闭原则（Open Close Principle,简称OCP）**

- **核心思想**：尽量通过扩展软件实体来解决需求变化，而不是通过修改已有的代码来完成变化
- **通俗来讲**： 一个软件产品在生命周期内，都会发生变化，既然变化是一个既定的事实，我们就应该在设计的时候尽量适应这些变化，以提高项目的稳定性和灵活性。

#### 3. 如何理解设计模式的六大原则？

我们知道，java中有类，父类，抽象类，接口这些概念，而设计模式的六大原则就解释了它们及其它们之间的关系是怎样的，接下来我们将由简到难一一剖析。

* **开闭原则**：是**总纲**，他告诉我们要对扩展开放，对修改关闭。即通过开闭原则，我们可以通过扩展行为来实现新的功能，而不是通过修改已有的代码。开闭原则可以帮助我们构建一个稳定，灵活的软件系统。

*  **单一职责原则**：面向对象最基本的概念就是类，此告诉我们实现**类**要职责单一。即每个类应该只负责一项规范，这是为在部分职责发生变化时，牵连到其他职责，是为了解耦合。

* **迪米特法则**：告诉我们**类与类**之间要要降低耦合，也叫最少知识原则，是指一个对象应该对其依赖的对象有最少的了解。一个类对于其他类知道的越少越好，就是说一个对象应当对其他对象有尽可能少的了解,只和朋友通信，不和陌生人说话。
* **里氏替换原则**：说完了类，就不得不提到子类和父类，如何保证子类和父类？而**里氏替换原则**规范。即子类可以替换父类，告诉我们只要**父类**能出现的地方**子类**就能出现。它体现了java三大特点中的**继承**，子类的权限不能低于父类。

* **接口隔离原则**：告诉我们在设计**接口**的时候要精简单一，通俗的说要建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。

* **依赖倒置原则**：对**接口和抽象类**的功能做了规范，通常情况的设计都是高层模块依赖于低层模块（比如说在盖楼过程中，需要打好地基，才可以修建好上层建筑）。这样看似顺理成章，低层模块不怎么变动，高层模块调用低层模块。但是事实上，事物总是在变化，经常低层模块变化，引起高层一系列的变化。即底层依赖于高层。细节应该依赖于抽象，因为抽象的东西要稳定的多。接口中制定好规范就好，不需要事先具体操作，即**面向接口编程**。

#### 4. 设计模式的分类

设计模式一般分为三类：创建型模式、结构型模式、行为型模式。

**创建型模式**

创建型模式简单来说就是用来创建对象的。一共有五种：单例模式、建造者模式、工厂方法模式、抽象工厂模式、原型模式。
 [单例模式](https://www.jianshu.com/p/d59c64480ed8) ：确保某一个类只有一个实例，并且提供一个全局访问点。
 [建造者模式](https://www.jianshu.com/p/154948d5adc6) ： 用来创建复杂的复合对象。
 [工厂方法模式](https://www.jianshu.com/p/e6c02a54f447) ：让子类来决定要创建哪个对象。
 [抽象工厂模式](https://www.jianshu.com/p/3e912410f21b) ：创建多个产品族中的产品对象。
 [原型模式](https://www.jianshu.com/p/6d1333917ae5) ：通过复制原型来创建新对象。

 **行为型模式**

行为型模式主要是描述类或者对象是怎样交互和怎样分配职责的。一共有十一种：策略模式、模板方法模式、观察者模式、迭代器模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。
 [策略模式](https://www.jianshu.com/p/ddcb8eb175f5) ：封装不同的算法，算法之间能互相替换。
 [状态模式](https://www.jianshu.com/p/a707662abd0a) ：根据不同的状态做出不同的行为。
 [责任链模式](https://www.jianshu.com/p/7fa31c57cbb5) ：将事件沿着链去处理。
 [观察者模式](https://www.jianshu.com/p/8f32da74cd8b) ：状态发生改变时通知观察者，一对多的关系。
 [模板方法模式](https://www.jianshu.com/p/9a480322aee1) ：定义一套流程模板，根据需要实现模板中的操作。
 [迭代器模式](https://www.jianshu.com/p/f4917cb02752) ：提供一种方法顺序访问一个聚合对象中的各个元素。
 [备忘录模式](https://www.jianshu.com/p/c8a63849d629) ：保存对象的状态，在需要时进行恢复。
 [访问者模式](https://www.jianshu.com/p/279563870478) ：稳定数据结构中，定义新的操作行为。
 [中介者模式](https://www.jianshu.com/p/9b50004446dd) ：将网状结构转变为星型结构，所有行为都通过中介。
 [解释器模式](https://www.jianshu.com/p/234a156b0210) ：定义语法，并对其进行解释。
 [命令模式](https://www.jianshu.com/p/ff909f9d925f) ：将请求封装成命令，并记录下来，能够撤销与重做。

**结构型模式**

结构型模式主要是用于处理类或者对象的组合。一共有七种：适配器模式、装饰模式、代理模式、外观模式、桥接模式、组合模式、享元模式。
 [代理模式](https://www.jianshu.com/p/a0e687e0904f) ：控制客户端对对象的访问。
 [组合模式](https://www.jianshu.com/p/0580301d141d) ：将整体与局部（树形结构）进行递归组合，让客户端能够以一种的方式对其进行处理。
 [适配器模式](https://www.jianshu.com/p/31686bf8f9a2) ：将原来不兼容的两个类融合在一起。
 [装饰者模式](https://www.jianshu.com/p/df1a96c5c046) ：为对象添加新功能。
 [享元模式](https://www.jianshu.com/p/1dc997737dd3) ：使用对象池来减少重复对象的创建。
 [外观模式](https://www.jianshu.com/p/e1e1eb7d22cf) ：对外提供一个统一的接口用来访问子系统。
 [桥接模式](https://www.jianshu.com/p/acf598db6d4d) ：将两个能够独立变化的部分分离开来。。

#### 5. 请手写一下单例模式？

> 创建单例类的步骤：
> 1、私有化该类的构造函数。
> 2、通过new在本类中创建一个本类对象。
> 3、提供一个公有的静态方法，将创建的对象返回。
> 单例类因为不允许其他程序用new来创建该类对象，所以只能将单例类中的方法定义成静态的（随类的加载而加载），静态方法不能访问非静态的成员，故只能> > 将该类中new的本类对象变成静态的。 

https://www.cnblogs.com/william-dai/p/10938666.html

>**单例模式懒汉式和饿汉式区别？**
>
>1. 饿汉式天生就是线程安全的，可以直接用于多线程而不会出现问题，懒汉式本身是非线程安全的，为了实现线程安全可以加synchronized锁。
>2. 资源加载和性能：饿汉式在类创建的同时就实例化一个静态对象出来，不管之后会不会使用这个单例，都会占据一定的内存，但是相应的，在**第一次调用时速度也会更快**，因为其资源已经初始化完成。而懒汉式顾名思义，会延迟加载，在第一次使用该单例的时候才会实例化对象出来，第一次调用时要做初始化，如果要做的工作比较多，**性能上会有些延迟**，之后就和饿汉式一样了。
>
>原文链接：https://blog.csdn.net/qq_35098526/article/details/79893628

**1. 懒汉式：用到时再去创建**

~~~java
//非线程安全的单例模式
public class Singleton {
    //懒汉式单例，只有在调用getInstance时才会实例化一个单例对象
    public static Singleton singleton; 
    private Singleton(){}
    public static Singleton getInstance(){
    if(user==null){       //step 1.
    singleton = new Singleton();  //step 2
    }
    return singleton;
    }
}
~~~

看上去，这段代码没什么明显问题，但它不是线程安全的。假设当前有N个线程同时调用getInstance（）方法，由于当前还没有对象生成，所以一部分同时都进入step 2,

那么就会由多个线程创建多个多个user对象。

解决办法：使用**synchronized关键字**。经改造上面代码展示如下：

~~~java
//实现双重校验锁的单例模式【推荐】
class  Singleton{
    //volatile保证禁止指令重排序，防止另外一个线程返回没有初始化的对象.
    private volatile  static Singleton instance;
    //设置类的构造为私有，防止被其他类创建
    private  Singleton(){}
    public static  Singleton instance (){
        //第一层屏障，为了防止多次加锁，而造成的性能损耗
        if(instance==null){
            //step2
            //加锁防止多线程
            synchronized(Singleton.class){
                //第二层屏障，为了防止已经突破了第一层屏障位于step2位置的线程,重现创建对象
                if(instance==null){
                    instance=new Singleton();
            }
        }
        return instance;
    }
~~~

**第一次校验**：也就是第一个if（uniqueInstance==null），这个是为了代码**提高代码执行效率**，由于单例模式只要一次创建实例即可，所以当创建了一个实例之后，再次调用getUniqueInstance方法就不必要进入同步代码块，不用竞争锁。直接返回前面创建的实例即可。说白了假设第一次不检验，看似问题也不大，但是其实这里所用到的思想就如我们在学习hashmap时为什么需要先比较hashcode再比较equals方法，就一句话谁快选谁，这里看似多判断了一次，然而synchronzied同步锁会大大削减效率，开销很大，所以我们就任性地先比较一次，这样如果运气好的话可以通过if语句，跳过synchronized这个步骤。

**第二次校验**：也就是第二个if（uniqueInstance==null），这个校验是**防止二次创建实例**，假如有一种情况，当uniqueInstance还未被创建时，线程t1调用getUniqueInstance方法，由于第一次判断if（uniqueInstance==null），此时线程t1准备继续执行，但是由于资源被线程t2抢占了，此时t2页调用getUniqueInstance方法，同样的，由于singleton并没有实例化，t2同样可以通过第一个if，然后继续往下执行，同步代码块，第二个if也通过，然后t2线程创建了一个实例singleton。此时t2线程完成任务，资源又回到t1线程，t1此时也进入同步代码块，如果没有这个第二个if，那么，t1就也会创建一个singleton实例，那么，就会出现创建多个实例的情况，但是加上第二个if，就可以完全避免这个多线程导致多次创建实例的问题。
原文链接：https://blog.csdn.net/weixin_43914278/article/details/104451055

但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。

**volatile：双重检查基础版中由重排序引发的问题**

- 做第一次检查的时候，如果lazyDoubleCheckSingleton != null，并不代表lazyDoubleCheckSingleton一定已经初始化完成了，造成这种情形的原因是指令重排序；
- lazyDoubleCheckSingleton = new LazyDoubleCheckSingleton(); 这句在底层经历了3个动作：
   1.分配内存给这个对象；
   2.初始化对象；
   3.设置 lazyDoubleCheckSingleton 指向刚分配的内存；
   **这3个动作中，2和3的动作可能颠倒，其造成的结果就是：Thread-0第一次检查的时候，由于Thread-1先执行3，lazyDoubleCheckSingleton 指向刚分配的内存，导致Thread-0看到的 lazyDoubleCheckSingleton 不为空，直接返回 lazyDoubleCheckSingleton，但此时lazyDoubleCheckSingleton 在Thread-1中还没有初始化，所以造成程序出问题；**
- Java规范中有个 intra-thread semantics 的规定，它保证重排序不会改变单线程的执行结果，重排序可以提高程序的执行性能；

**重排序问题的解决方案**

- 不允许重排序；
- 允许重排序，但不允许另一个线程看到这个重排序；
  链接：https://www.jianshu.com/p/b4157c2e8fe5

**不允许重排序的解决方案**

- 用 volatile 修饰 lazyDoubleCheckSingleton，就禁止了重排序；
- 在多线程的时候，多CPU会共享内存，加了 volatile 后，所有的线程都能看到共享内存的最新状态，保证了内存的可见性；
- 用 volatile 修饰的共享变量在进行写操作的时候，会将当前CPU缓存行的数据写进内存，使得其他CPU缓存了该内存地址的数据无效，从而迫使其他CPU重新从共享内存中获取数据，这样就保证了内存的可见性；

>                    //类的加载过程：
>                                      //1.加载二进制数据到内存中，生成对应的Class数据结构
>                                      //2.连接阶段：验证，准备(给类的静态变量赋默认)，解析
>                                      //3.初始化(给类的静态变量赋初值)
>                                      //字节码层面（JIT,CPU对指令都会重新排序）
>                                      // 正常       重序后
>                                      //1.分配空间        1.分配空间
>                                      //2.初始化(真值)    2. 引用赋值
>                                      //3.引用赋值        3.初始化(真值)
>                                      //由于s是静态变量，第二步和第三步可能引发问题
>                                  }

> 他最明显的原因是，初始化Helper对象的写操作和对Helper字段的写入不能正常工作。因此，调用getHelper()的线程可以看到对Helper对象的非空引用，但是可以看到Helper对象字段的默认值，而不是构造函数中设置的值。如果编译器内联了对构造函数的调用，那么如果编译器能够证明构造函数不能抛出异常或执行同步，那么初始化对象的写操作和写到助手字段的写入可以自由地重新排序。即使编译器没有重新排序这些写入，在多处理器上，处理器或内存系统也可以重新排序这些写入，就像运行在另一个处理器上的线程所看到的那样。

>在给helper对象初始化的过程中，jvm做了下面3件事：
>
>1.给helper对象分配内存
>
>2.调用构造函数
>
>3.将helper对象指向分配的内存空间
>
>由于jvm的"优化",指令2和指令3的执行顺序是不一定的，当执行完指定3后，此时的helper对象就已经不在是null的了,但此时指令2不一定已经被执行。
>
>假设线程1和线程2同时调用getHelper()方法，此时线程1执行完指令1和指令3，线程2抢到了执行权，此时helper对象是非空的。
>
>所以线程2拿到了一个尚未初始化的helper对象，此时线程2调用这个helper就会抛出异常
>————————————————
>版权声明：本文为CSDN博主「Null_RuzZ」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
>原文链接：https://blog.csdn.net/null_ruzz/article/details/72530826
>
>

**2. 饿汉式：初始化时即创建，用到时直接返回**

 ~~~java
//天生的线程安全
public class Singleton {
    //1.私有化构造器
    private Singleton(){};
    //2.在类中创建一个类的实例,私有化,静态的
    private static  Singleton instance   = new Singleton();
   // 3.通过公共方法调用,此公共方法只能类调用,因为设置了 static
    public static Singleton getInstance(){
        return instance;
    }
}
 ~~~

3. 静态内部类【推荐】

 ~~~java
public class Singleton {
    private static class SingletonHolder{
        private static final Singleton INSTTANCE = new Singleton();
    }
 
    private Singleton(){};
 
    public static final Singleton getInstance(){
        return SingletonHolder.INSTTANCE;
    }
}
 ~~~



![image-20200720221554779](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200720221554779.png)

![image-20200720221611449](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200720221611449.png)

![image-20200720221656414](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200720221656414.png)



# 数据结构

#### 1. B-树和B+树

图片来源: [link](https://www.jianshu.com/p/71700a464e97).

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200325215551384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzUxODAzOA==,size_16,color_FFFFFF,t_70)
一个m阶的B-树和B+的区别，具有如下几个特征：

<table>
   <tr>
      <td>
         关键词
      </td>
      <td>
         B-树
      </td>
      <td>
         B+树
      </td>
      <td>
         备注
      </td>
   </tr>
   <tr>
      <td>
         最大分支，最小分支
      </td>
      <td>
         每个结点最多有m个分支（子树），最少⌈m/2⌉（中间结点）个分支或者2个分支（是根节点非叶子结点）。 
      </td>
      <td>
         同左
      </td>
      <td>
         m阶对应的就是就是最大分支
      </td>
   </tr>
   <tr>
      <td>
         n个关键字与分支的关系
      </td>
      <td>
         分支等于n+1
      </td>
      <td>
         分支等于n
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         关键字个数（B+树关键字个数要多）
      </td>
      <td>
         大于等于⌈m/2⌉-1小于等于m-1
      </td>
      <td>
         大于等于⌈m/2⌉小于等于m
      </td>
      <td>
         B+树关键字个数要多，+体现在的地方。
      </td>
   </tr>
   <tr>
      <td>
         叶子结点相同点
      </td>
      <td>
         每个节点中的元素互不相等且按照从小到大排列；所有的叶子结点都位于同一层。
      </td>
      <td>
         同左
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         叶子结点不相同
      </td>
      <td>
         不包含信息
      </td>
      <td>
         叶子结点包含信息，指针指向记录。
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         叶子结点之间的关系
      </td>
      <td>
         无
      </td>
      <td>
         B+树上有一个指针指向关键字最小的叶子结点，所有叶子节点之间链接成一个线性链表
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         非叶子结点
      </td>
      <td>
         一个关键字对应一个记录的存储地址
      </td>
      <td>
         只起到索引的作用
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         存储结构
      </td>
      <td>
         相同
      </td>
      <td>
         同左
      </td>
      <td>
         无
      </td>
   </tr>
</table>

**B+树是B-树的一种变体，而B-树是二叉排序树的一种升级。二排序树是二路查找，而b+树树多路查找，一个m阶的b+树每个节点最多有m个分支，节点最多会有m个关键字，是有序排列的，每个关键字的左分支节点的内关键字都比它的值小，而有分支节点内的关键字都比他大。**

回答思路：

1. m阶B-树和B+树都满足**：m阶就是结点最大分支m**。
2. 但是B+树的“+”体现在哪呢：首先，**B+树的每个结点内关键字n个数最大值比B-树多1**。
3. 根据1，2得知**：n个关键字与分支的关系：B-树分支为n+1,B-树分支为n**。
4. 再考虑叶子结点相同点**：每个节点中的元素互不相等且按照从小到大排列；所有的叶子结点都位于同一层**。
5. 再考虑叶子结点不同点**：B+树上有一个指针指向关键字最小的叶子结点，所有叶子节点之间链接成一个线性链表**。
6. 再考虑叶子结点不同点2**：B+树结点不包含信息；叶子结点包含信息，指针指向记录**。
7. 再考虑==非==叶子结点不同点**：B-树非叶子结点一个关键字对应一个记录的存储地址；B+树非叶子结点只起到索引的作用**。

**【题目拓展：B+树比B树的优势】**

1. 单一节点存储更多的元素，使得查询的IO次数更少；

>这也使得B+树相对于二叉查找树和b-树，都更加矮胖，

2. 所有查询都要查找到叶子节点，每次查询IO次数相同，查询性能稳定；

>任何关键字的查询必须走从根结点到叶子结点，查询路径长度相同

3. 所有叶子节点形成有序链表，便于范围查询。

##### 浅析Mysql索引数据结构演变

https://blog.csdn.net/weixin_34019144/article/details/93181425

#### 2. 红黑树

* **什么是二叉排序（BST）树？**
  二叉树是空树或者满足一下条件：

1. 若它的左子树不为空，则左子树上的左节点的关键字的值均小于根节点关键字的值。
2. 若它的右子树不为空，则右子树上的左节点的关键字的值均大于根节点关键字的值。
3. 左右子树又分别是一颗二叉排序树

* **什么是平衡二叉（AVL）树？**
  平衡二叉树首先是二叉查找树，由于树越矮查找效率越高，就有了二叉查找树。二叉平衡树中所有平衡因子只能是-1，0，1三个值

* **什么是平衡因子？**
  一个结点的平衡因子为其左子树的高度减去右子树高度的差。

* **什么是红黑树？**

* [漫画讲解](https://www.cnblogs.com/wffzk/p/11978958.html)

* [link](http://www.360doc.com/content/18/0904/19/25944647_783893127.shtml)

* 红黑树是一颗二叉搜索树，它相对二叉搜索树增加了一个存储位来标识结点颜色，可以使 Red 或 Black。通过对任何一条从根到叶子的简单路径上各个结点的颜色进行约束，确保没有一条路径会比其他路径长出两倍。

* **红黑树有什么特点？**

* 1.节点是红色或黑色。

  2.根节点是黑色。

  3.每个叶子节点都是黑色的空节点（NIL节点）。

  4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

  5.从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

  > **简单来说**：
  >
  > 1. **根节点和叶子节点是黑色的**；
  > 2. **从每个叶子到根的所有路径上不能有两个连续的红色节点**；
  > 3. **从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点**；

* **红黑树什么时候调整？**

* 什么情况下会破坏红黑树的规则，什么情况下不会破坏规则呢？我们举两个简单的栗子：

  在举例子之前，我们做一点小小的补充！

  插入之前所有根至外部节点的路径上黑色节点数目都相同，所以如果插入的节点是黑色肯定错误（黑色节点数目不相同），

  而相对的插入红节点可能会也可能不会违反“没有连续两个节点是红色”这一条件，所以插入的节点为红色，如果违反条件再调整

* **红黑树如何调整？**

* 变色：

  为了重新符合红黑树的规则，尝试把红色节点变为黑色，或者把黑色节点变为红色。

* 左旋转：

  逆时针旋转红黑树的两个节点，使得父节点被自己的右孩子取代，而自己成为自己的左孩子

  右旋转：

  顺时针旋转红黑树的两个节点，使得父节点被自己的左孩子取代，而自己成为自己的右孩子

* 

#### 3. 跳表

![img](https://pics1.baidu.com/feed/d52a2834349b033b81b1a2b655c7e6d7d539bdab.png?token=071b640b8915d3527917b8bee0c72493&s=35B67D330FA848034E7CECCA03007032

![img](https://pics3.baidu.com/feed/8c1001e93901213f14bbb91d6beee6d52e2e9571.png?token=85af3949f546ff1a8bb42ccf9a547492&s=AFC5B25ECEB9588810C1894C03007073)

* **有序的链表**：在一个有序的链表里面，查询跟插入的算法复杂度都是O(n)。

* **跳表**：是一种改进的有序的链表，结点是跳过一部分的，从而加快了查询的速度。

  > 图片来源：[link](https://baijiahao.baidu.com/s?id=1633338040568845450&wfr=spider&for=pc)

#### 4. 排序

**前言**：这是我考研时根据率辉老师的《高分笔记》总结的。



| 名称         | 空间复杂度 | 最好情况下时间复杂度             | 最差情况下时间复杂度 | 稳定性 |
| ------------ | ---------- | -------------------------------- | -------------------- | ------ |
| 直接插入排序 | O(1)       | 已经有序，双层循环变为单层，O(n) | O(n^2^ )             | 稳定   |
| 希尔排序     | O(1)       | 无                               | O(n^2^)              | 不稳定 |
| 冒泡排序     | O(n)       | 已经有序，O(n)                   | O(n^2^)              | 稳定   |
| 快速排序     | O(log~2~n) | 越无序效率越高，O(log~2~n)       | O(n^2^)              | 不稳定 |
| 简单选择排序 | O(1)       | O(n^2^)                          | O(n^2^)              | 不稳定 |
| 堆排序       | O(1)       | O(log~2~n)                       | O(log~2~n)           | 不稳定 |
| 二路归并排序 | O(n)       | O(nlog~2~n)                      | O(nlog~2~n)          | 稳定   |
| 基数排序     | O(rd)      | O(d(n+rd))                       | O(d(n+rd))           | 稳定   |

   **备注**：
   插入类排序：直接插入排序，希尔排序。
   交换类排序：冒泡排序，快速排序。
   选择类排序：简单选择排序，堆排序。

 **记忆方法**

1.时间复杂度记忆方法

平均情况下，“==快些归队==”的时间复杂度为**O(nlog2n)**，其他都为**O(n^2^）**。

**注**: ==快==：快速排序；==些==：希尔排序；==归==：归并排序；==队==：堆排序；

2.稳定性总结

“情绪**不稳定**，==快些选一堆==好友来来聊天吧！”

**注**: ==快==：快速排序；==些==：希尔排序；==选==：简单选择；==堆==：堆排序；解决哈希冲突的四种方法

https://www.cnblogs.com/chenchen127/p/11881299.html

#### 5.  哈希冲突解决方法

1. **开放地址方法**

　　（1）线性探测：按顺序决定哈希值时，如果某数据的哈希值已经存在，则在原来哈希值的基础上往后加一个单位，直至不发生哈希冲突。　

　　（2）再平方探测：按顺序决定哈希值时，如果某数据的哈希值已经存在，则在原来哈希值的基础上先加1的平方个单位，若仍然存在则减1的平方个单位。随之是2的平方，3的平方等等。直至不发生哈希冲突。

　　（3）伪随机探测：按顺序决定哈希值时，如果某数据已经存在，通过随机函数随机生成一个数，在原来哈希值的基础上加上随机数，直至不发生哈希冲突。

2. **链式地址法**（HashMap的哈希冲突解决方法）

对于相同的哈希值，使用链表进行连接。使用数组存储每一个链表。

优点（1）拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；

　　（2）由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况；

　　（3）开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间；

　　（4）在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。

缺点：指针占用较大空间时，会造成空间浪费，若空间用于增大散列表规模进而提高开放地址法的效率。

3. **建立公共溢出区**

　　建立公共溢出区存储所有哈希冲突的数据。

4. **再哈希法**

　　对于冲突的哈希值再次进行哈希处理，直至没有哈希冲突。

#### 6. [dfs和bfs](https://www.cnblogs.com/wzl19981116/p/9397203.html)

**1.dfs(深度优先搜索)是两个搜索中先理解并使用的，其实就是暴力把所有的路径都搜索出来，它运用了回溯，保存这次的位置，深入搜索，都搜索完了便回溯回来，搜下一个位置，直到把所有最深位置都搜一遍，要注意的一点是，搜索的时候有记录走过的位置，标记完后可能要改回来；**

回溯法是一种搜索法，按条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法；
![img](https://images2018.cnblogs.com/blog/1329647/201807/1329647-20180731170200913-1161325278.png)
例如这张图，从1开始到2，之后到5，5不能再走了，退回2，到6，退回2退回1，到3，一直进行；

理解这种方法比较简单，难的是要怎么用

```
void dfs(int deep)
{
	int x=deep/n,y=deep%n;
	if(符合某种要求||已经不能在搜了)
	{
		做一些操作；
		return ;
	}
	if(符合某种条件且有地方可以继续搜索的)//这里可能会有多种条件，可能要循环什么的
	{
		a[x][y]='x';//可能要改变条件，这个是瞎写的
	        dfs(deep+1,sum+1);//搜索下一层
		a[x][y]='.';//可能要改回条件，有些可能不用改比如搜地图上有多少块连续的东西
	}
}
```

**2.bfs(宽度/广度优先搜索)，这个一直理解了思想，不会用，后面才会的，思想，从某点开始，走四面可以走的路，然后在从这些路，在找可以走的路，直到最先找到符合条件的，这个运用需要用到队列(queue)，需要稍微掌握这个才能用bfs。**

图，bfs就是和它类似，很好的帮助理解，雷从上往下，同时向四面八方的延长（当然不是很严谨的），然后找到那个最近的建筑物，然后劈了它；
![img](https://images2018.cnblogs.com/blog/1329647/201807/1329647-20180731170200913-1161325278.png)
还是这张图，从1开始搜，有2，3，4几个点，存起来，从2开始有5，6，存起来，搜3，有7，8，存起来，搜4，没有了；现在开始搜刚刚存的点，从5开始，没有，然后搜6.。。一直进行，直到找到；

```
int visit[N][N]//用来记录走过的位置
int dir[4][2]={0,-1,0,1,-1,0,1,0};
struct node
{
	int x,y,bits;//一般是点，还有步数，也可以存其他的
};
queue<node>v;
void bfs1(node p)
{
	node t,tt;
	v.push(p);
	while(!v.empty())
	{
		t=v.front();//取出最前面的
		v.pop();//删除
		if(找到符合条件的)
		{
			做记录；
			while(!v.empty()) v.pop();//如果后面还需要用，随手清空队列
			return;
		}
		visit[t.x][t.y]=1;//走过的进行标记，以免重复
		rep(i,0,4)//做多次查找
		{
			tt=t;
			tt.x+=dir[i][0];tt.y+=dir[i][1];//这里的例子是向上下左右查找的
			if(如果这个位置符合条件)
			{
				tt.bits++;//步数加一
				v.push(tt); //把它推入队列，在后面的时候就可以用了
			}
		}
	}
}
```

3.dfs和bfs的区别

其实有时候两个都可以用，不过需要其他的东西来记录什么的，各自有各自的优势

bfs是用来搜索最短径路的解法是比较合适的

比如求最少步数的解，最少交换次数的解，最快走出迷宫等等，因为bfs搜索过程中遇到的第一个解一定是离最初位置最近的，所以遇到第一个解，一定就是最优解，此时搜索算法可以终止
而如果用dfs，会搜一些其他的位置，需要花相对比较多的时间，需要搜很多次，然后如果找到还不一定是最优解，还要记录这次找的位置，与之后找到的答案进行比较，看看谁才是最优解，这样就比较麻烦

dfs应用比较广泛，用起来比较简单原答案：适合搜索全部的解 。。现在看来比较蠢，其实也没有很适合，只是我当初比较会用dfs而已，来着其实是一样的

如果要搜索全部的解，在记录路径的时候会简单一点，只需要把每一次找的点，放进去答案中就好；并且，相对而言dfs在做很多题目可以用上，比如分治、数位dp，其实就是递归啦，而bfs用的比较少。因为我做的题目比较少，没遇见
原答案：因为要搜索全部的解，在记录路径的时候也会简单一点，而bfs搜索过程中，遇到离根最近的解，并没有什么用，也必须遍历完整棵搜索树。

bfs是浪费空间节省时间，dfs是浪费时间节省空间。

因为dfs要走很多的路径，可能都是没用的，（做有些题目的时候要进行剪枝，就是确定不符合条件的就可以结束，以免浪费时间，否则有些题目会TLE）；
而bfs可以走的点要存起来，需要队列，因此需要空间来储存，便是浪费了空间，假设有十层，各个结点有2个子节点，那么储存到第10层就要存 2^10-1 个数据，而dfs只需要存10个数据，但是找到答案的速度相对快一点。

稍微理解之后就可以了，不一定要纠结怎么用，先去做题目，很多都是做着就突然明白怎么用了。



# MySQL理论

#### 1. 数据库三大范式

什么是范式：简言之就是，数据库设计对数据的存储性能，还有开发人员对数据的操作都有莫大的关系.所以**建立科学的，规范的的数据库**是需要满足一些.

1. **第一范式（列不可再分）**： 数据库表中的所有字段值都是不可分解的原子值，如一张表里有一个字段是高级职称，但是在高校里高级职称包括副教授和教授，这属于可分的，所以不符合第一范式.

2. **第二范式（非主属性完全依赖于码 ）**：在一个数据库表中，一个表中只能保存一种（**类**）数据，不可以把多种数据保存在同一张数据库表中.

   例如，在选课关系表(学号，课程号，成绩，学分)，关键字为组合关键字(学号，课程号)，但由于非主属性学分仅依赖于课程号，对关键字(学号，课程号)只是部分依赖，而不是完全依赖，因此此种方式会导致数据冗余以及更新异常等问题，解决办法是将其分为两个关系模式：学生表(学号，课程号，分数)和课程表(课程号，学分)，新关系通过学生表中的外关键字课程号联系，在需要时进行连接.

3. **第三范式（确保每列都和主键列直接相关，而不是间接相关）**：减小了数据冗余.有一张表(学号，系名，系主任)，这里存在传递依赖.学号->系名，系名->系主任 传递依赖，需要将系名和系主任另外新建一张表.

4. **BCNF范式(排除了任何属性对码的传递依赖和部分依赖)**：

   * 所有非主属性对每一个码都是完全函数依赖.

   * 所有的主属性对每一个不包含它的码，也是完全函数依赖.

   * 没有任何属性完全函数依赖于非码的任何一组属性.

>**完全函数依赖**
>定义：设X，Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X.
>
>比如: 当主键为学号时，学号->姓名
>
>**部分函数依赖**
>定义：设X，Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X.
>
>这主要针对于组合属性，比如，当主键为（学号，课程号）的组合属性时，学分->课程号，不依赖于其中的学号，即只依赖于这个集合的一部分，为部分函数依赖.
>
>**传递函数依赖**：
>设X，Y，Z是关系R中互不相同的属性集合，存在X→Y(Y !→X)，Y→Z，则称Z传递函数依赖于X.
>
>数据库的表中**：列**即**属性**；**行**即**元组**.
>参考网站： [link](https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html).
>
>原文链接：https://blog.csdn.net/qq_40511966/article/details/104047883

#### 2. [Mysql的存储引擎以及区别](https://www.cnblogs.com/rgever/p/9736374.html)

**主要区别**：

-   MyISAM（"my-z[ei]m"）不支持事务；InnoDB是事务类型的存储引擎。       
-   MyISAM只支持表级锁；InnoDB支持行级锁和表级锁，默认为行级锁（**适合高并发**）。       
-   MyISAM引擎不支持外键；InnoDB支持外键。
-   索引方面，都是b+树，但是MyISAM是非聚簇索引，而InnoDB是聚簇索引

**从使用上来说**：

1. MyISAM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyISAM
2. InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB

![img](https://img-blog.csdn.net/20181010091048777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIxODcwNTU1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

>**Innodb**：Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别.该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引.但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表.当需要使用数据库事务时，该引擎当然是首选.由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率.但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表.
>**MyISAM**：MyISAM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些.不过和Innodb不同，MyISAM中存储了表的行数，于是SELECT COUNT(#) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描.如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyISAM也是很好的选择.

#### 3、一条SQL查询是如何执行的（不熟悉）？

https://blog.csdn.net/belalds/article/details/91430614

![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20181123112246223.png?x-oss-process=image/watermark，type_ZmFuZ3poZW5naGVpdGk，shadow_10，text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01lZ3VzdGFzX0pKQw==，size_16，color_FFFFFF，t_70)

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分.

Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等.

而存储引擎层负责数据的存储和提取.其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎.现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎.

也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB.不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine=memory， 来指定使用内存引擎创建表.不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择.

从图中不难看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分.你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用.

**连接器**

第一步，你会先连接到这个数据库上，这时候接待你的就是连接器.连接器负责跟客户端建立连接、获取权限、维持和管理连接.连接命令一般是这么写的：

```
mysql -h$ip -P$port -u$user -p
```

输完命令之后，你就需要在交互对话里面输入密码.虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露.如果你连的是生产服务器，强烈建议你不要这么做.

连接命令中的 mysql 是客户端工具，用来跟服务端建立连接.在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码.

- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行.
- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限.之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限.

这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限.修改完成后，只有再新建的连接才会使用新的权限设置.

连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它.文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接.

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181123113120614.png)

客户端如果太长时间没动静，连接器就会自动将它断开.这个时间是由参数 wait_timeout 控制的，默认值是 8 小时.

如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query.这时候如果你要继续，就需要重连，然后再执行请求了.

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接.短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个.

建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接.

但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的.这些资源会在连接断开的时候才释放.所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了.

怎么解决这个问题呢？你可以考虑以下两种方案.

1. 定期断开长连接.使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连.
2. 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源.这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态.

**查询缓存**

连接建立完成后，你就可以执行 select 语句了.执行逻辑就会来到第二步：查询缓存.

MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句.之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中.key 是查询的语句，value 是查询的结果.如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端.

如果语句不在查询缓存中，就会继续后面的执行阶段.执行完成后，执行结果会被存入查询缓存中.你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高.

**但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利.**

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空.因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了.对于更新压力大的数据库来说，查询缓存的命中率会非常低.除非你的业务就是有一张静态表，很长时间才会更新一次.比如，一个系统配置表，那这张表上的查询才适合使用查询缓存.

好在 MySQL 也提供了这种“按需使用”的方式.你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存.而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：

```
mysql> select SQL_CACHE * from T where ID=10；
```

需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了.

**分析器**

如果没有命中查询缓存，就要开始真正执行语句了.首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析.

分析器先会做“词法分析”.你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么.

MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句.它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”.

做完了这些识别以后，就要做“语法分析”.根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法.

如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”.

```
mysql> elect * from t where ID=1;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1
```

一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容.

**优化器**

经过了分析器，MySQL 就知道你要做什么了.在开始执行之前，还要先经过优化器的处理.

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序.比如你执行下面这样的语句，这个语句是执行两个表的 join：

```
mysql> select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;
```

- 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20.
- 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10.
  这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案.

优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段.如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等.

**执行器**

MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句.

开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示.

```
mysql> select * from T where ID=10;
ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
```

如果有权限，就打开表继续执行.打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口.

比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：

1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行.
3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端.

至此，这个语句就执行完成了.

对于有索引的表，执行的逻辑也差不多.第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的.

你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行.这个值就是在执行器每次调用引擎获取数据行的时候累加的.

在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此 引擎扫描行数跟 rows_examined 并不是完全相同的.

#### 4. 什么是回表（不熟悉）

回表就是先通过数据库索引扫描出数据所在的行，再通过行主键id取出索引中未提供的数据，即基于非主键索引的查询需要多扫描一棵索引树.因此，可以通过索引先查询出id字段，再通过主键id字段，查询行中的字段数据，即通过再次查询提供MySQL查询速度.

> **回表查询**，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。

#### 5. MySQL是如何解决幻读的（重要）

**一、什么是幻读**

在一次事务里面，多次查询之后，结果集的个数不一致的情况叫做幻读。而多出来或者少的哪一行被叫做幻行，Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读。

**二、为什么要解决幻读**

在高并发数据库系统中，需要保证事务与事务之间的隔离性，还有事务本身的一致性。

**三、MySQL 是如何解决幻读的**

如果你看到了这篇文章，那么我会默认你了解了 脏读 、不可重复读与可重复读。

**1. 多版本并发控制（MVCC）（快照读）**

多数数据库都实现了多版本并发控制，并且都是靠**保存数据快照**来实现的。以 InnoDB 为例，每一行中都冗余了两个字段。一个是行的创建版本，一个是行的删除（过期）版本。版本号随着每次事务的开启自增。事务每次取数据的时候都会**取创建版本小于当前事务版本的数据，以及过期版本大于当前版本的数据**。

普通的 select 就是快照读。

```
select * from T where number = 1;
```

原理：将历史数据存一份快照，所以其他事务增加与删除数据，对于当前事务来说是不可见的。

**2. next-key 锁 （当前读）**

next-key 锁包含两部分

1. 记录锁（**行锁**）
2. **间隙锁**

**行锁是加在索引上的锁**，**间隙锁是加在索引之间的**。（思考：如果列上没有索引会发生什么？）

```sql
select * from T where number = 1 for update;
select * from T where number = 1 lock in share mode;
insert
update
delete
```

原理**：将当前数据行与上一条数据和下一条数据之间的间隙锁定，保证此范围内读取的数据是一致的**。

其他：MySQL InnoDB 引擎 RR 隔离级别是否解决了幻读？

a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意dml操作），a事务再select出来的结果在MVCC下还和第一次select一样，接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了，实测在RR级别下确实如此。

如果这样理解的话，Mysql的RR级别确实防不住幻读

有道友回复[ 地址：](https://github.com/Yhzhtk/note/issues/42#issuecomment-449682887)

在快照读读情况下，mysql通过mvcc来避免幻读。
在当前读读情况下，mysql通过next-key来避免幻读。
select * from t where a=1;属于快照读
select * from t where a=1 lock in share mode;属于当前读

不能把快照读和当前读得到的结果不一样这种情况认为是幻读，这是两种不同的使用。所以我认为mysql的rr级别是解决了幻读的。

先说结论，MySQL 存储引擎 InnoDB 隔离级别 RR 解决了幻读问题。

如引用一问题所说，T1 select 之后 update，会将 T2 中 insert 的数据一起更新，那么认为多出来一行，所以防不住幻读。看着说法无懈可击，但是其实是错误的，InnoDB 中设置了 快照读 和 当前读 两种模式，如果只有快照读，那么自然没有幻读问题，但是如果将语句提升到当前读，那么 T1 在 select 的时候需要用如下语法： select * from t for update (lock in share mode) 进入当前读，那么自然没有 T2 可以插入数据这一回事儿了。

注意：next-key 固然很好的解决了幻读问题，但是还是遵循一般的定律，隔离级别越高，并发越低。

以上所述是小编给大家介绍的MySQL是如何解决幻读的详解整合，希望对大家有所帮助，如果大家有任何疑问请给我留言，小编会及时回复大家的。在此也非常感谢大家对脚本之家网站的支持！

#### 6. 主从复制原理 （多集群）

> 整理自深入浅出mysql：https://download.csdn.net/download/qq_16399991/10660150
>
> https://blog.csdn.net/qq_16399991/article/details/82749333

**概述**

   mysql从3.23版本开始提供复制功能，复制是将主库的DDL和DML操作通过二进制日志传递到复制服务器（从库）上，然后从库对这些日志重新执行（重做），从而使得主库和从库保持数据一致。

  **mysql复制的优点**：

- 如果主库出现问题，可以快速切换到从库提供服务
- 可以在从库执行查询操作，降低主库的访问压力。
- 可以在从库进行备份，以免备份期间影响主库的服务。

**注意**：由于mysql实现的异步复制，所以主库和从库数据之间存在一定的差异，在从库执行查询操作需要考虑这些数据的差异，一般只有更新不频繁和对实时性要求不高的数据可以通过从库插叙，实行要求高的仍要从主库查询。

**复制原理**

mysql的复制原理大致如下。

(1)首先，mysql主库在事务提交时会把数据库变更作为事件Events记录在二进制文件binlog中；mysql主库上的sys_binlog控制binlog日志刷新到磁盘。

(2)主库推送二进制文件binlog中的事件到从库的中继日志relay log,之后从库根据中继日志重做数据库变更操作。通过逻辑复制，以此来达到数据一致。

Mysql通过3个线程来完成主从库之间的数据复制：其中BinLog Dump线程跑在主库上，I/O线程和SQl线程跑在从库上。当从库启动复制（start slave）时，首先创建I/O线程连接主库，主库随后创建Binlog Dump线程读取数据库事件并发给I/O线程，I/O线程获取到数据库事件更新到从库的中继日志Realy log中去，之后从库上的SQl线程读取中继日志relay log 中更新的数据库事件并应用。

####  7.redo和undo日志（重要）

>https://blog.csdn.net/q1060701529/article/details/102393291
>
>https://blog.csdn.net/qq_38125183/article/details/80652557

**Redo**是没搞成重搞一遍，**undo**是搞了后悔

>|            | **Undo**                   | **Redo**             |
>| ---------- | -------------------------- | -------------------- |
>| **记录**   | **怎样还原修改**           | **怎样创建修改**     |
>| **用于**   | **回滚、读一致性**         | **前滚、数据库修改** |
>| **存储于** | **Undo段**                 | **Redo日志文件**     |
>| **保护**   | **多用户系统中的读一致性** | **损失的数据**       |

>**undo日志**基本是**逻辑日志**，**其记录时间点为修改缓冲中页面之前**(先于redo日志，这样redo日志可以记录undo页面的变换，防止undo日志页因为宕机有部分没有刷新到ibd文件回滚段)，需要注意的是次级索引记录的修改不记录undo日志(为什么？我感觉也可以记录。。)。需要注意的是binlog日志的记录点是在读取到commit之后写入的（即一定要知道事务提交了才能记录），这个时间redo已经写入，但一般修改的脏页还没刷新到硬盘。这三个日志写入时间点可以根据参数控制，一般都是联合使用。
>
>**redo日志**大部分为**物理日志**，**其记录时间点为缓冲中页面修改完成**，但还没有刷新到硬盘的时间点（事务提交之前），即日至一定要比数据先到硬盘，聚集索引，次级索引，undo页面修改都需要记录redo日志，即可以把redo日志看成大管家，保证所有数据的完整性。
>
>**rollback时**，要做以下工作：
>1.撤销已做的所有修改，其完成方式如下：从undo段读回数据，然后实际上逆向执行前面所做的操作，并将undo条目标记为已用
>2.会话持有的所有锁都将释放，如果有人在排队等待我们持有的锁，将会被唤醒
>
>结论：rollback的花费远远超过commit的花费，rollback的花费直接跟之前执行的操作有关，所以尽量的少rollback

首先来讨论**事务的四大特性ACID**

- 原子性（Atomicity）：事务作为一个整体来执行，要不都执行，要不都不执行

- 一致性（Consistency）：事务必须保证数据库从一个一致状态转移到另一个一致状态。不能破坏关系数据的完整性以及业务逻辑的一致性。完整性一般就是数据的域完整性、实体完整性以及参照完整性。域完整性始址我们在创建表的时候指定的数据类型，输入限制。实体完整性规定我们的记录必须唯一，也就是说一个记录中必须存在一个或者多个字段唯一标示这一条记录。参照完整性则一般对应于关系表之间的关系，保证主键和外键之间的参照关系。不能因为执行事务儿破坏数据的完整性。

  逻辑业务一致性举个例子。再银行转账操作中，a、b初始值1000，a像b转100，但是不能因为我们的事务操作使得b只收到了50。事务要保证业务操作中我们的业务一致性不能乱。

- 隔离性（Isolation）：多个事务并发的时候，一个事务执行的时候不会影响另一个事务。

- 持久性（Durability）：已被提交的事务必须保存再数据库中。

**undo日志到底做了什么? undo日志会记录事务执行过程中，每次修改的数据的原始值**。

```mysql
x =5,y  = 8
t1 begin:
	//undo日志记录x=5
	x = x- 1;
	//undo日志记录y=8
	y = y-2;
	//事务执行临近结束，将undo日志写入到磁盘
	//将数据写入到磁盘
commit
```

我们都知道，事务是具有原子性的要不全做，要不全部做。可到底是什么机制协助了数据库，undo日志就可以保证数据库事务操作的原子性，从上面的流程我们可以得知**每次进行事务修改之前，都会把未修改之前的值存储到undo日志中，当然再提交的时候也是先将undo写到磁盘，再把修改后的数据写到磁盘**。倘若再undo写入磁盘之前发生了异常，根本就不需要做任何操作，这时候事务是被认为执行失败的，也不需要回滚，因为undo日志没有写入磁盘，数据库被认为处于没有执行事务的状态。若再数据写入磁盘的时候发生故障，则可以根据undo日志进行回滚，整个过程下来起码实现了。

**undo（**原子性以及持久性**）操作的特点总结如下**：

1. 在更新数据前把数据记录到**undo操作**
2. **持久性**，只要数据提交则必定保存到了数据库
3. undo log必须先于数据持久化到磁盘，这样的话若数据写入磁盘或者进行commit是出错，可以根据undo日志进行回滚
4. **若事务再undo持久化之前出错**，则数据库中的数据还保持在事务之前的状态。undo日志中也没有相应的记录，不需要回滚

当然undo的缺陷也很明显，他需要提交一次undo日志到磁盘，和一次数据到磁盘。io次数过多，性能太低。

**redo的出现**

**为了解决undo性能过低的问题，就引入了redo**，redo与undo正相反，他记录的是**新数据的备份。并且事务在提交的时候只需将redo日志持久化到磁盘即可，数据可以根据redo日志异步的持久到磁盘。当发生异常的时候，只要redo日志写入到磁盘我们就可以根据redo日志来进行回滚**。倘若redo日志再持久化到磁盘的时候出错，数据库就相当于没有执行过当前事务。

**数据库恢复策略**

1.只按照redo日志进行回复，所有事务（包括未提交的事务）都按照redo日志，也就是视图提交后的结果进行恢复

2.第二种分两步走，第一部和第一种一样，先根据redo日志对所有事务进行恢复 操作。再根据undo日志对未提交的日志进行回复操作。

Mysql采用的是第二种恢复策略。显然第一种策略也能进行事无恢复，但是为什么Mysql会采用第二种呢。我个人理解是这样的，虽然只按照redo日志进行回复也能回复数据。但是redo日志记录的是事务修改后的数据，这对于已经提交的事务是没有问题的。但是对于未提交的事务，当灾难发生时，事务并没有被提交，逻辑上应该认为这个事务是操作失败的，也就是类似于在做普通的sql的时候出现了异常，此时我们需要做回滚操作。只按照redo日志进行恢复，那么那些未提交的事务会直接恢复到事务提交后的结果。

不妨设想一个场景，a向b转100块钱，这个事务执行的顺序也就是，将 a-100和b+100的结果写入到redo日志，redo日志进行持久化操作，最后一步就是事务提交。但是再事务提交的节骨眼儿上服务器宕了，这时候由于用户a长时间得不到服务器响应，客户端也应该向用户显示操作失败吧（假设需要同步的显示操作结果），但是根据redo日志进行回复后，a-100 以及 b+100的操作被数据库恢复了，但是用户那边的情况却恰恰相反。这样对于一个可靠性要求比较高的系统来说本就是灾难

#### 8. sql语句的书写顺序以及执行顺序上面

**1. 书写顺序**

***按以下的顺序书写sql语句***

```sql
SELECT 查询列表.
FROM 表 1                                      
【连接类型】 JOIN 表2						   
ON 连接条件
WHERE 筛选条件
GROUP BY 分组列表
HAVING 分组后的筛选条件
ORDER BY 排序的字段
LIMIT 起始的条目索引，条目数;
```

即：

```
SELECT` →`FROM` → `JOIN` → `ON` → `WHERE` → `GROUP BY` → `HAVING` → `ORDER BY`→ `LIMIT
```

***注意***：

① 连接类型有：`inner`、`left outer`、`right outer`、`cross`

② 起始条目索引默认从0开始；

③ 若 每页显示条目数：`pageSize`，要显示的页数：`page`
则有：

```sql
SELECT * FROM 表 LIMIT （page-1）* pageSize,pageSize
1
```

**2. 执行顺序**

***按右边标出的 ①-⑨ 的顺序执行***

```sql
SELECT 查询列表				⑦					
FROM 表 1					①                                      
【连接类型】 JOIN 表 2		②						   
ON 连接条件					③
WHERE 筛选条件				④
GROUP BY 分组列表			⑤
HAVING 分组后的筛选条件		⑥
ORDER BY 排序的字段			⑧
LIMIT 起始的条目索引，条目数;	⑨
123456789
```

即：

```
FROM` → `JOIN` → `ON` → `WHERE` → `GROUP BY` → `HAVING` → `SELECT` → `ORDER BY`→ `LIMIT
```

![image-20200806165825395](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200806165825395.png)

#### 【MySQL索引】

> https://cloud.tencent.com/developer/article/1125452
>
> https://www.jianshu.com/p/7c0709976f40

#####  [1] 什么是MySQL索引？

**索引（Index）的建立是为了优化数据库查询性能而建立的数据结构。**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200724124648619.png" alt="image-20200724124648619" style="zoom: 67%;" />

##### [2] B+树相对于B-树的优势？

数据库的索引结构是B+树.

1. 相比于其他查找树（B-树），B+树单一节点存储更多的关键字，也就是说B+树更加矮胖，使得查询时的平均IO次数更少，**查询效率更高**；
2. B+树的关键字信息全部存储在叶子结点中，非叶子结点只存储索引地址.所以查询都要从根节点查找到叶子节点，也就是说查询路径长度相同，**查询性能稳定**；
3. B+树的所有叶子节点形成有序链表，**便于范围查询**.

##### [3] MySQL索引实现

**1. MyISAM索引实现（非聚集索引）**

MyISAM引擎使用B+Tree作为索引结构，叶节点data域存放数据记录的地址。MyISAM的索引文件仅仅保存数据记录的地址。

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200724131341473.png" alt="image-20200724131341473" style="zoom:67%;" />

**2. InnoDB索引实现（聚集索引）**

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同，第一个重大区别是InnoDB的数据文件本身就是索引文件。

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200724132731709.png" alt="image-20200724132731709" style="zoom:67%;" />

>**InnoDB为什么必须要求表必须有主键？且是单调自增的？**
>
>因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择
>
>##### 什么情况下可以用到B树索引
>
>(1) 定义有主键的列一定要建立索引。因为主键可以加速定位到表中的某行
>
>(2) 定义有外键的列一定要建立索引。外键列通常用于表与表之间的连接，在其上创建索引可以加快表间的连接
>
>(3) 对于经常查询的数据列最好建立索引。
>
>① 对于需要在指定范围内快速或频繁查询的数据列，因为索引已经排序，其指定的范围是连续的，查询可以利用索引的排序，加快查询的时间
>
>② 经常用在 `where`子句中的数据列，将索引建立在`where`子句的集合过程中，对于需要加速或频繁检索的数据列，可以让这些经常参与查询的数据列按照索引的排序进行查询，加快查询的时间

##### [4] 聚簇索引（非聚簇索引）

**聚簇索引是对磁盘上实际数据重新组织以按指定的一个或多个列的值排序的算法**.特点是存储数据的顺序和索引顺序一致.
**聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针**.

![img](https://img2018.cnblogs.com/blog/1266222/201810/1266222-20181002095044128-1277628264.png)

>**聚集索引**：一个表中只能有一个，聚集索引的顺序与数据真实的物理存储顺序一致.**查询速度贼快**，聚集索引的叶子节点上是该行的所有数据 ，数据索引能加快范围查询(聚集索引的顺序和数据存放的逻辑顺序一致).主键!=聚集索引.
>
>**辅助索引(非聚集索引)**：一个表中可以有多个，叶子节点存放的不是一整行数据，而是键值，叶子节点的索引行中还包含了一个'书签'，这个书签就是指向聚簇索引的一个指针，从而在聚簇索引树中找到一整行数据.
>
>**聚集索引与辅助索引的区别**：叶子节点是否存放的为一整行数据
>
>**为什么主键通常建议使用自增id**
>
>**聚簇索引的数据的物理存放顺序与索引顺序是一致的**，即：**只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的**。如果主键不是自增id，那么可以想 象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。

##### [6] 最左前缀原则

[link1](https://www.jianshu.com/p/0d6c828d3c70)，[link2](https://zhuanlan.zhihu.com/p/29118331)


1. **覆盖索引**：如果在普通索引树上的查询已经直接提供了结果，不需要回表操作，这样的普通索引叫做覆盖索引.覆盖索引的使用可以显著提高查询效率，是常见的MySQL性能优化手段.

2. **索引的最左前缀原则**：MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引.在联合索引的情况下，不需要索引的全部定义，**只要满足最左前缀**，就可以利用索引来加快查询速度.这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符.**最左前缀原则的利用也可以显著提高查询效率，是常见的MySQL性能优化手段**.

>1. 一个 2 列的索引 (name， age)，对 (name)、(name， age) 上建立了索引；
>2. 一个 3 列的索引 (name， age， sex)，对 (name)、(name， age)、(name， age， sex) 上建立了索引.


3. **索引下推**：在MySQL5.6之前，只能从根据最左前缀查询到ID开始一个个回表.到主键索引上找出数据行，再对比字段值.MySQL5.6引入的索引下推优化，（联合索引前提）可以在索引遍历过程中，对索引中包含的其余字段先做判断，直接过滤掉不满足条件的记录，减少回表次数，提升查询效率.

##### **[7] 联合索引**

MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组<a1, a2, …, an>，其中各个元素均为数据表的一列遵循最左前缀规则，对where，order by，group by 都生效.

##### [8] 覆盖索引

>SQL语句只通过索引，就取到了所需要的数据，这个过程就叫做索引覆盖，换句话说查询列要被所使用的索引覆盖。

**解释一**： 就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。

**解释二**： 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。

**解释三**：是非聚集组合索引的一种形式，它包括在查询里的Select、Join和Where子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数据）。

不是所有类型的索引都可以成为覆盖索引。覆盖索引必须要存储索引的列，而哈希索引、空间索引和全文索引等都不存储索引列的值，所以MySQL只能使用B-Tree索引做覆盖索引当发起一个被索引覆盖的查询(也叫作索引覆盖查询)时，在EXPLAIN的Extra列可以看到“Using index”的信息。

注：遇到以下情况，执行计划不会选择覆盖查询。

* select选择的字段中含有不在索引中的字段 ，即索引没有覆盖全部的列。

* where条件中不能含有对索引进行like的操作。

##### **[9] 什么情况下索引会失效？**

**即查询不走索引**

下面列举几种不走索引的 SQL 语句：

\1. 索引列参与表达式计算：

```
SELECT 'sname' FROM 'stu' WHERE 'age' + 10 = 30;
```

\2. 函数运算：

```
SELECT 'sname' FROM 'stu' WHERE LEFT('date'，4) < 1990; 
```

\3. %词语%--模糊查询：

```
SELECT * FROM 'manong' WHERE `uname` LIKE '码农%' -- 走索引 
SELECT * FROM 'manong' WHERE `uname` LIKE "%码农%" -- 不走索引 
```

\4. 字符串与数字比较不走索引：

```
CREATE TABLE 'a' ('a' char(10)); EXPLAIN SELECT * FROM 'a' WHERE 'a'="1" -- 走索引 EXPLAIN SELECT * FROM 'a'WHERE 'a'=1 -- 不走索引，同样也是使用了函数运算 
```

\5. 查询条件中有 or ，即使其中有条件带索引也不会使用.换言之，就是要求使用的所有字段，都必须建立索引：

```
select * from dept where dname='xxx' or loc='xx' or deptno = 45;
```

\6. 正则表达式不使用索引.

\7. MySQL 内部优化器会对 SQL 语句进行优化，如果优化器估计使用全表扫描要比使用索引快，则不使用索引.

>#####  怎么知道创建的索引有没有被使用到？**或者说怎么才可以知道这条语句运行很慢的原因?**
>
>使用 Explain 命令来查看语句的执行计划，MySQL 在执行某个语句之前，会将该语句过一遍查询优化器，之后会拿到对语句的分析，也就是执行计划，其中包含了许多信息.可以通过其中和索引有关的信息来分析是否命中了索引，例如：possilbe_key、key、key_len 等字段，分别说明了此语句可能会使用的索引、实际使用的索引以及使用的索引长度.

##### [10] 什么情况下不建议建索引

- 对于那些查询中很少涉及的列、重复值比较多的列不要建立索引 例如，在查询中很少使用的列，有无索引并不能提高查询的速度，相反增加了系统维护时间和消耗了系统空间；又如，“性别”列只有列值“男”和“女”，增加索引并不能显著提高查询的速度 对于定义为text、image和bit数据类型的列不要建立索引。因为这些数据类型的数据列的数据量要么很大，要么很小，不利于使用索引。
- 表记录比较少 例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引
- 索引的选择性较低 所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值 `Index Selectivity = Cardinality / #T` 显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。情况下不建议建索引
  - 对于那些查询中很少涉及的列、重复值比较多的列不要建立索引 例如，在查询中很少使用的列，有无索引并不能提高查询的速度，相反增加了系统维护时间和消耗了系统空间；又如，“性别”列只有列值“男”和“女”，增加索引并不能显著提高查询的速度 对于定义为text、image和bit数据类型的列不要建立索引。因为这些数据类型的数据列的数据量要么很大，要么很小，不利于使用索引。
  - 表记录比较少 例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引
  - 索引的选择性较低 所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值 `Index Selectivity = Cardinality / #T` 显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。

##### [11] Hash索引

因为底层是哈希表，数据存储在哈希表中顺序是没有关联的，所以他不适合范围查找，如果要范围查找就需要全表扫描，他只适合全值扫描；简单的来说就是hash索引适合等值查找，不适合范围查找。    

####  [<事务专题>]

##### [1]   事务的四种特性？

* **原子性**（Atomicity）：事务作为一个整体被执行 ，要么全部执行，要么全部不执行
* **一致性**（Consistency）：保证数据库状态从一个一致状态转变为另一个一致状态
* **隔离性**（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行
* **持久性**（Durability）：一个事务一旦提交，对数据库的修改应该永久保存


> 事务是数据库的概念**：园艺搁池**
>
> undo日志就可以保证数据库事务操作的**原子性和持久性**
>
> 数据库四种隔离级别对应**隔离性**

##### [2]   并发操作会产生的问题

假如有事务1，事务2两个事务.

* **第一类丢失更新：由于事务1的回滚，导致事务2更新的的数据丢失.**
* **第二类丢失更新：由于事务1的提交，导致事务2更新的的数据丢失.**
* **脏读：由于事务1回滚，事务2读取了事务1未提交的数据，导致脏读.**
* **不可重复读：事务1前后多次读取，由于事务2期间修改了数据，导致值不一致**.
* **幻读：事务1读的时候读出了N条记录，事务2在事务1执行的过程中增加 了1条，事务1再读的时候就变成了N+1条**。

> **更脏不换**，[link](https://blog.csdn.net/qq_40831381/article/details/95895553?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.compare>)
>
> 不可重复复和幻读的区别在于前者是对于单行，后者是对于多行而言，因此前者主要是针对更新操作，后者是针对于插入操作，幻读可以理解为行数的不可重复读。

**第一类更新丢失**：

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629223059881.png" alt="image-20200629223059881" style="zoom: 67%;" />

**第二类更新丢失**：

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629223450820.png" alt="image-20200629223450820" style="zoom: 67%;" />

**脏读**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629224115804.png" alt="image-20200629224115804" style="zoom: 50%;" />

**不可重复读**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629224241243.png" alt="image-20200629224241243" style="zoom:50%;" />

**幻读**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629224325220.png" alt="image-20200629224325220" style="zoom:50%;" />



##### [3] 事务的隔离级别及实现原理？（重要）

> 原文链接：https://blog.csdn.net/soonfly/article/details/70238902
>
> 可重复读：https://blog.csdn.net/wangbaosongmsn/article/details/106874093

**前言：**Mysql如果不加限制，会造成一系列的并发问题，所以需要进行加锁操作。但是加锁会影响性能，所以存在矛盾，事务的隔离划分出不同的隔离级别就是为了在不同场景内选择适合的隔离级别.事务的隔离级别越高，对数据的完整性和一致性保证越佳，但是对并发操作的影响也越大.**MySQL事务默认隔离级别是可重复读**.

为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92定义了4个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己的业务逻辑要求，通过选择不同的隔离级别来平衡 “隔离”与“并发”的矛盾。下表很好地概括了这4个隔离级别的特性。 

![image-20200629224535553](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629224535553.png)

**首先**：**数据库所有写操作都会加排它锁**， 排他锁会阻止其它事务再对其**锁定的数据**加读或写的锁，但是对不加锁的读(select)就不起作用了。

* **READ UNCOMMITTED(读未提交)** ： 对于修改的项加排它锁，直到事务结束释放；没有快照读（MVCC），只能读最新版本的数据，不能避免任何并发问题。

* **READ COMMITTED(读已提交)** ：对于修改的项加排它锁，直到事务结束释放；有快照读，快照的粒度是**语句级**。可以避免**更新丢失和脏读**。  

* **REPEATABLE READ(可重复度)** ：对于修改的项加排它锁，直到事务结束释放；有快照读，快照的粒度是**事务级**。可以避免**不可重复读**。

* **SERIALIZABLE（串行化）** ：对于修改的项加排它锁， 使用间隙锁解决幻读问题，不会引发**并发**问题。 

> **MVCC简述：**数据库在每一行记录的后面增加两个隐藏列，分别记录创建版本号和删除版本号。 另外，每一个事务在启动的时候，都有一个唯一的递增的版本号。
>
> * **在插入操作时** ： **记录的创建版本号就是事务版本号**。
> * **在更新操作的时候**，旧的那行记录，标记删除版本号为当前事务版本号，然后插入一行新的记录的方式。
> * **删除操作的时候**，就把事务版本号作为删除版本号。
> * **查询时的要求**，创建版本号<=**当前事务版本号**<删除版本号

#### 【MySQL中的锁】

> 原文链接：https://blog.csdn.net/soonfly/article/details/70238902
>

首先从思想上无论在java还是mysql都有这乐观锁和悲观锁的概念，数据库可以分为**悲观锁（共享锁和排他锁）**，本文就从这里入手。

##### [1] 为什么要加锁

锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的 计算资源（如CPU、RAM、I/O等）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一 个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。本章我们着重讨论MySQL锁机制 的特点，常见的锁问题，以及解决MySQL锁问题的一些方法或建议。 

##### [2] 不同引擎所支持的锁？

> 它们都支持表级锁，BDB采用页面锁，InnoDB采用的是行级锁。

**MyISAM和MEMORY存储引擎**：采用的是表级锁（table-level locking）；

**BDB存储引擎**：采用的是页面锁（page-level locking），但也支持表级锁；

**InnoDB存储引擎**：既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。 
**表级锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 
**行级锁**：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 
**页面锁**：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 
从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度 来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有 并发查询的应用，如一些在线事务处理（OLTP）系统。

> MySQL的表级锁有两种模式**：表共享读锁（Table Read Lock）**和**表独占写锁（Table Write Lock）**。 

##### [3]   行锁：悲观锁

InnoDB实现了以下两种类型的**悲观锁**。

* **X锁**（Exclusive Lock）—排他锁或独占锁：若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁.它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止.在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁.

  注意：排他锁会阻止其它事务再对其锁定的数据加读或写的锁，但是不加锁的就没办法控制了.

>**排他锁指的是一个事务在一行数据加上排他锁后，其他事务不能再在其上加其他的锁，而并非不能读**
>
>在select命令中使用独占锁的SQL语句为：select … for update;

*  **S锁**（Shared Lock）—共享锁：若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁.这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改.

>如果在select查询语句中要手动加入共享锁，那么对应的SQL语句为：select ... lock in share mode

**InnoDB行锁实现方式**
InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 

##### [4]  意向锁

**为了允许行锁和表锁共存**，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

**意向共享锁（IS）**：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
**意向排他锁（IX）**：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。
![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20170419165851422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc29vbmZseQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

如果一个事务请求的锁模式与当前的锁兼容，InnoDB就请求的锁授予该事务；反之，如果两者两者不兼容，该事务就要等待锁释放。 
意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁。 
**事务可以通过以下语句显式给记录集加共享锁或排他锁**：

共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
排他锁（X）：SELECT * FROM table_name WHERE ... FOR UPDATE。
用SELECT ... IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁。

##### [5] 间隙锁

当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁 （Next-Key锁）。 
举例来说，假如emp表中只有101条记录，其empid的值分别是 1,2,…,100,101，下面的SQL：

~~~sql
Select * from  emp where empid > 100 for update;
~~~


是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。

**InnoDB使用间隙锁的目的**，一方面是为了**防止幻读**，以满足相关隔离级别的要求，对于上面的例子，要是不使 用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另外一方面，是为了**满足其恢复和复制的需要**。有关其恢复和复制对锁机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况，在后续的章节中会做进一步介绍。

很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

> 在mysql的innoDB存储引擎中，如果**更新操作**是针对一个区间的，那么它会**锁住这个区间内所有的记录**，比如update xxx where id between a and b那么它会锁住a到b之间所有记录，注意是所有记录，甚至这个记录并不存在也会被锁住，这个时候，如果另外一个连接需要插入一条记录到a到b之间，那么它就必须等到上一个事务结束。

##### [5] MVCC：乐观锁

> https://www.jianshu.com/p/56fa361e0d94

mysql的innodb采用的是行锁，而且采用了多版本并发控制来提高读操作的性能。 什么是多版本并发控制呢 ？

**MVCC（multiversion concurrency control）**。**其实就是在每一行记录的后面增加两个隐藏列，分别记录创建版本号和删除版本号**。 另外，**每一个事务在启动的时候，都有一个唯一的递增的版本号**。

1、**在插入操作时** ： **记录的创建版本号就是事务版本号**。比如我插入一条记录, 事务id 假设是1 ，那么记录如下：

| id   | name | create version | delete version |
| ---- | ---- | -------------- | -------------- |
| 1    | test | 1              |                |

2、**在更新操作的时候**，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。比如，针对上面那行记录，事务Id为2 要把name字段更新

~~~sql
update table set name= 'new_value' where id=1;
~~~

| id   | name      | create version | delete version |
| ---- | --------- | -------------- | -------------- |
| 1    | test      | 1              | 2              |
| 1    | new_value | 2              |                |

3、**删除操作的时候**，就把事务版本号作为删除版本号。比如

~~~sql
delete from table where id=1;
~~~

| id   | name      | create version | delete version |
| ---- | --------- | -------------- | -------------- |
| 1    | new_value | 2              | 3              |

4、**查询操作**：
 从上面的描述可以看到，在查询时要符合以下两个条件的记录才能被事务查询出来：

1. **当前事务版本号小于删除版本号 ，就是说删除操作是在当前事务启动之后做的**。
2. **创建版本号 小于或者等于 当前事务版本号 ，就是说记录创建是在事务中（等于的情况）或者事务启动之前**。

>创建版本号<=当前事务版本号<删除版本号

1. 这样就保证了各个事务互不影响。从这里也可以体会到一种提高系统性能的思路，就是： 通过版本号来减少锁的争用。
2. 另外，只有read-committed和 repeatable-read 两种事务隔离级别才能使用MVCC
   read-uncommited由于是读到未提交的，所以不存在版本的问题
3. 而serializable 则会对所有读取的行加锁。

##### [6] 什么时候会加锁？

在数据库增删改查四种操作中**，insert、delete和update都是会加排它锁**(Exclusive Locks)的，select不会加锁，只有显式声明才会加锁:

- select: 即最常用的查询，是不加任何锁的
- select ... lock in share mode: 会加共享锁(Shared Locks)
- select ... for update: 会加排它锁

##### [7] 牛客网总结

https://www.cnblogs.com/leedaily/p/8378779.html

![image-20200629214107805](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629214107805.png)

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629214019240.png" alt="image-20200629214019240" style="zoom: 67%;" />

![image-20200629214154861](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629214154861.png)

![image-20200629214230725](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629214230725.png)

#### [<MySQL优化总结>]

https://www.nowcoder.com/discuss/150059?type=0&order=0&pos=8&page=0

https://zhuanlan.zhihu.com/p/98146427

1. **数据库设计和表创建时考虑性能**
2. **sql的编写注意优化**
3. **分区**
4. **分库**
5. **分表**

##### **[1] **数据库设计和表创建时考虑性能

**设计表时注意**：

- **表字段避免null值出现，null值很难查询优化且占用额外的索引空间，推荐默认数字0代替**
- **尽量使用INT而不是BIGINT**，如果非负加上UNSIGNED，当然使用TINYINT、SMALLINT、MEDIUMINT更好.
- 使用枚举或整数代替字符串类型
- 尽量使用timestamp而非datatime
- 单表不要有太多字段，建议在20以内
- 用整型来存IP

**索引**：

- 不用外键，由程序保证约束
- 尽量不用UNIQUE，由程序保证约束
- **字符字段最好不要做主键**
- 字符字段只建前缀索引
- **值分布稀少的字段不适合建索引，例如'性别'**
- **应尽量避免在where子句中对字段进行null值判断，否则将导致引擎进行全表扫描**
- 使用多列索引时注意顺序和查询条件保持一致，同时删除不必要的单列索引
- 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描

**使用合适的数据类型**：

- 使用可存下数据的最小数据类型， 整型<datetime<char<varchar<blob
- 使用简单的数据类型，整型比字符处理开销更小，因为字符串的比较更复杂.如，int类型存储时间类型，bigint类型转ip函数.
- 使用合理字段属性长度，固定长度的表会更快.使用enum、char而不是varchar
- 尽可能使用not null定义字段
- 尽量少用text，非用不可最好分表

**选择合适的索引列**：

- 查询频繁的列，在where，group by，order by， on从句中出现的列
- where条件中<，<=，=，>，>=，between，in，以及like 字符串+通配符（%）出现的列
- 长度小的列，索引字段越小越好，因为数据库的存储单位是页，一页中能存下的数据越多越好
- 离散度大的列，放在联合索引前面.查看离散度，通过统计不同的列值来实现，count越大，离散程度越高

##### [2] SQL的编写需要注意优化

- **使用limit对查询结果的记录进行限定**
- **避免select * ，将需要查找的字段列出来**
- 使用连接（join）来代替子查询
- 拆分大的delete或insert语句
- **通过开启慢查询日志来找出较慢的SQL**
- 不做列运算：select id where age+1=10， 任何对列的操作都将导致全表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能移至等号右边
- **sql语句尽可能简单：一条sql只能在一个CPU运行；大语句拆小语句，减少锁时间；一条大的SQL可堵死整个库**
- OR改写成IN： OR的效率是N级别，IN的效率是log(n)级别，IN的个数建议控制在200以内
- 不要函数和触发器 ，在应用程序实现
- 避免%xxxx式查询
- 少用join
- 使用同类型比较，比如用‘123’和‘123’比，123和123比
- 尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
- 对于连续数值，使用BETWEEN不用IN: SELECT id FROM t WHERE num BETWEEN 1 AND 5
- 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大

##### [3] 谈谈你对慢查询的理解，如何解决慢查询？

[link](https://www.cnblogs.com/lukefan/archive/2019/05/17/10879627.html)

分析MySQL语句查询性能的方法除了使用 EXPLAIN 输出执行计划，还可以让MySQL记录下查询超过指定时间的语句，我们将**超过指定时间的SQL语句查询称为“慢查询”**.

**慢查询的优化方法？**

1. **只返回必要的列**：最好不要使用 SELECT * 语句.
2. **只返回必要的行**：使用 LIMIT 语句来限制返回的数据.
3. **缓存重复查询的数据**：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的

##### [4] 分区

mysql的分区是一种简单的水平分区，用户在建表时加上分区参数，对应用是透明的

对用户来说分区表是一个独立的逻辑表，但是底层由多个物理子表组成.用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，我测试，查询时不带分区条件的列，也会提高速度，故该措施值得一试.

**分区的好处是**：

- 可以让单表存储更多的数据
- 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据.另外，还可以对一个独立分区进行优化、检查、修复等操作
- 部分查询能够从查询条件确定只落在少数分区上，速度会很快
- 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备
- 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争
- 可以备份和恢复单个分区

**分区的限制和缺点**：

- 一个表最多只能有1024个分区
- 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来
- 分区表无法使用外键约束
- NULL值会使分区过滤无效
- 所有分区必须使用相同的存储引擎

**分区的类型**：

- RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区
- LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择
- HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算.这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式
- KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数.必须有一列或多列包含整数值
- 具体关于mysql分区的概念请自行google或查询官方文档，我这里只是抛砖引玉了.

##### **[5] 分表**

**分表就是把一张大表，按照如上过程都优化了，还是查询卡死，那就把这个表分成多张表，把一次查询分成多次查询，然后把结果组合返回给用户**.

分表分为垂直拆分和水平拆分，通常以某个字段做拆分项.比如以id字段拆分为100张表： 表名为 tableName_id%100

但：分表需要修改源程序代码，会给开发带来大量工作，极大的增加了开发成本，故：只适合在开发初期就考虑到了大量数据存在，做好了分表处理，不适合应用上线了再做修改，成本太高！！！而且选择这个方案，都不如选择我提供的第二第三个方案的成本低！故不建议采用.

##### [6] 分库

把一个数据库分成多个，建议做个读写分离就行了，真正的做分库也会带来大量的开发成本，得不偿失！不推荐使用.



# MySQL编程

*SQL分支及常用命令脑图：[link](https://blog.csdn.net/weixin_43518038/article/details/104996604).*

**查询时用到的表格**

**表结构如下**

  * 学生课：Student(**Sno**，Sname，Ssex，Sage，Sdept)
  * 课程表：Student(**Cno**，Cname，Cpno，Ccredit)
  * 学生选课表：SC(**Sno，Cno**，Ssex，Grade)

**注**：加粗字体为**主关键字**.
*[主关键字]: 主关键字(primary key)是表中的一个或多个字段，它的值用于唯一地标识表中的某一条记录.在两个表的关系中，主关键字用来在一个表中引用来自于另一个表中的特定记录.主关键字是一种唯一关键字，表定义的一部分.一个表的主键可以由多个关键字共同组成，并且主关键字的列不能包含空值.主关键字是可选的，并且可在 CREATE TABLE 或 ALTER TABLE 语句中定义.
**(a) Student**

<table>
   <tr>
      <td>
         学号(Sno)
      </td>
      <td>
         姓名（Sname）
      </td>
      <td>
         性别（Ssex）
      </td>
      <td>
         年龄（Sage）
      </td>
      <td>
         所在系（Sdept）
      </td>
   </tr>
   <tr>
      <td>
         20125121
      </td>
      <td>
         李勇
      </td>
      <td>
         男
      </td>
      <td>
         20
      </td>
      <td>
         CS
      </td>
   </tr>
   <tr>
      <td>
         201215122
      </td>
      <td>
         刘晨
      </td>
      <td>
         女
      </td>
      <td>
         19
      </td>
      <td>
         CS
      </td>
   </tr>
   <tr>
      <td>
         201215122
      </td>
      <td>
         王敏
      </td>
      <td>
         女
      </td>
      <td>
         18
      </td>
      <td>
         MA
      </td>
   </tr>
   <tr>
      <td>
         201215125
      </td>
      <td>
         张立
      </td>
      <td>
         男
      </td>
      <td>
         19
      </td>
      <td>
         IS
      </td>
   </tr>
</table>




**(b) Course**

<table>
   <tr>
      <td>
         课程号(Cno)
      </td>
      <td>
         课程名（Cname）
      </td>
      <td>
         先行课（Cpno）
      </td>
      <td>
         学分（Ccredit）
      </td>
   </tr>
   <tr>
      <td>
         1
      </td>
      <td>
         数据库
      </td>
      <td>
         5
      </td>
      <td>
         4
      </td>
   </tr>
   <tr>
      <td>
         2
      </td>
      <td>
         数学
      </td>
      <td>
         null
      </td>
      <td>
         2
      </td>
   </tr>
   <tr>
      <td>
         3
      </td>
      <td>
         信息系统
      </td>
      <td>
         1
      </td>
      <td>
         4
      </td>
   </tr>
   <tr>
      <td>
         4
      </td>
      <td>
         操作系统
      </td>
      <td>
         6
      </td>
      <td>
         3
      </td>
   </tr>
   <tr>
      <td>
         5
      </td>
      <td>
         数据结构
      </td>
      <td>
         7
      </td>
      <td>
         4
      </td>
   </tr>
   <tr>
      <td>
         6
      </td>
      <td>
         数据处理
      </td>
      <td>
         null
      </td>
      <td>
         2
      </td>
   </tr>
   <tr>
      <td>
         7
      </td>
      <td>
         PASCAL语言
      </td>
      <td>
         6
      </td>
      <td>
         4
      </td>
   </tr>
</table>




**（c）SC**

<table>
   <tr>
      <td>
         学号（Sno)
      </td>
      <td>
         课程号（Cno）
      </td>
      <td>
         成绩（Crade）
      </td>
   </tr>
   <tr>
      <td>
         201215121
      </td>
      <td>
         1
      </td>
      <td>
         92
      </td>
   </tr>
   <tr>
      <td>
         201215121
      </td>
      <td>
         2
      </td>
      <td>
         85
      </td>
   </tr>
   <tr>
      <td>
         201215121
      </td>
      <td>
         3
      </td>
      <td>
         88
      </td>
   </tr>
   <tr>
      <td>
         201215122
      </td>
      <td>
         2
      </td>
      <td>
         90
      </td>
   </tr>
   <tr>
      <td>
         201215122
      </td>
      <td>
         3
      </td>
      <td>
         80
      </td>
   </tr>
</table>




另外，我们要了解这四个词的含义：**模式，基本表，视图，索引.**
*[模式]:   是数据库中全体数据的逻辑结构和特征的描述，在关系型数据库中，模式的具体表现是一系列表及表与表之间的联系.
*[基本表]: 基本表就是一个关系及属性的描述，如：学生（学好，姓名，性别，班级）.
*[视图]:视图是一种外模式，是建立在基础表之上的数据查询.
*[索引]:数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息.

#### 1．模式定义与删除

**SQL的数据定义语句**：

<table>
   <tr>
      <td>
         操作对象 
      </td>
      <td>
         创建
      </td>
      <td>
         删除
      </td>
            <td>
         修改
      </td>
   </tr>
   <tr>
      <td>
         模式
      </td>
      <td>
         CREATE  SCHEMA
      </td>
      <td>
         DROP   SCHEMA
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         表
      </td>
      <td>
         CREATE  TABLE    
      </td>
      <td>
         DROP  TABLE 
      </td>
      <td>
         ALTER  TABLE 
      </td>
   </tr>
   <tr>
      <td>
         视图
      </td>
      <td>
         CREATE  VIEW
      </td>
      <td>
         DROP  VIEW
      </td>
      <td>
         无
      </td>
   </tr>
   <tr>
      <td>
         索引
      </td>
      <td>
         CREATE  INDEX
      </td>
      <td>
         DROP  INDEX
      </td>
      <td>
         ALTER  INDEX
      </td>
   </tr>
</table>

##### 1.1 定义模式

在SQL中，模式定义语句如下：

>CREATE SCHEMA <模式名> AUTHORIZATION <用户名>;

【例1.1】为用户WANG定义一个学生-课程模式S-T：
**CREATE SCHEMA ”S-T” AUTHORIZATION WANG;**
###

##### 1.2 模式删除

在SQL中，模式删除语句如下：

>DROP SCHEMA <模式名> <CASCADE|RESTRICT>;

*[CASCADE|RESTRICT]: CASCADE(级联)，删除模式的同时把该模式中所有数据库对象全部删除；RESTRICT（限制），表示如果该模式中已经定义了下属的数据库脆响，则拒绝该删除语句的执行.

【例1.2】删除模式ZHANG和其中定义的表TAB1；
**DROP SCHEMA ZHANG CASCADE;**

#### 2. 基本表操作

##### 2.1 定义基本表

在SQL中，定义基本表语句如下：

>CREATE TABLE <表名> ( <列名> <数据类型>[列级完整性约束条件]，<br/>　　　　　　　　　　　[列名> <数据类型>[列级完整性约束条件]，<br/>　　　　　　　　　　　...<br/>　　　　　　　　　　　<表级完整性约束条件>]);

【例 2.1】建立学生选课表SC， 表(c).
**CREATE TABLE SC**
　**(Sno CHAR(9)，**   　　　　　 //定义Sno，数据类型为CHAR，字节不多于9
　**Cno CHAR(4)，**
　**Grade SMALLINT，**    　　　　//定义Grade，数据类型为SMALLINT
　**PRIMARY KEY(Sno， Cno)，**   //主码由两个属性构成，必须作为表级完整性进行定义
　**FOREIGE KEY (Sno) REFERENCES Student(Sno)，**
//表级完整性定义，Sno为外码，被参照表为Student
　**FOREIGE KEY (Cno) REFERENCES Course(Cno)，**
//表级完整性定义，Cno为外码，被参照表为Course
);  
*[外码]:　关系模式R中属性或属性组X并非R的码，但X是另一个关系模式的码，则称X是R的外码.

##### 2.2 修改基本表 

==略==

##### 2.3 删除基本表

==略==

##### 2.4索引的建立与删除

==略==

#### 3．数据查询

**其一般格式为：**

>SELECT [ALL|DISTINCT] <目标列表达式> [，<目标列表达式>] ...
>FROM <表名或视图名> [，<表名或视图名>] |(<SELECT语句>)[AS]<别名>
>[WHERE <条件表达式>]
>[GROUP BY <列名1> [HAVING <条件表达式>]]
>[ORDER BY <列名2> [ASC|DESC]];

**含义为：**

* 根据WHERE子句的表达式从FROM子句指定的表中找出满足条件的元组，再按照SELECT子句中的目标表达式选出元组中的属性值形成结果表.
* 如果有GROUP BY表达式，则将结果按照<列名1>分组.HAVING 为输出指定条件的组.
* 如果有ORDER BY表达式，则将结果按照 <列名2>升序或者降序.

##### 3.1  单表查询：仅涉及一个表的查询

**WHERE常用的查询条件**

<table>
   <tr>
      <td>
         查询条件
      </td>
      <td>
         谓词
      </td>
   </tr>
   <tr>
      <td>
         比较
      </td>
      <td>
         =，>，<，>=，<=，!=，<>，!>，!<;NOT加上述比较符号
      </td>
   </tr>
   <tr>
      <td>
         确定范围
      </td>
      <td>
         BETWEEN AND， NOT BETWEEN AND
      </td>
   </tr>
   <tr>
      <td>
         确定集合
      </td>
      <td>
         IN， NOT IN
      </td>
   </tr>
   <tr>
      <td>
         字符匹配
      </td>
      <td>
         LIKE，NOT LIKE（%任意长度；_单个字符）
      </td>
   </tr>
   <tr>
      <td>
         空值
      </td>
      <td>
         IS NULL， IS NOT NULL
      </td>
   </tr>
   <tr>
      <td>
         多重条件（逻辑运算）
      </td>
      <td>
         AND， OR， NOT
      </td>
   </tr>
</table>




[例 3.1] 查询年龄在20岁以下的学生姓名和年龄
**SELECT Sname， Sage
　FROM Student
　WHERE Sage<20;**

##### 3.2 连接查询：涉及两个表以上的查询

[例3.2.1：等值与非等值连接查询] 查询每个学生及其选修课程的情况
**SELECT Student，SC.** 　　　　　　　 / /若把列中重复的属性列去掉改为自然连接：则为** 　**Student.Sno，Sname，Ssex，Sage，Sdpet，Cno，Grade** 　
　**FROM Student， SC**　　　　　　　　//容易混淆时，属性名前应该加前缀
　**WHERE Student.Sno=SC.Sno;**　　//将Student与SC中同一学生的元组连接起来

[例3.2.2：等值与非等值连接查询] 查询选修2号课程且成绩在90分以上的所有学生的学号和姓名
**SELECT Student.Sno，Sname
　FROM Student，SC
　WHERT Student.Sno=SC.Sno AND SC.Cno=’2’AND SC.Grade>90;**

[例3.2.3：自身连接] 查询每一门课的间接先修课（即先修课的先修课）
**SELECT FIRST.Cno，SECOND Cpno** //注意要编号
　**FROM Course FIRST.Course SECOND
　WHERE FIRST.Cpno=SECOND.Cno;**

[例3.2.4：外连接：将不满足条件的元组作为结果输出] 改进例3.2.1
**SELECT Student.Sno，Sname，Ssex，Sage，Sdpet，Cno，Grade
　FROM Student LEFT OUTER JOIN SC ON (Student.Sno=SC.Sno);**

[例3.2.5：多表连接] 查询每个学生的学号，姓名，选修课的课程名及成绩
**SELECT Student，Sno，Sname，Cname，Grade
　FROM Student，SC，Course
　WHERE Student.Sno=SC.SnoAND SC.Cno=Course.Cno;**

##### 3.3 嵌套查询

[例3.3.1：带有IN谓词的子查询]查询“刘晨”在同一个系学习的学生
首先确定“刘晨”所在的系名
**SELECT Sdept
　FROM Student
　WHERE Sname=’刘晨’；**
再确定CS系的学生
**SELECT Sno，Student，Sdept
　FROM Student
　WHERE Sdept=’CS’;**
最后第一步查询嵌入到第二步中
**SELECT Sno，Sname，Sdept
　FROM Student
　WEHRE Sdept IN
　(SELECT Sdept
　FROM Student
　WHERE Sname=’刘晨’
)；**
//子查询不依赖父查询，成为不相关子查询

[例3.2.2：带有比较运算符的子查询]　是相关子查询

[例3.2.3：带有ANY(SOME)或ALL谓词的子查询] ==略==

[例3.2.4：带有EXISTS谓词的子查询]　带有EXISTS谓词的子查询不返回数据，只返回真（内层不为空）和假（内层为空）.

[例5：基于派生表查询 ]==略==

#####  3.4 数据更新

[例3.4.1：插入数据INSERT]插入一条选课记录（‘201215128’，’1’）
**INSERT
 　INTO SC(Sno，Cno)
　 VALUES(‘201215128’，’1’)**

[例3.4.2：修改 数据UPDATE]将学生201215121的年龄改为22岁

**UPDATE Student
　 SET Sage=22
　 WHERE Sno=’201215121’;**
　 
[例3.4.3：删除数据DELETE]删除学号为201215128的学生记录
**DELETE
 　FROM Student
 　WHERE Sno=’201215128’;**

#### 4．视图

==略==

#### 5. [SQL连接查询](https://www.cnblogs.com/cthon/p/9075774.html)

**MySQL 连接的使用**

在前几章节中，我们已经学会了如何在一张表中读取数据，这是相对简单的，但是在真正的应用中经常需要从多个数据表中读取数据。

本章节我们将向大家介绍如何使用 MySQL 的 JOIN 在两个或多个表中查询数据。

你可以在 SELECT, UPDATE 和 DELETE 语句中使用 Mysql 的 JOIN 来联合多表查询。

JOIN 按照功能大致分为如下三类：

- **INNER JOIN（内连接,或等值连接）**：获取两个表中字段匹配关系的记录。
- **LEFT JOIN（左连接）：**获取左表所有记录，即使右表没有对应匹配的记录。
- **RIGHT JOIN（右连接）：** 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。

**在命令提示符中使用 INNER JOIN**

![img](https://www.runoob.com/wp-content/uploads/2014/03/img_innerjoin.gif)

~~~sql
mysql> SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author = b.runoob_author;
~~~

等价于：

~~~sql
mysql> SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a, tcount_tbl b WHERE a.runoob_author = b.runoob_author;
~~~

**MySQL LEFT JOIN**

MySQL left join 与 join 有所不同。 MySQL LEFT JOIN 会读取左边数据表的全部数据，即便右边表无对应数据。

![img](https://www.runoob.com/wp-content/uploads/2014/03/img_leftjoin.gif)



#### 6. 分页查询

LIMIT 子句可以被用于指定 SELECT 语句返回的记录数。需注意以下几点：

1、第一个参数指定第一个返回记录行的偏移量，注意从 0开始
2、第二个参数指定返回记录行的最大数目
3、如果只给定一个参数：它表示返回最大的记录行数目
4、第二个参数为 -1 表示检索从某一个偏移量到记录集的结束所有的记录行
5、初始记录行的偏移量是 0(而不是 1)

> https://blog.csdn.net/happypX/article/details/94504057
>
> https://www.jb51.net/article/109749.htm

在我们使用查询语句的时候，经常要返回前几条或者中间某几行数据，这个时候怎么办呢？不用担心，mysql已经为我们提供了这样一个功能。

~~~sql
SELECT * FROM table LIMIT [offset,] rows | rows OFFSET offset 
~~~

LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的`偏移量`，第二个参数指定返回记录行的最大数目。`初始记录行的偏移量是 0(而不是 1)`： 为了与 PostgreSQL 兼容，MySQL 也支持句法： LIMIT # OFFSET #。

~~~sql
mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15
~~~

为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1：

~~~sql
mysql> SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last.
~~~

如果只给定一个参数，它表示返回最大的记录行数目： 

~~~sql
mysql> SELECT * FROM table LIMIT 5; //检索前 5 个记录行
~~~

换句话说，`LIMIT n` 等价于` LIMIT 0,n`。

**Mysql的分页查询语句的性能分析**

MySql分页sql语句，如果和MSSQL的TOP语法相比，那么MySQL的LIMIT语法要显得优雅了许多。使用它来分页是再自然不过的事情了。

**最基本的分页方式：**

~~~sql
SELECT ... FROM ... WHERE ... ORDER BY ... LIMIT ...
~~~

在中小数据量的情况下，这样的SQL足够用了，唯一需要注意的问题就是确保使用了索引：举例来说，如果实际SQL类似下面语句，那么在category_id, id两列上建立复合索引比较好：

~~~sql
SELECT * FROM articles WHERE category_id = 123 ORDER BY id LIMIT 50, 10
~~~

**子查询的分页方式：**

随着数据量的增加，页数会越来越多，查看后几页的SQL就可能类似：

~~~sql
SELECT * FROM articles WHERE category_id = 123 ORDER BY id LIMIT 10000, 10
~~~

一言以蔽之，就是越往后分页，`LIMIT语句的偏移量就会越大，速度也会明显变慢`。

此时，我们可以通过子查询的方式来提高分页效率，大致如下：

~~~sql
SELECT * FROM articles WHERE id >= 
(SELECT id FROM articles WHERE category_id = 123 ORDER BY id LIMIT 10000, 1) LIMIT 10
~~~

**JOIN分页方式**

~~~sql
SELECT * FROM `content` AS t1 
JOIN (SELECT id FROM `content` ORDER BY id desc LIMIT ".($page-1)*$pagesize.", 1) AS t2 
WHERE t1.id <= t2.id ORDER BY t1.id desc LIMIT $pagesize;
~~~

经过我的测试，join分页和子查询分页的效率基本在一个等级上，消耗的时间也基本一致。 explain SQL语句：

~~~sql
id select_type table type possible_keys key key_len ref rows Extra
1 PRIMARY <derived2> system NULL NULL NULL NULL 1 
1 PRIMARY t1 range PRIMARY PRIMARY 4 NULL 6264 Using where
2 DERIVED content index NULL PRIMARY 4 NULL 27085 Using index
~~~

为什么会这样呢？因为**子查询是在索引上完成的，而普通的查询时在数据文件上完成的，通常来说，索引文件要比数据文件小得多，所以操作起来也会更有效率。**

实际可以利用类似**策略模式**的方式去处理分页，比如判断如果是一百页以内，就使用最基本的分页方式，大于一百页，则使用子查询的分页方式。

## 【MySQL命令脑图】

![20190305122455799](X:\Users\xu\Desktop\20190305122455799.png)



## 【MySQL学习日志】

~~~maysql
show tables;
show table status;
show  databases;
use community;
show databases;
use community;
show tables;
show columns FROM comment;
select * from comment;
select user_id from comment;
select distinct user_id from comment;
select distinct user_id from comment limit 1;
select distinct user_id from comment limit 2;
select distinct user_id from comment limit 2，3;
select distinct user_id from comment limit 2;
select distinct user_id from comment limit 2，3;
select  comment.user_id from comment;
select * from user;
select username from user;
select username from user order by username desc; 
select username from user where username='zzz';
select username from user where username<>'zzz';
select * from user;
select * from user where status between 0 and 1;
select * from user where type=0 and status=1;
select * from user where type =0 or status=1;
# 如果要列出价格为10美元以上并且由1002或1003制造的所有产品.
# select prod_name，prod_price from products where vend_id=1003 and pro_price>=10;
#以上错误 SQL语言优先处理and，必须使用优先级更高的()
# select prod_name，prod_price from products where (vend_id=1002 or vend_id=1003) and pro_price>=10;
# IN 操作符与or类似
# 通配符匹配字符串
select * from user where password like '_5%';
select * from user where salt regexp '\\5' order by username desc;
#6.11
#\\：匹配特殊字符 [:lower:]:匹配小写字母 ?使得g可选
select * from user where username regexp '[a-z]hang';
#匹配连在一起的3位数字 {}前要带[]
select * from user where id regexp '[[:digit:]]{3}' order by id;
#定位符
#创建计算字段 使用 concat可以对字段进行拼接
select Concat(username，password) from user order by id desc;
#使用数据处理函数 使用rtrim()可以去除列值右边的空格
# uppar()可以将文本转化为大写
# 汇总数据：
#聚集函数
#1.AVG()函数
select * from user;
select AVG(id) from user;
#2.COUNT()函数
select COUNT(id) from user;
#3.MAX()函数 MIN()函数
select MAX(id) from user;
select MIN(id) from user;
select id from user order by id desc;
#4.SUM()函数
select SUM(id) from user;
#使用别名，使用AS关键字
#数据分组，不适用group by只能查询一种salt的id数量
select count(id) AS num_id from user where salt ='49f10';
#根据行的某一列的值进行分组
select salt，count(id) AS num_id from user group by salt order by salt;
#having过滤分组，where过滤行
select salt，count(id) AS num_id from user group by  salt having count(id)>=2;
#子查询 IN
# 1.利用子查询进行过滤
select id from user;
select id from user where id in(1，11);
select username  from user where id in(select id from message where from_id ='1');
# 2.作为计算字段使用子查询
#相关子查询：涉及外部查询的子查询
#联结表：为什么要使用联结？
#https://www.runoob.com/mysql/mysql-join.html
# 等值联结
select * from user;
select * from comment;
select username，user_id from  user，comment where user.id=comment.id;
#在使用以下语法时，可以明确联结条件.
#MySQL left join 与 join 有所不同.
#MySQL LEFT JOIN 会读取左边数据表的全部数据，即便右边表无对应数据.
select username，user_id from user LEFT join comment on user.id=comment.id;
select username，user_id from  user，comment;
# 内部联结 INNER JOIN ON 可以明确指定联结的类型
# select返回
#联结多个表
# 高级联结
# union 组合查询
# 全文本搜索 什么是全文本搜索？
# 插入数据INSERT更新数数据UPADATE删除数据DELETE
select * from  user order by id desc;
INSERT INTO user(username)values('2118327937');
INSERT INTO user values('110');#必须有null去逐一匹配
UPDATE user SET username='1206512593@qq.com' where password='hello';
DELETE FROM user WHERE username='2118327937';
~~~

# MySQL练习题

https://www.jianshu.com/p/476b52ee4f1b

网上流传较广的50道SQL训练，奋斗了不知道多久终于写完了。前18道题的难度依次递增，从19题开始的后半部分算是循环练习和额外function的附加练习，难度恢复到普通状态。
 第9题非常难，我反正没有写出来，如果有写出来了的朋友还请赐教。
 这50道里面自认为应该没有太多错误，而且尽可能使用了最简单或是最直接的查询，有多种不相上下解法的题目我也都列出了，但也欢迎一起学习的朋友进行讨论和解法优化啊~

------

数据表介绍

1. 学生表 Student(SId,Sname,Sage,Ssex)
   SId 学生编号,Sname 学生姓名,Sage 出生年月,Ssex 学生性别

2. 课程表 Course(CId,Cname,TId)
   CId 课程编号,Cname 课程名称,TId 教师编号

3. 教师表Teacher(TId,Tname)
   TId 教师编号,Tname 教师姓名

4. 成绩表SC(SId,CId,score)
   SId 学生编号,CId 课程编号,score 分数

**学生表 Student**

```csharp
create table Student(SId varchar(10),Sname varchar(10),Sage datetime,Ssex varchar(10));
insert into Student values('01' , '赵雷' , '1990-01-01' , '男');
insert into Student values('02' , '钱电' , '1990-12-21' , '男');
insert into Student values('03' , '孙风' , '1990-12-20' , '男');
insert into Student values('04' , '李云' , '1990-12-06' , '男');
insert into Student values('05' , '周梅' , '1991-12-01' , '女');
insert into Student values('06' , '吴兰' , '1992-01-01' , '女');
insert into Student values('07' , '郑竹' , '1989-01-01' , '女');
insert into Student values('09' , '张三' , '2017-12-20' , '女');
insert into Student values('10' , '李四' , '2017-12-25' , '女');
insert into Student values('11' , '李四' , '2012-06-06' , '女');
insert into Student values('12' , '赵六' , '2013-06-13' , '女');
insert into Student values('13' , '孙七' , '2014-06-01' , '女');
```

**科目表 Course**

```csharp
create table Course(CId varchar(10),Cname nvarchar(10),TId varchar(10));
insert into Course values('01' , '语文' , '02');
insert into Course values('02' , '数学' , '01');
insert into Course values('03' , '英语' , '03');
```

教师表 Teacher

```csharp
create table Teacher(TId varchar(10),Tname varchar(10));
insert into Teacher values('01' , '张三');
insert into Teacher values('02' , '李四');
insert into Teacher values('03' , '王五');
```

成绩表 SC

```csharp
create table SC(SId varchar(10),CId varchar(10),score decimal(18,1));
insert into SC values('01' , '01' , 80);
insert into SC values('01' , '02' , 90);
insert into SC values('01' , '03' , 99);
insert into SC values('02' , '01' , 70);
insert into SC values('02' , '02' , 60);
insert into SC values('02' , '03' , 80);
insert into SC values('03' , '01' , 80);
insert into SC values('03' , '02' , 80);
insert into SC values('03' , '03' , 80);
insert into SC values('04' , '01' , 50);
insert into SC values('04' , '02' , 30);
insert into SC values('04' , '03' , 20);
insert into SC values('05' , '01' , 76);
insert into SC values('05' , '02' , 87);
insert into SC values('06' , '01' , 31);
insert into SC values('06' , '03' , 34);
insert into SC values('07' , '02' , 89);
insert into SC values('07' , '03' , 98);
```

------

#### 1. 练习题目

1. **查询" 01 "课程比" 02 "课程成绩高的学生的信息及课程分数**

   ~~~mysql
   # 查询" 01 "课程比" 02 "课程成绩高的学生的信息及课程分数
   # as的意思为命名
   # r的意思为命名
   select * from Student RIGHT JOIN (
       select t1.SId, class1, class2 from
             (select SId, score as class1 from sc where sc.CId = '01') as t1, 
             (select SId, score as class2 from sc where sc.CId = '02') as t2
       where t1.SId = t2.SId AND t1.class1 > t2.class2
   )r 
   on Student.SId = r.SId;
   ~~~

**1.1 查询同时存在" 01 "课程和" 02 "课程的情况**

~~~mysql
# 查询同时存在" 01 "课程和" 02 "课程的情况
select * from 
    (select * from sc where sc.CId = '01') as t1, 
    (select * from sc where sc.CId = '02') as t2
where t1.SId = t2.SId;
~~~

1.2 **查询存在" 01 "课程但可能不存在" 02 "课程的情况(不存在时显示为 null )**

~~~mysql
select * from 
(select * from sc where sc.CId = '01') as t1
left join 
(select * from sc where sc.CId = '02') as t2
on t1.SId = t2.SId;
~~~

1.3 查询不存在" 01 "课程但存在" 02 "课程的情况

~~~mysql
#查询不存在" 01 "课程但存在" 02 "课程的情况
select * from sc
where sc.SId not in (
    select SId from sc 
    where sc.CId = '01'
) 
AND sc.CId= '02';
~~~

1. 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩

~~~mysql
#查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩
#这里只用根据学生ID把成绩分组，对分组中的score求平均值，最后在选取结果中AVG大于60的即可. 注意，这里必须要给计算得到的AVG结果一个alias.（AS ss）
#得到学生信息的时候既可以用join也可以用一般的联合搜索
select Student.SId, Student.Sname, r.ss from Student right join(
      select SId, AVG(score) AS ss from sc
      GROUP BY SId
      HAVING AVG(score)> 60
)r on Student.SId = r.SId;
~~~

1. 查询在 SC 表存在成绩的学生信息

~~~mysql
#查询在 SC 表存在成绩的学生信息
select DISTINCT student.* from student join sc on student.SId =SC.SId; 
#DISTINCT去重
~~~

1. 查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null )

~~~mysql
#查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩(没成绩的显示为 null )
select student.sid, student.sname,r.coursenumber,r.scoresum
from student,
(select sc.sid, sum(sc.score) as scoresum, count(sc.cid) as coursenumber from sc 
group by sc.sid) as r
where student.sid = r.sid;
~~~

4.1 查有成绩的学生信息

~~~mysql
# 查有成绩的学生信息
select distinct student.* from student,sc where student.sid=sc.sid; 
select * from student
where student.sid in (select sc.sid from sc);
~~~

1. 查询「李」姓老师的数量

   ~~~mysql
   #查询「李」姓老师的数量
   select count(tid) as count_tid from teacher group by tname having tname like "李%";
   #y由于教师表中「李」姓老师不重复
   select count(*)
   from teacher
   where tname like '李%';
   ~~~

2. 查询学过「张三」老师授课的同学的信息

   ~~~mysql
   #查询学过「张三」老师授课的同学的信息
   select student.* from student,teacher,course,sc
   where 
       student.sid = sc.sid 
       and course.cid=sc.cid 
       and course.tid = teacher.tid 
       and tname = '张三';
   ~~~

3. 查询没有学全所有课程的同学的信息

   ~~~mysql
   #查询没有学全所有课程的同学的信息
   select * from student 
   where student.sid not in(
      select sc.sid from sc
      group by sc.sid
      having count(sc.cid)=(select count(cid) from course)
   );
   ~~~

4. 查询至少有一门课与学号为" 01 "的同学所学相同的同学的信息

   ~~~mysql
   #查询至少有一门课与学号为" 01 "的同学所学相同的同学的信息
   select * from student 
   where student.sid in (
       select sc.sid from sc 
       where sc.cid in(
           select sc.cid from sc 
           where sc.sid = '01'
       )
   );
   ~~~

5. 查询和" 01 "号的同学学习的课程   完全相同的其他同学的信息

6. 查询没学过"张三"老师讲授的任一门课程的学生姓名

   ~~~mysql
   #查询没学过"张三"老师讲授的任一门课程的学生姓名
   select distinct student.sname from student where student.sid not in(
   select  sc.sid from sc where sc.cid in(
   select course.cid from
   course where course.tid in(
   select teacher.tid from teacher where teacher.tname="张三"
   )
   )
   );
   #题解
   select * from student
       where student.sid not in(
           select sc.sid from sc where sc.cid in(
               select course.cid from course where course.tid in(
                   select teacher.tid from teacher where tname = "张三"
               )
           )
       );
   #联合查询
   select * from student
   where student.sid not in(
       select sc.sid from sc,course,teacher 
       where
           sc.cid = course.cid
           and course.tid = teacher.tid
           and teacher.tname= "张三"
   );
   ~~~

7. 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩

   ~~~mysql
   # 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩
   select student.sid,student.sname,avg(sc.score) from 
   student,sc 
   where student.sid=sc.sid and sc.score<60
   group by sc.sid 
   having count(*)>1;
   
   select student.sid, student.sname, AVG(sc.score) from student,sc
   where 
       student.sid = sc.sid and sc.score<60
   group by sc.sid 
   having count(*)>1;
   ~~~

   

8. 检索" 01 "课程分数小于 60，按分数降序排列的学生信息

   ~~~mysql
   # 检索" 01 "课程分数小于 60，按分数降序排列的学生信息
   select distinct student.* from student,sc where student.sid=sc.sid and sc.cid="01" and  sc.score<60 order by sc.score desc;
   select student.*, sc.score from student, sc
   where student.sid = sc.sid
   and sc.score < 60
   and cid = "01"
   ORDER BY sc.score DESC;
   ~~~

9. 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩

   ~~~mysql
   # 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩
   select * from sc left join (
   select sc.sid,avg(sc.score) as avg_score from sc
   group by sid)r
   on sc.sid=r.sid
   order by avg_score desc;
   ~~~

   

10. 查询各科成绩最高分、最低分和平均分：

    ~~~mysql
    # 查询各科成绩最高分、最低分和平均分
    select sc.cid, max(sc.score) as score_max, min(sc.score) as score_min,avg(sc.score) as score_avg
    from sc group by sc.cid;
    ~~~

以如下形式显示：课程 ID，课程 name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率

及格为>=60，中等为：70-80，优良为：80-90，优秀为：>=90



要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列

1. 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺

15.1 按各科成绩进行排序，并显示排名， Score 重复时合并名次

1. 查询学生的总成绩，并进行排名，总分重复时保留名次空缺

16.1 查询学生的总成绩，并进行排名，总分重复时不保留名次空缺

1. 统计各科成绩各分数段人数：课程编号，课程名称，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比
2. 查询各科成绩前三名的记录
3. 查询每门课程被选修的学生数
4. 查询出只选修两门课程的学生学号和姓名
5. 查询男生、女生人数
6. 查询名字中含有「风」字的学生信息
7. 查询同名同性学生名单，并统计同名人数
8. 查询 1990 年出生的学生名单
9. 查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列
10. 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩
11. 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数
12. 查询所有学生的课程及分数情况（存在学生没成绩，没选课的情况）
13. 查询任何一门课程成绩在 70 分以上的姓名、课程名称和分数
14. 查询不及格的课程
15. 查询课程编号为 01 且课程成绩在 80 分以上的学生的学号和姓名
16. 求每门课程的学生人数
17. 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩
18. 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩
19. 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩
20. 查询每门功成绩最好的前两名
21. 统计每门课程的学生选修人数（超过 5 人的课程才统计）。
22. 检索至少选修两门课程的学生学号
23. 查询选修了全部课程的学生信息
24. 查询各学生的年龄，只按年份来算
25. 按照出生日期来算，当前月日 < 出生年月的月日则，年龄减一
26. 查询本周过生日的学生
27. 查询下周过生日的学生
28. 查询本月过生日的学生
29. 查询下月过生日的学生

#### 2.答案

------

1.查询" 01 "课程比" 02 "课程成绩高的学生的信息及课程分数
 因为需要全部的学生信息，则需要在sc表中得到符合条件的SId后与student表进行join，可以left join 也可以 right join



```csharp
select * from Student RIGHT JOIN (
    select t1.SId, class1, class2 from
          (select SId, score as class1 from sc where sc.CId = '01')as t1, 
          (select SId, score as class2 from sc where sc.CId = '02')as t2
    where t1.SId = t2.SId AND t1.class1 > t2.class2
)r 
on Student.SId = r.SId;
```



```csharp
select * from  (
    select t1.SId, class1, class2 
    from
        (SELECT SId, score as class1 FROM sc WHERE sc.CId = '01') AS t1, 
        (SELECT SId, score as class2 FROM sc WHERE sc.CId = '02') AS t2
    where t1.SId = t2.SId and t1.class1 > t2.class2
) r 
LEFT JOIN Student
ON Student.SId = r.SId;
```

1.1 查询同时存在" 01 "课程和" 02 "课程的情况



```csharp
select * from 
    (select * from sc where sc.CId = '01') as t1, 
    (select * from sc where sc.CId = '02') as t2
where t1.SId = t2.SId;
```

1.2 查询存在" 01 "课程但可能不存在" 02 "课程的情况(不存在时显示为 null )
 这一道就是明显需要使用join的情况了，02可能不存在，即为left join的右侧或right join 的左侧即可.



```csharp
select * from 
(select * from sc where sc.CId = '01') as t1
left join 
(select * from sc where sc.CId = '02') as t2
on t1.SId = t2.SId;
```



```csharp
select * from 
(select * from sc where sc.CId = '02') as t2
right join 
(select * from sc where sc.CId = '01') as t1
on t1.SId = t2.SId;
```

1.3 查询不存在" 01 "课程但存在" 02 "课程的情况

```csharp
select * from sc
where sc.SId not in (
    select SId from sc 
    where sc.CId = '01'
) 
AND sc.CId= '02';
```

1. 查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩
   这里只用根据学生ID把成绩分组，对分组中的score求平均值，最后在选取结果中AVG大于60的即可. 注意，这里必须要给计算得到的AVG结果一个alias.（AS ss）
   得到学生信息的时候既可以用join也可以用一般的联合搜索



```csharp
select student.SId,sname,ss from student,(
    select SId, AVG(score) as ss from sc  
    GROUP BY SId 
    HAVING AVG(score)> 60
    )r
where student.sid = r.sid;
```



```csharp
select Student.SId, Student.Sname, r.ss from Student right join(
      select SId, AVG(score) AS ss from sc
      GROUP BY SId
      HAVING AVG(score)> 60
)r on Student.SId = r.SId;
```



```csharp
select s.SId,ss,Sname from(
select SId, AVG(score) as ss from sc  
GROUP BY SId 
HAVING AVG(score)> 60
)r left join 
(select Student.SId, Student.Sname from
Student)s on s.SId = r.SId;
```

1. 查询在 SC 表存在成绩的学生信息



```csharp
select DISTINCT student.*
from student,sc
where student.SId=sc.SId
```

4.查询所有同学的学生编号、学生姓名、选课总数、所有课程的成绩总和
 联合查询不会显示没选课的学生：



```csharp
select student.sid, student.sname,r.coursenumber,r.scoresum
from student,
(select sc.sid, sum(sc.score) as scoresum, count(sc.cid) as coursenumber from sc 
group by sc.sid)r
where student.sid = r.sid;
```

如要显示没选课的学生(显示为NULL)，需要使用join:



```csharp
select s.sid, s.sname,r.coursenumber,r.scoresum
from (
    (select student.sid,student.sname 
    from student
    )s 
    left join 
    (select 
        sc.sid, sum(sc.score) as scoresum, count(sc.cid) as coursenumber
        from sc 
        group by sc.sid
    )r 
   on s.sid = r.sid
);
```

4.1 查有成绩的学生信息
 这一题涉及到in和exists的用法，在这种小表中，两种方法的效率都差不多，但是请参考[SQL查询中in和exists的区别分析](https://www.jianshu.com/p/f212527d76ff)
 当表2的记录数量非常大的时候，选用exists比in要高效很多.
 EXISTS用于检查子查询是否至少会返回一行数据，该子查询实际上并不返回任何数据，而是返回值True或False.
 结论：IN()适合B表比A表数据小的情况
 结论：EXISTS()适合B表比A表数据大的情况



```csharp
select * from student 
where exists (select sc.sid from sc where student.sid = sc.sid);
```



```csharp
select * from student
where student.sid in (select sc.sid from sc);
```

1. 查询「李」姓老师的数量



```csharp
select count(*)
from teacher
where tname like '李%';
```

1. 查询学过「张三」老师授课的同学的信息
   多表联合查询



```csharp
select student.* from student,teacher,course,sc
where 
    student.sid = sc.sid 
    and course.cid=sc.cid 
    and course.tid = teacher.tid 
    and tname = '张三';
```

1. 查询没有学全所有课程的同学的信息
   因为有学生什么课都没有选，反向思考，先查询选了所有课的学生，再选择这些人之外的学生.



```csharp
select * from student
where student.sid not in (
  select sc.sid from sc
  group by sc.sid
  having count(sc.cid)= (select count(cid) from course)
);
```

1. 查询至少有一门课与学号为" 01 "的同学所学相同的同学的信息
   这个用联合查询也可以，但是逻辑不清楚，我觉得较为清楚的逻辑是这样的：从sc表查询01同学的所有选课cid--从sc表查询所有同学的sid如果其cid在前面的结果中--从student表查询所有学生信息如果sid在前面的结果中



```csharp
select * from student 
where student.sid in (
    select sc.sid from sc 
    where sc.cid in(
        select sc.cid from sc 
        where sc.sid = '01'
    )
);
```

9.查询和" 01 "号的同学学习的课程完全相同的其他同学的信息
 不会做。



```undefined

```

10.查询没学过"张三"老师讲授的任一门课程的学生姓名
 仍然还是嵌套，三层嵌套， 或者多表联合查询



```csharp
select * from student
    where student.sid not in(
        select sc.sid from sc where sc.cid in(
            select course.cid from course where course.tid in(
                select teacher.tid from teacher where tname = "张三"
            )
        )
    );
```



```csharp
select * from student
where student.sid not in(
    select sc.sid from sc,course,teacher 
    where
        sc.cid = course.cid
        and course.tid = teacher.tid
        and teacher.tname= "张三"
);
```

11.查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩
 从SC表中选取score小于60的，并group by sid，having count 大于1



```csharp
select student.sid, student.sname, AVG(sc.score) from student,sc
where 
    student.sid = sc.sid and sc.score<60
group by sc.sid 
having count(*)>1;
```

1. 检索" 01 "课程分数小于 60，按分数降序排列的学生信息
   双表联合查询，在查询最后可以设置排序方式，语法为ORDER BY ***** DESC\ASC;



```csharp
select student.*, sc.score from student, sc
where student.sid = sc.sid
and sc.score < 60
and cid = "01"
ORDER BY sc.score DESC;
```

1. 按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩



```csharp
select *  from sc 
left join (
    select sid,avg(score) as avscore from sc 
    group by sid
    )r 
on sc.sid = r.sid
order by avscore desc;
```

1. 查询各科成绩最高分、最低分和平均分：

以如下形式显示：课程 ID，课程 name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率

及格为>=60，中等为：70-80，优良为：80-90，优秀为：>=90

要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列



```swift
select 
sc.CId ,
max(sc.score)as 最高分,
min(sc.score)as 最低分,
AVG(sc.score)as 平均分,
count(*)as 选修人数,
sum(case when sc.score>=60 then 1 else 0 end )/count(*)as 及格率,
sum(case when sc.score>=70 and sc.score<80 then 1 else 0 end )/count(*)as 中等率,
sum(case when sc.score>=80 and sc.score<90 then 1 else 0 end )/count(*)as 优良率,
sum(case when sc.score>=90 then 1 else 0 end )/count(*)as 优秀率 
from sc
GROUP BY sc.CId
ORDER BY count(*)DESC, sc.CId ASC
```

1. 按各科成绩进行排序，并显示排名， Score 重复时保留名次空缺
   这一道题有点tricky，可以用变量，但也有更为简单的方法，即自交（左交）
   用sc中的score和自己进行对比，来计算“比当前分数高的分数有几个”。



```csharp
select a.cid, a.sid, a.score, count(b.score)+1 as rank
from sc as a 
left join sc as b 
on a.score<b.score and a.cid = b.cid
group by a.cid, a.sid,a.score
order by a.cid, rank ASC;
```

1. 查询学生的总成绩，并进行排名，总分重复时不保留名次空缺
   这里主要学习一下使用变量。在SQL里面变量用@来标识。



```csharp
set @crank=0;
select q.sid, total, @crank := @crank +1 as rank from(
select sc.sid, sum(sc.score) as total from sc
group by sc.sid
order by total desc)q;
```

1. 统计各科成绩各分数段人数：课程编号，课程名称，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比
   有时候觉得自己真是死脑筋。group by以后的查询结果无法使用别名，所以不要想着先单表group by计算出结果再从第二张表里添上课程信息，而应该先将两张表join在一起得到所有想要的属性再对这张总表进行统计计算。这里就不算百分比了，道理相同。
   注意一下，用case when 返回1 以后的统计不是用count而是sum



```csharp
select course.cname, course.cid,
sum(case when sc.score<=100 and sc.score>85 then 1 else 0 end) as "[100-85]",
sum(case when sc.score<=85 and sc.score>70 then 1 else 0 end) as "[85-70]",
sum(case when sc.score<=70 and sc.score>60 then 1 else 0 end) as "[70-60]",
sum(case when sc.score<=60 and sc.score>0 then 1 else 0 end) as "[60-0]"
from sc left join course
on sc.cid = course.cid
group by sc.cid;
```

1. 查询各科成绩前三名的记录
   大坑比。mysql不能group by 了以后取limit，所以不要想着讨巧了，我快被这一题气死了。思路有两种，第一种比较暴力，计算比自己分数大的记录有几条，如果小于3 就select，因为对前三名来说不会有3个及以上的分数比自己大了，最后再对所有select到的结果按照分数和课程编号排名即可。



```csharp
select * from sc
where (
select count(*) from sc as a 
where sc.cid = a.cid and sc.score<a.score 
)< 3
order by cid asc, sc.score desc;
```

第二种比较灵巧一些，用自身左交，但是有点难以理解。
 先用自己交自己，条件为a.cid = b.cid and a.score<b.score，其实就是列出同一门课内所有分数比较的情况。
 想要查看完整的表可以



```csharp
select * from sc a 
left join sc b on a.cid = b.cid and a.score<b.score
order by a.cid,a.score;
```

![img](https:////upload-images.jianshu.io/upload_images/42676-2670692dd66e33cd.png?imageMogr2/auto-orient/strip|imageView2/2/w/734/format/webp)

结果

查看，发现结果是47行的一个表，列出了类似 01号课里“30分小于50，也小于70，也小于80，也小于90”“50分小于70，小于80，小于90”.....
 所以理论上，对任何一门课来说，分数最高的那三个记录，在这张大表里，通过a.sid和a.cid可以联合确定这个同学的这门课的这个分数究竟比多少个其他记录高/低，
 如果这个特定的a.sid和a.cid组合出现在这张表里的次数少于3个，那就意味着这个组合（学号+课号+分数）是这门课里排名前三的。
 所以下面这个计算中having count 部分其实count(*)或者任意其他列都可以，这里制定了一个列只是因为比count(*)运行速度上更快。



```csharp
select a.sid,a.cid,a.score from sc a 
left join sc b on a.cid = b.cid and a.score<b.score
group by a.cid, a.sid
having count(b.cid)<3
order by a.cid;
```

1. 查询每门课程被选修的学生数



```csharp
select cid, count(sid) from sc 
group by cid;
```

1. 查询出只选修两门课程的学生学号和姓名
   嵌套查询



```csharp
select student.sid, student.sname from student
where student.sid in
(select sc.sid from sc
group by sc.sid
having count(sc.cid)=2
);
```

联合查询



```csharp
select student.SId,student.Sname
from sc,student
where student.SId=sc.SId  
GROUP BY sc.SId
HAVING count(*)=2；
```

21.查询男生、女生人数



```csharp
select ssex, count(*) from student
group by ssex;
```

1. 查询名字中含有「风」字的学生信息



```csharp
select *
from student 
where student.Sname like '%风%'
```

23.查询同名学生名单，并统计同名人数
 找到同名的名字并统计个数



```csharp
select sname, count(*) from student
group by sname
having count(*)>1;
```

嵌套查询列出同名的全部学生的信息



```csharp
select * from student
where sname in (
select sname from student
group by sname
having count(*)>1
);
```

24.查询 1990 年出生的学生名单



```csharp
select *
from student
where YEAR(student.Sage)=1990;
```

25.查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列



```csharp
select sc.cid, course.cname, AVG(SC.SCORE) as average from sc, course
where sc.cid = course.cid
group by sc.cid 
order by average desc,cid asc;
```

26.查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩
 having也可以用来截取结果表，在这里就先得到平均成绩总表，再截取AVG大于85的即可.



```csharp
select student.sid, student.sname, AVG(sc.score) as aver from student, sc
where student.sid = sc.sid
group by sc.sid
having aver > 85;
```

1. 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数



```csharp
select student.sname, sc.score from student, sc, course
where student.sid = sc.sid
and course.cid = sc.cid
and course.cname = "数学"
and sc.score < 60;
```

1. 查询所有学生的课程及分数情况（存在学生没成绩，没选课的情况）



```csharp
select student.sname, cid, score from student
left join sc
on student.sid = sc.sid;
```

1. 查询任何一门课程成绩在 70 分以上的姓名、课程名称和分数



```csharp
select student.sname, course.cname,sc.score from student,course,sc
where sc.score>70
and student.sid = sc.sid
and sc.cid = course.cid;
```

30.查询存在不及格的课程
 可以用group by 来取唯一，也可以用distinct



```csharp
select cid from sc
where score< 60
group by cid;
```



```csharp
select DISTINCT sc.CId
from sc
where sc.score <60;
```

31.查询课程编号为 01 且课程成绩在 80 分及以上的学生的学号和姓名



```csharp
select student.sid,student.sname 
from student,sc
where cid="01"
and score>=80
and student.sid = sc.sid;
```

1. 求每门课程的学生人数



```csharp
select sc.CId,count(*) as 学生人数
from sc
GROUP BY sc.CId;
```

1. 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩
   用having max()理论上也是对的，但是下面那种按分数排序然后取limit 1的更直观可靠



```csharp
select student.*, sc.score, sc.cid from student, teacher, course,sc 
where teacher.tid = course.tid
and sc.sid = student.sid
and sc.cid = course.cid
and teacher.tname = "张三"
having max(sc.score);
```



```csharp
select student.*, sc.score, sc.cid from student, teacher, course,sc 
where teacher.tid = course.tid
and sc.sid = student.sid
and sc.cid = course.cid
and teacher.tname = "张三"
order by score desc
limit 1;
```

1. 成绩有重复的情况下，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩
   为了验证这一题，先修改原始数据



```bash
UPDATE sc SET score=90
where sid = "07"
and cid ="02";
```

这样张三老师教的02号课就有两个学生同时获得90的最高分了。
 这道题的思路继续上一题，我们已经查询到了符合限定条件的最高分了，这个时候只用比较这张表，找到全部score等于这个最高分的记录就可，看起来有点繁复。



```csharp
select student.*, sc.score, sc.cid from student, teacher, course,sc 
where teacher.tid = course.tid
and sc.sid = student.sid
and sc.cid = course.cid
and teacher.tname = "张三"
and sc.score = (
    select Max(sc.score) 
    from sc,student, teacher, course
    where teacher.tid = course.tid
    and sc.sid = student.sid
    and sc.cid = course.cid
    and teacher.tname = "张三"
);
```

1. 查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩
   同上，在这里用了inner join后会有概念是重复的记录：“01 课与 03课”=“03 课与 01 课”，所以这里取唯一可以直接用group by



```csharp
select  a.cid, a.sid,  a.score from sc as a
inner join 
sc as b
on a.sid = b.sid
and a.cid != b.cid
and a.score = b.score
group by cid, sid;
```

36.查询每门功成绩最好的前两名
 同上19题



```csharp
select a.sid,a.cid,a.score from sc as a 
left join sc as b 
on a.cid = b.cid and a.score<b.score
group by a.cid, a.sid
having count(b.cid)<2
order by a.cid;
```

37.统计每门课程的学生选修人数（超过 5 人的课程才统计）



```csharp
select sc.cid, count(sid) as cc from sc
group by cid
having cc >5;
```

38.检索至少选修两门课程的学生学号



```csharp
select sid, count(cid) as cc from sc
group by sid
having cc>=2;
```

1. 查询选修了全部课程的学生信息



```csharp
select student.*
from sc ,student 
where sc.SId=student.SId
GROUP BY sc.SId
HAVING count(*) = (select DISTINCT count(*) from course )
```

40.查询各学生的年龄，只按年份来算
 不想做，一般都用41题的方法精确到天



1. 按照出生日期来算，当前月日 < 出生年月的月日则，年龄减一



```csharp
select student.SId as 学生编号,student.Sname  as  学生姓名,
TIMESTAMPDIFF(YEAR,student.Sage,CURDATE()) as 学生年龄
from student
```

42.查询本周过生日的学生



```csharp
select *
from student 
where WEEKOFYEAR(student.Sage)=WEEKOFYEAR(CURDATE());
```

1. 查询下周过生日的学生



```csharp
select *
from student 
where WEEKOFYEAR(student.Sage)=WEEKOFYEAR(CURDATE())+1;
```

44.查询本月过生日的学生



```csharp
select *
from student 
where MONTH(student.Sage)=MONTH(CURDATE());
```

45.查询下月过生日的学生

```csharp
select *
from student 
where MONTH(student.Sage)=MONTH(CURDATE())+1;
```

#### 3. mysql中如何查看sql语句是否用到索引

1、操作步骤
1.1 使用explain ，放在sql前面
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190814174824522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTMxMDE3OQ==,size_16,color_FFFFFF,t_70)
2、解释
我们只需要注意一个最重要的type 的信息很明显的提现是否用到索引：

type结果值从好到坏依次是：

system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL

一般来说，得保证查询至少达到range级别，最好能达到ref，否则就可能会出现性能问题。

possible_keys：sql所用到的索引

key：显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL

rows: 显示MySQL认为它执行查询时必须检查的行数

#### 4.mysql查询什么时候用on什么时候用where？

https://blog.csdn.net/cheyuan4575/article/details/100720316

数据库在通过连接两张或多张表来返回记录时，都会生成一张中间的临时表，然后再将这张临时表返回给用户。

   在使用left jion时，on和where条件的区别如下：

1、 on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。

2、where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。

   假设有两张表：

表1：tab2

| id   | size |
| ---- | ---- |
| 1    | 10   |
| 2    | 20   |
| 3    | 30   |

表2：tab2

| size | name |
| ---- | ---- |
| 10   | AAA  |
| 20   | BBB  |
| 20   | CCC  |


两条SQL:
1、select * form tab1 left join tab2 on (tab1.size = tab2.size) where tab2.name=’AAA’
2、select * form tab1 left join tab2 on (tab1.size = tab2.size and tab2.name=’AAA’)

第一条SQL的过程：1、中间表 on条件: tab1.size = tab2.sizetab1.idtab1.sizetab2.sizetab2.name11010AAA22020BBB22020CCC330(null)(null)||2、再对中间表过滤 where 条件： tab2.name=’AAA’tab1.idtab1.sizetab2.sizetab2.name11010AAA 

 

第二条SQL的过程：1、中间表 on条件: tab1.size = tab2.size and tab2.name=’AAA’ (条件不为真也会返回左表中的记录)tab1.idtab1.sizetab2.sizetab2.name11010AAA220(null)(null)330(null)(null)

   其实以上结果的关键原因就是left join,right join,full join的特殊性，**不管on上的条件是否为真都会返回left或right表中的记录**，full则具有left和right的特性的并集。 而inner jion没这个特殊性，则条件放在on中和where中，返回的结果集是相同的。

on、where、having的区别

 

on、where、having这三个都可以加条件的子句中，on是最先执行，where次之，having最后。有时候如果这先后顺序不影响中间结果的话，那最终结果是相同的。但因为on是先把不符合条件的记录过滤后才进行统计，它就可以减少中间运算要处理的数据，按理说应该速度是最快的。        根据上面的分析，可以知道where也应该比having快点的，因为它过滤数据后才进行sum，所以having是最慢的。但也不是说having没用，因为有时在步骤3还没出来都不知道那个记录才符合要求时，就要用having了。        在两个表联接时才用on的，所以在一个表的时候，就剩下where跟having比较了。在这单表查询统计的情况下，如果要过滤的条件没有涉及到要计算字段，那它们的结果是一样的，只是where可以使用rushmore技术，而having就不能，在速度上后者要慢。        如果要涉及到计算的字段，就表示在没计算之前，这个字段的值是不确定的，根据上篇写的工作流程，where的作用时间是在计算之前就完成的，而having就是在计算后才起作用的，所以在这种情况下，两者的结果会不同。        在多表联接查询时，on比where更早起作用。系统首先根据各个表之间的联接条件，把多个表合成一个临时表后，再由where进行过滤，然后再计算，计算完后再由having进行过滤。由此可见，要想过滤条件起到正确的作用，首先要明白这个条件应该在什么时候起作用，然后再决定放在那里 JOIN联表中ON,WHERE后面跟条件的区别对于JOIN的连表操作，这里就不细述了，当我们在对表进行JOIN关联操作时，对于ON和WHERE后面的条件，不清楚大家有没有注意过，有什么区别，可能有的朋友会认为跟在它们后面的条件是一样的，你可以跟在ON后面，如果愿意，也可以跟在WHERE后面。它们在ON和WHERE后面究竟有一个什么样的区别呢？在JOIN操作里，有几种情况。LEFT JOIN,RIGHT JOIN,INNER JOIN等。为了清楚的表达主题所描述的问题，我简要的对LEFT,RIGHT,INNER这几种连接方式作一个说明。下面就拿一个普通的博客系统的日志表(post)和分类表(category)来描述吧。这里我们规定有的日志可能没有分类，有的分类可能目前没有属于它的文章。1.  LEFT JOIN:（保证找出左联表中的所有行）查出所有文章，并显示出他们的分类：`SELECT p.title,c.category_name FROM post p LEFT JOIN category c ON p.cid = c.cid`2.  RIGHT JOIN:（保证找出右联表中的所有行）查询所有的分类，并显示出该分类所含有的文章数。`SELECT COUNT(p.id),c.category_name FROM post p RIGHTJOIN  category c ON p.pid = c.cid`3.  INNER JOIN（找出两表中关联相等的行）查询有所属分类的日志。（即那些没有所性分类的日志文章将不要我们的查询范围之内）。`SELECT p.title,c.category_name FROM post p INNER JOIN category c ON p.cid = c.cid.`这种情况和直接两表硬关联等价。现在我们回过头来看上面的问题。对于第一种情况，如果我们所ON 的条件写在WHERE 后面，将会出现什么情况呢？即：`SELECT p.title,c.category_name FROM post p LEFT JOIN category c WHERE  p.cid = c.cid`对于第二种情况，我们同样按照上面的书写方式。`SELECT COUNT(p.id),c.category_name FROM post p RIGHTJOIN  category c WHERE p.pid = c.cid`如果运行上面的SQL语句，就会发现，它们已经过滤掉了一些不满足条件的记录，可能在这里，大家会产生疑问了，不是用了LEFT和RIGHT吗？它们可以保证左边或者右边的所有行被全部查询出来，为什么现在不管用了呢？对于出现这种的问题，呵呵！是不是觉得有些不可思议。出现这种的问题，原因就在WHERE和ON这两个关键字后面跟条件。好了，现在我也不调大家味口了，给大家提示答案吧。对于JOIN参与的表的关联操作，如果需要不满足连接条件的行也在我们的查询范围内的话，我们就必需把连接条件放在ON后面，而不能放在WHERE后面，如果我们把连接条件放在了WHERE后面，那么所有的LEFT,RIGHT,等这些操作将不起任何作用，对于这种情况，它的效果就完全等同于INNER连接。对于那些不影响选择行的条件，放在ON或者WHERE后面就可以。记住：所有的连接条件都必需要放在ON后面，不然前面的所有LEFT,和RIGHT关联将作为摆设，而不起任何作用。

#### 5.on、where、having的区别

on、where、having这三个都可以加条件的子句中，**on是最先执行，where次之，having最后**。有时候如果这先后顺序不影响中间结果的话，那最终结果是相同的。但因为on是先把不符合条件的记录过滤后才进行统计，它就可以减少中间运算要处理的数据，按理说应该速度是最快的。  

  根据上面的分析，可以知道where也应该比having快点的，因为它过滤数据后才进行sum，所以having是最慢的。但也不是说having没用，因为有时在步骤3还没出来都不知道那个记录才符合要求时，就要用having了。  

  在两个表联接时才用on的，所以在一个表的时候，就剩下where跟having比较了。在这单表查询统计的情况下，如果要过滤的条件没有涉及到要计算字段，那它们的结果是一样的，只是where可以使用rushmore技术，而having就不能，在速度上后者要慢。  

  如果要涉及到计算的字段，就表示在没计算之前，这个字段的值是不确定的，根据上篇写的工作流程，where的作用时间是在计算之前就完成的，而having就是在计算后才起作用的，所以在这种情况下，两者的结果会不同。  

  在多表联接查询时，on比where更早起作用。系统首先根据各个表之间的联接条件，把多个表合成一个临时表后，再由where进行过滤，然后再计算，计算完后再由having进行过滤。由此可见，要想过滤条件起到正确的作用，首先要明白这个条件应该在什么时候起作用，然后再决定放在那里

#### 6. sql语句什么时候需要加前缀

你说的是abc.table，的 abc吧，这个是用户名，是这张表所属于的用户。
我举个例子：
比如有a，b两个用户。b用户下有一张c表。a用户下也有一张c表。
如果a用户写select * from c,那么这个c查询的是a用户下的c表。
如果a用户写为select * from b.c，那么这次a用户查询的就是b用户下的c表，不过这里有一个前提，a用户有查询b用户下c表的权限。
oracle下因为遵循最小权限原则，比如b用户对于b用户下的c表可以进行增删改查，但是对于另外一个人来说能查询就可以，如果让他去删除和改，那么可能会有问题产生，所以只给查询的权限，所以就会出现这个问题。

#### 7.SQL中GROUP BY用法示例

https://www.jianshu.com/p/8b135d373df1

概述

*GROUP BY我们可以先从字面上来理解，GROUP表示分组，BY后面写字段名，就表示根据哪个字段进行分组，如果有用Excel比较多的话，GROUP BY比较类似Excel里面的透视表。
 **GROUP BY必须得配合聚合函数来用，分组之后你可以计数（COUNT），求和（SUM），求平均数（AVG）等**。*

常用聚合函数

- count()  *计数*
- sum()  *求和*
- avg()   *平均数*
- max()  *最大值*
- min()   *最小值*

语法



```sql
SELECT column_name, aggregate_function(column_name)
FROM table_name
WHERE column_name operator value
GROUP BY column_name;
```

例子

接下来我们将通过例子进行理解：
 我们现在有一张dept_emp表共四个字段，分别是emp_no(员工编号)，dept_no(部门编号)，from_date(起始时间)，to_date(结束时间)，记录了员工在某一部门所处时间段，to_date等于9999-01-01的表示目前还在职。

![img](https:////upload-images.jianshu.io/upload_images/8061266-0cb6ecd1ac14baa1.png?imageMogr2/auto-orient/strip|imageView2/2/w/582/format/webp)

image.png

部门人数

我们现在想知道每个部门有多少名在职员工，步骤如下：

1. 筛选在职员工 `where to_date='9999-01-01'`;
2. 对部门进行分组`group by dept_no`
3. 对员工进行计数 `count(emp_no)`

完整语句如下：



```sql
SELECT
  dept_no as 部门,
  count( emp_no) as 人数
FROM
  dept_emp 
WHERE
  to_date = '9999-01-01' 
GROUP BY
  dept_no
```

结果

![img](https:////upload-images.jianshu.io/upload_images/8061266-4b0feb5fca3be132.png?imageMogr2/auto-orient/strip|imageView2/2/w/228/format/webp)

image.png

部门名称

我们上一步分组之后得到的结果是部门编号，下一步我们可以通过departments去关联出部门名称，语句如下：



```sql
SELECT
    ( SELECT d.dept_name FROM departments d WHERE de.dept_no = d.dept_no ) AS 部门,
    count( de.emp_no ) AS 人数 
FROM
    dept_emp de 
WHERE
    de.to_date = '9999-01-01' 
GROUP BY
    de.dept_no
```

结果

![img](https:////upload-images.jianshu.io/upload_images/8061266-d1f1c6654681d4bc.png?imageMogr2/auto-orient/strip|imageView2/2/w/354/format/webp)

image.png

HAVING

**当然提到GROUP BY 我们就不得不提到HAVING，HAVING相当于条件筛选，但它与WHERE筛选不同，HAVING是对于GROUP BY对象进行筛选。**
 我们举个例子：
 每个部门人数都有了，那如果我们想要进一步知道员工人数大于30000的部门是哪些，这个时候就得用到HAVING了。
 语句如下：



```sql
SELECT
    ( SELECT d.dept_name FROM departments d WHERE de.dept_no = d.dept_no ) AS 部门,
    count( de.emp_no ) AS 人数 
FROM
    dept_emp de 
WHERE
    de.to_date = '9999-01-01' 
GROUP BY
    de.dept_no 
HAVING
    count( de.emp_no ) > 30000 
```

结果

![img](https:////upload-images.jianshu.io/upload_images/8061266-81e50d2cd4263b65.png?imageMogr2/auto-orient/strip|imageView2/2/w/282/format/webp)

# LINUX

Linux常用命令英文全称（辅助理解用）: [link](https://blog.csdn.net/weixin_43518038/article/details/104986728).

#### 1. Linux基础命令

(1) 首先，在进入linux系统后.我们常常需要知道系统只有哪些文件，这个时候可以使用**显示列表命令（ls）**.

~~~
[root@localhost ~]# ls       //显示列表
[root@localhost ~]# ls -l    //显示长列表
~~~

(2) 在对**目录**进行操作时.我们可以选择**创建新目录(mkdir)，切换目录(cd)，复制文件或目录(cp)，删除文件或目录(rm)**.

~~~
[root@localhost ~]# mkdir newdir       //创建名字为“newdir ”的目录 
[root@localhost ~]# cd newdir          //进入名字为“newdir ”的目录  
[root@localhost ~]# cd ..              //返回上一层目录
[root@localhost ~]# cp newdir newdir1  //复制名字为“newdir ”的目录，新目录名为newdir1
[root@localhost ~]# rm newdir          //删除名字为“newdir ”的目录
~~~

(3) 在对**文件**进行操作时.我们可以选择**创建新文件(touch)，显示文件内容(cat)，修改文件内容(vim)，复制文件内容(cd)**.

~~~
[root@localhost ~]# touch file       //创建名字为“file ”的文件
[root@localhost ~]# cat file         //显示名字为“file”的文件
[root@localhost ~]# vim file         //创建名字为“file”的文件
~~~

(4) 当我们要**重启或者关闭系统**时，可以使用**shutdowm**命令：

~~~
[root@localhost ~]# shutdowm -h      //关机
[root@localhost ~]# shutdowm -r      //重启
~~~

#### 2. Linux中级命令 

(5) 想要对linux系统，进行更高级的处理时，我们需要**获取root权限**.

~~~
[root@localhost ~]# su root         //获取root权限
~~~

(6) 想要**管理用户信息**时，我们可以使用以下命令:

~~~
[root@localhost ~]# useradd xumingxiao   //创建名字为“xumingxiao”的用户
[root@localhost ~]# password xumingxiao  //修改名字为“xumingxiao”的用户名密码
~~~

(7) 当想要了对**磁盘**进行操作时时，我们可以使用以下命令：

~~~
[root@localhost ~]# df -h                     //显示已经挂载的分区列表
[root@localhost ~]# mount /dev/hda2 /mnt/hda2 //挂载一个叫做hda2的盘 - 确定目录 ‘/ mnt/hda2’ 已经存在
[root@localhost ~]# umount /dev/hda2          //卸载一个叫做hda2的盘 - 先从挂载点 ‘/ mnt/hda2’ 退出
~~~

(8) 当我们需要**从指定的服务器下载 rpm包**并且安装时.我们可以使用以下命令：

~~~
[root@localhost ~]#  yum install rpm          //安装rpm包
[root@localhost ~]#  yum remove rpm           //删除rpm包，括与该包有依赖性的包
~~~

#### 3. Linux进阶命令 

Linux中高级命令包括grep，awk，top，ps，sed，sort，tail和head命令

(9) grep（Global Regular Expression Print）**可以使用正则表达式搜索文本里面的内容**

~~~ 
[root@localhost ~]# grep “passport” file.log
~~~

(10) awk命令主要是**将一行分为多个字段做处理**，格式如下所示：

~~~ 
[root@localhost ~]# awk [-F field-separator] 'commands' input-file(s)
~~~

(11) top和ps命令：探测进程，ps和top命令的区别：

* **ps看到的是命令执行瞬间的进程信息，而top可以持续的监视**.
* ps只是查看进程，而top还可以监视系统性能，如平均负载，cpu和内存的消耗.
* top可以操作进程，如改变优先级(命令r)和关闭进程(命令k).
* ps主要是查看进程的，关注点在于查看需要查看的进程.
* top主要看cpu，内存使用情况，及占用资源最多的进程由高到低排序，关注点在于资源占用情况.

(12) sed 命令是**利用脚本来处理文本文件**.

~~~ 
[root@localhost ~]# sed –n ‘2，3p’ test.txt//可以将文件的第二行和第三行裁剪出来
~~~

(13) sort命令可以实现对**文件进行排序**.

~~~ 
[root@localhost ~]# sort -n test.txt//正序排序：
[root@localhost ~]# sort –nr test.txt//反序排序
~~~

(14) tail和head命令：可以**查看文件的指定行数**

~~~ linux
[root@localhost ~]# tail –n 2 file.log// 可以查看文件的最后2行.
[root@localhost ~]# tail –f file.log// 可以实时查看文件的后边追加的部分.
[root@localhost ~]# head –n 2 file.log// 可以查看文件的开始2行.
~~~

## [Linux命令脑图]

![linux](X:\Users\xu\Desktop\linux.png)

## [linux理论]

##### 1. **drwxr-xr-x 2 root root 4096 06-29 14:30 Test 什么意思?**

drwxr-xr-x 2 root root 4096 06-29 14:30 Test 分段解bai释
d: 这个应该是目录吧 然后2 就是文件数du.
rwxr-xr-x 这里是三zhi段分开解释.r表示可读W表示可写x表示运行
rwx 表示文dao件所有者的权限
r-x 表示文件所有者所在组的权限
r-x 表示其他人的权限
第一个 root 用户
第二个 root 用户组
4096 是文件大小
06-29 14:30 是创建时间
test 文件名

##### 2. **pwd是什么意思呢**

在Linux系统bai中，pwd命令用作显示工作目录的路du径名称，全称是“Print Working Directory”.

##### 3. **rm -p? 错是rm -r**

##### 4.**Linux less命令**

https://blog.csdn.net/weixin_44316575/article/details/103245508

[![Linux 命令大全](https://www.runoob.com/images/up.gif) Linux 命令大全](https://www.runoob.com/linux/linux-command-manual.html)

less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件.

##### 5. **chomd如何使用**

https://www.runoob.com/linux/linux-comm-chmod.html

https://blog.csdn.net/pythonw/article/details/80263428

##### 6.**find命令的使用**

https://www.runoob.com/linux/linux-comm-find.html

Linux find 命令用来在指定目录下查找文件.任何位于参数之前的字符串都将被视为欲查找的目录名.如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件.并且将查找到的子目录和文件全部进行显示.

##### 7. linux下find和grep的区别

https://blog.csdn.net/denghonghao/article/details/78610861

在使用linux时，经常需要进行文件查找.其中查找的命令主要有find和grep.两个命令是有区的.

**区别**：(1)find命令是根据**文件的属性**进行查找，如文件名，文件大小，所有者，所属组，是否为空，访问时间，修改时间等. 

(2)grep是根据**文件的内容进行**查找，会对文件的每一行按照给定的模式(patter)进行匹配查找.

##### 8. linux命令中“|”符号是什么意思？

这个符号叫做管道符号.

管道命令符的作用能用一句话来概括：“**把前一个命令原本要输出到屏幕的数据当作是后一个命令的标准输入**”.

输入方法是同时按下键盘的“Shift”与“\”键，执行格式为“命令A | 命令B”.
如：history | grep date指从history这条命令运行的结果中显示包含有 “date” 的命令.