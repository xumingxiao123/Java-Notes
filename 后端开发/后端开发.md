# Redis

> **为什么有些概念很难理解？**
> **例1**：redis是一款远程内存数据库.     
> **例2**：熊猫是一种哺乳动物.             
> 很显然，例2的句子比例1句子更容易理解.**例1和例2是同样的语法结构**--主谓宾.**不同的是词语本身的含义**：“哺乳动物”是常见的词语，我们都对它的含义很熟悉；而“远程内存数据库”对于初学者来说却晦涩难懂，并不常见.也就是说，句子结构并不是我们去理解概念的阻碍，而是词语本身的含义.或许在我们理解了“远程内存数据库”中的词语，概念本身就并不陌生.
> 所以本文对于新事物的学习思想是：**对专业名词追根溯源**.

#### 1. **Redis是什么?**

Redis (REmote DIctionary Server)是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列，是一个高性能的key-value数据库.
Redis与其他key-value缓存产品有以下三个特点：

- Redis**支持数据的持久化**，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用.
- Redis**不仅支持简单的key-value类型的数据**，同时还提供list，set，zset，hash等数据结构的存储.
- Redis**支持数据的备**份，即master-slave模式的数据备份.

**为什么要用Redis**

- **性能极高** – Redis读的速度是110000次/s，写的速度是81000次/s .
- **丰富的数据类型** – Redis支持Strings， Lists， Hashes， Sets 及 Ordered Sets 数据类型操作.
- **原子** – Redis的所有操作都是原子性的，即要么成功执行要么失败完全不执行.单个操作是原子性的.多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来.
- **丰富的特性** – Redis还支持publish/subscribe， key过期等特性.

> 总结：
>
> 1. Redis（Remote Dictionary Server远程字典服务器)，是一款高性能的分布式数据库，基于**内存**运行并支持**持久化**的**NoSQL**数据库.
>
> 2. 它可以储存键（key）与**string**、**hash**、**list**、**set**和s**orted se**t五种不同类型的值（value）之间的映射.
> 3. 使用redis可能出现**缓存雪崩**、**缓存击穿**、**缓存穿透**和数据库和缓存的双写一致性问题等问题.

###### [1] 什么是远程字典服务器？

 **远程**：有远程的就有本地的.本地的意思就是你自己的电脑，远程就是指别人的电脑.
**字典**：就像普通的字典一样，数据字典就是用来对数据进行定义和解释的.它可以用作：数据库、缓存和消息中间件.
**服务器**：服务器就是远程电脑，服务器可以在网络中为其它客户机提供计算或者应用服务.

###### **[2] 为什么redis是高性能的？**

1）基于**内存**实现，完全内存计算；
2）**单线程**操作，避免了**线程上下文切换**操作；
3）**多路I/O复用**的线程模型，实现了一个线程监控多个IO流，及时响应请求；
4）Redis对外部的依赖比较少，属于轻量级内存数据库.

>> **内存**: 内存的访问速度是很快的，常用的DDR4内存的读写速度是机械硬盘的30倍；
>
>>**单线程**：避免了线程上下文切换和竞争条件.也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
>
>>**什么是线程上下文切换？**
>>即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制.时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）.**CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务.但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换**.
>>这就像我们同时读两本书，当我们在读一本英文的技术书籍时，发现某个单词不认识， 于是便打开中英文词典，但是在放下英文书籍之前，大脑必须先记住这本书读到了多少页的第多少行，等查完单词之后，能够继续读这本书.这样的切换是会影响读书效率的，同样上下文切换也会影响多线程的执行速度.
>>**I/O多路复用技术是什么，为什么很快？**
>>常见的IO模型有阻塞模型、非阻塞模型、IO多路复用，信号驱动IO，异步.
>>
>>1. 阻塞式IO: 使用系统调用，并一直阻塞直到内核将数据准备好，之后再由内核缓冲区复制到用户态，在等待内核准备的这段时间什么也干不了.
>>2. 非阻塞式IO：内核在没有准备好数据的时候会返回错误码，而调用程序不会休眠，而是不断轮询询问内核数据是否准备好
>>3. IO多路复用：类似非阻塞，只不过轮询不是由用户线程去执行，而是由内核去轮询，内核监听程序监听到数据准备好后，调用内核函数复制数据到用户空间
>>4. 信号驱动IO： 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的.
>>5. 异步IO：应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号.
>
>>**不好理解？举例说明:**
>>
>>1. 阻塞：比如某个时候你在去餐厅吃饭，又想出去逛街.但是你不知道饭菜什么时候来，只好坐在餐厅里面等.直到做好，然后吃完才离开去做逛街.这就是典型的阻塞.
>>2. 非阻塞忙轮询：接着上面的例子，如果用忙轮询的方法，出去我们逛一会，然后每分钟回来问一下服务员：“饭菜好了没？”
>>3. IO多路复用：餐厅安装了电子屏幕用来显示点餐的状态，逛街一会，回来就不用去询问服务员了，直接看电子屏幕就可以了.
>>4. 异步IO：不想逛街，餐厅太吵了，回家好好休息一下.于是我们叫外卖，打个电话点餐，然后我可以在家好好休息一下，饭好了送货员送到家里来.这就是典型的异步，只需要打个电话说一下，然后可以做自己的事情，饭好了就送来了.
>>5. 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O.
>
>>**阻塞是个什么概念呢？**
>>比如某个时候你在去餐厅吃饭，又想出去逛街.但是你不知道饭菜什么时候来，只好坐在餐厅里面等.直到做好，然后吃完才离开去做逛街.这就是典型的阻塞.

###### **[3] 分布式的含义？**

把一个需要非常巨大的计算能力才能解决的问题分成许多小的部分，然后把这些部分分配给多个计算机进行处理，最后把这些计算结果综合起来得到最终的结果

###### **[4] NoSQL的含义？**

**NoSQL**泛指非关系型的数据库.与之对应的是关系数据库SQL.关系数据库的查询经常会关联两个表的数据，而NoSQL不关联表.

#### 2. Redis有哪五种不同类型的值？应用场景有哪些？

1. **string**：redis 中字符串 value 最大可为512M.可以用来做一些**计数器**（也是实际工作中最常见的）.
2. **hash**：键值对集合，是一个字符串类型的 Key和 Value 的映射表，也就是说其存储的Value是一个键值对（Key- Value）.可以用来存放一些具有特定结构的信息.用于**用户信息管理**.
3. **list**：简单的字符串列表，按照插入顺序排序，可以添加一个元素到列表的头部（左边）或者尾部（右边），其底层实现是一个链表.可以**实现一个简单消息队列**功能，做基于redis的分页功能等.
4. **set**：是一个字符串类型的无序集合.可以用来进行全局去重等.做**用户标签**.
5. **sorted set**：是一个字符串类型的有序集合，给每一个元素一个固定的分数score来保持顺序.可以用来做**排行榜应用**或者进行范围查找等.

* 补充：用**sorted set**实现一个排行榜需要注意什么问题？答：并列问题.

![image-20200629214430327](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629214430327.png)

**详细介绍：**

Redis支持五种数据类型：**string**（字符串），**hash**（哈希），**list**（列表），**set**（集合）及**zset**(sorted set：有序集合).每种数据类型有其适合的使用场景，下面具体介绍.

###### [1] String（字符串）

string 是 redis 最基本的类型，你可以理解成与 **Memcached** 一模一样的类型，一个 key 对应一个 value.string 类型是二进制安全的.意思是 redis 的 string 可以包含任何数据.比如jpg图片或者序列化的对象.string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB.

**使用方法**

```
SET key value   设置指定 key 的值  
GET key     获取指定 key 的值.
SETEX key seconds value 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位).
```

**使用场景**

1. **会话缓存**
   用户登录系统后，使用Redis保存用户的Session信息，每次用户查询登录信息都直接从Redis中获取.

2. **计数器**

- 比如登录系统会限制密码错误次数，当一个用户在一定时间内连续输入密码错误，就不能登录，需要一段时间后才能登录，我们可以使用redis，把username作为key，错误的次数作为value，同时设置过期时间即可.
- 手机验证码限收到短信的次数
- 统计其他计数

3. **定时器**
   redis的key可以设置过期时间，我们基于此特性设置一个定时器.

4. **对象**
   我们把对象序列化后，可以使用redis保存该对象，然后在获取对象信息的时候，反序列化value

5. **分布式锁**
   redis提供了setnx()方法，即SET IF NOT EXIST，只有在key不存在的时候才能set成功，这就意味着同一时间多个请求只有一个请求能保存成功，这块的可以自行搜索redis的分布式锁

###### [2] Hash（哈希）

Redis hash 是一个键值(key=>value)对集合，即编程语言中的Map类型.
Redis hash 是一个 string 类型的 field 和 value 的映射表.

**使用方法**

```
HSET key field value 
将哈希表 key 中的字段 field 的值设为 value .
HGET key field
获取存储在哈希表中指定字段的值.
HKEYS key
获取所有哈希表中的字段
HMSET key field1 value1 [field2 value2 ]
同时将多个 field-value (域-值)对设置到哈希表 key 中.
```

**使用场景**

hash 特别适合用于存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)

###### [3] List（列表）

Redis 列表是简单的字符串列表，按照插入顺序排序.你可以添加一个元素到列表的头部（左边）或者尾部（右边）.

**使用方法**

```
LPUSHX key value 
将一个值插入到已存在的列表头部  
LPUSH key value1 [value2]
将一个或多个值插入到列表头部
LPOP key
移出并获取列表的第一个元素
BLPOP key1 [key2 ] timeout
移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止.
```

**使用场景**

1. **消息队列**
   Redis的lpush+brpop命令组合即可实现阻塞队列，生产者客户端使用lrpush从列表左侧插入元素，多个消费者客户端使用brpop命令阻塞式的"抢"列表尾部的元素，多个客户端保证了消费的负载均衡和高可用性.

2. **类目/文章/活动等列表**
   最常见的就是各个系统的首页数据，包括电商系统的商品类目，拼团活动列表，博客园的首页文章列表等

3. **其他**
   根据push和pop的方式不同，有以下组合方式

```
    lpush + lpop = Stack(栈) lpush + rpop = Queue(队列) lpush + ltrim = Capped Collection(有限集合) lpush + brpop = Message Queue(消息队列) 
```

``

###### [4] Set（集合）

Redis 的 Set 是 String 类型的无序集合.集合成员是唯一的，这就意味着集合中不能出现重复的数据.

Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1).

**使用方法**

```
SADD key member1 [member2] 
向集合添加一个或多个成员  
SDIFF key1 [key2]
返回给定所有集合的差集
SINTER key1 [key2]
返回给定所有集合的交集
SMEMBERS key
返回集合中的所有成员
```

**使用场景**

1. 标签(tag)
   比如在点餐评价系统中，用户给某商家评价，商家会有多个评价标签，但是不会重复的，如果100万人给某商家评价打了标签，如果使用MySQL数据库获取大数据量去重后的评价标签，会影响数据库的性能和系统的并发量.

2. 相同点/异同点
   利用交集、并集、差集等操作，可以计算两个人的共同喜好，全部的喜好，自己独有的喜好等功能.

###### [5] zset (sorted set：有序集合)

Redis 有序集合和集合一样也是string类型元素的集合，且不允许重复的成员.

不同的是每个元素都会关联一个double类型的分数.redis正是通过分数来为集合中的成员进行从小到大的排序.

有序集合的成员是唯一的，但分数(score)却可以重复.

**使用方法**

```
ZADD key score1 member1 [score2 member2] 
向有序集合添加一个或多个成员，或者更新已存在成员的分数  
ZCARD key
获取有序集合的成员数
ZREM key member [member ...]
移除有序集合中的一个或多个成员
```

**使用场景**：

*  **排行榜**：例如博客园需要对用户发表的文章做排行榜，榜单的维度可能是多个方面的：按照时间、按照点赞数、按照热度，浏览数等

#### 3. 使用redis可能出现的问题

**首先我们应该先明确缓存处理的流程**：
 前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果.

###### [1] **缓存雪崩**

指**缓存由于某些原因（比如 宕机、cache服务挂了或者不响应）整体失效了，导致大量请求到达后端数据库**，从而导致数据库崩溃，整个系统崩溃，发生灾难.

* 解决办法：可以给缓存设置不同的缓存时间，更新数据使用**互斥锁**或者通过**双缓存**在避免缓存雪崩.

###### [2] **缓存击穿**

缓存击穿是指缓存中没有但数据库中有的数据.如果一些key被高并发访问**，恰好在这个时间点某个key缓存过期，从而导致了大量请求达到数据库**，，这就导致数据库中并发的去执行了很多不必要的查询操作，从而导致巨大冲击和压力.

* 解决办法：使用互斥锁，只让一个请求去load DB，成功之后重新写缓存，其余请求没有获取到互斥锁，可以尝试重新获取缓存中的数据.

###### [3] **缓存穿透**

是指**缓存和数据库中都没有的数据，而用户不断发起请求，导致请求都打到了数据库**上，导致数据库异常.

* 解决办法：可以使用互斥锁或者无论是否取到结果都将结果存入缓存，还可以使用有效的机制（比如布隆过滤器）来拦截不合法的key值等.

###### [4] 三种问题区别记忆方法

在一个高频访问的应用系统中，每次用户的请求需要去DB中获取数据，会对数据库造成很大的压力、容易导致数据库的奔溃.所以才会出现缓存来分担一部分的数据库的压力. 但是使用缓存也带来了一系列问题:

> 打个比方，数据库是人，缓存是防弹衣，子弹是线程，本来防弹衣是防止子弹打到人身上的，但是当防弹衣里面没有防弹的物质时，子弹就会穿过它打到人身上.

1. **缓存雪崩（被霰弹枪打）**：**"雪崩"对应的是大量请求**，缓存某一时间失效了，然后**大量请求**到达后端数据库，从而导致数据库崩溃.

   解决方法：避免同时过期，构建多级缓存，部署多个redis实例。

2. **缓存击穿（被狙击枪多次打一点）**：**"击穿"对应的是redis某点被（key）击穿**。如果**一些key被高并发访问**，恰好在这个时间点某个key缓存过期，从而导致了大量请求达到数据库，，这就导致数据库中并发的去执行了很多不必要的查询操作，从而导致巨大冲击和压力.

   解决方法：加互斥锁，永不过期.

3. **缓存穿透（被巴雷特打）**：**"穿透"最为严重，指的是缓存和数据库被穿透，都穿的透透的了**。是指缓存和数据库中都没有的数据，而用户不断发起请求，导致**请求都打到了数据库**上，导致数据库异常.这时的用户很可能是攻击者.

   解决方法：缓存空值，布隆过滤器.

**缓存雪崩、缓存穿透、缓存击穿的解决方案**

**缓存雪崩**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629221647159.png" alt="image-20200629221647159" style="zoom:50%;" />

**缓存击穿**

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629221419115.png" alt="image-20200629221419115" style="zoom:50%;" />

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200719220627332.png" alt="image-20200719220627332" style="zoom:80%;" />

###### [5] **数据库和缓存的双写一致性问题**

> 在**高并发**请求下很容易导致数据不一致的问题，如果你的业务需要保证数据的强一致性，那么建议不要使用缓存.**在数据库中和缓存数据的删除或者写入过程中，如果有失败的情况，会导致数据的不一致**.
> 解决办法：
> **双删延时的解决办法.可以先删除缓存数据，然后再更新数据库数据，最后再隔固定的时间再次删除缓存.**
> 更新数据库产生的binlog订阅（使用canal）.将有变化的key记录下来，并且尝试去不断的去删除缓存（如果上次删除缓存失败）

缓存不一致详解：

**最初级的缓存不一致问题及解决方案**

问题：先修改数据库，再删除缓存.如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致.

解决思路：先删除缓存，再修改数据库.如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致.因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中.

**比较复杂的数据不一致问题分析**

数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改.一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据**，放到了缓存中.随后数据变更的程序完成了数据库的修改.完了，数据库和缓存中的数据不一样了...

**为什么上亿流量高并发场景下，缓存会出现这个问题？**

只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题.其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场景.但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就**可能会出现上述的数据库+缓存不一致的情况**.

**解决方案如下：**

更新数据的时候，根据**数据的唯一标识**，将操作路由之后，发送到一个 jvm 内部队列中.读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中.

一个队列对应一个工作线程，每个工作线程**串行**拿到对应的操作，然后一条一条的执行.这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新.此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成.

这里有一个**优化点**，一个队列中，其实**多个更新缓存请求串在一起是没意义的**，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可.

待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中.

如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值.

高并发的场景下，该解决方案要注意的问题：

- 读请求长时阻塞

由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回.

该解决方案，最大的风险点在于说，**可能数据更新很频繁**，导致队列中积压了大量更新操作在里面，然后**读请求会发生大量的超时**，最后导致大量的请求直接走数据库.务必通过一些模拟真实的测试，看看更新数据的频率是怎样的.

另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要**部署多个服务**，每个服务分摊一些数据的更新操作.如果一个内存队列里居然会挤压 100 个商品的库存修改操作，每隔库存修改操作要耗费 10ms 去完成，那么最后一个商品的读请求，可能等待 10 * 100 = 1000ms = 1s 后，才能得到数据，这个时候就导致**读请求的长时阻塞**.

一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时间，如果读请求在 200ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的.

**如果一个内存队列中可能积压的更新操作特别多**，那么你就要**加机器**，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少.

其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的.像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了.

我们来**实际粗略测算一下**.

如果一秒有 500 的写操作，如果分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作.每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200ms 以内肯定能返回了.

经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列.

- 读请求并发量过高

这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值.

但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大.

- 多服务实例部署的请求路由

可能这个服务部署了多个实例，那么必须**保证**说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器**路由到相同的服务实例上**.

比如说，对同一个商品的读写请求，全部路由到同一台机器上.可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等.

- 热点商品的路由问题，导致请求的倾斜

万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大.就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些机器的负载会高一些.

#### 5. Redis底层数据结构

//https://stor.51cto.com/art/201910/605032.htm

主要提供了5种数据结构：**字符串**(String)、**哈希**(hash)、**列表**(list)、**集合**(set)、**有序集合**(short set);

**redis底层实现的8种数据结构**

```markdown
SDS simple synamic string：支持自动动态扩容的字节数组 
list ：链表 
dict ：使用双哈希表实现的， 支持平滑扩容的字典 
zskiplist ：附加了后向指针的跳跃表 
intset ： 用于存储整数数值集合的自有结构 
ziplist ：一种实现上类似于TLV， 但比TLV复杂的， 用于存储任意数据的有序序列的数据结构 
quicklist：一种以ziplist作为结点的双链表结构， 实现的非常不错 
zipmap ： 一种用于在小规模场合使用的轻量级字典结构 
```

![原创：redis中8种数据结构的底层数据结构源码详解](https://s5.51cto.com/oss/201910/29/c32a5a2c4d92da4751e53fd5eb2d345b.jpeg)

其中5种存储类型与8种数据结构的桥梁， **是redisObject**;

Redis中的Key与Value在表层都是一个redisObject实例， 所以该结构有所谓的"类型"， 即是ValueType. 对于每一种Value Type类型的redisObject;

其底层至少支持两种不同的底层数据结构来实现. 以应对在不同的应用场景中， Redis的运行效率， 或内存占用等

**底层数据结构分析**

**1、SDS - simple dynamic string**

可以在安装目录的src文件夹下看到sds.c和sds.h的源码文件

```
typedef char *sds; 
  
/* Note: sdshdr5 is never used， we just access the flags byte directly. 
 * However is here to document the layout of type 5 SDS strings. */ 
struct __attribute__ ((__packed__)) sdshdr5 { 
 unsigned char flags; /* 3 lsb of type， and 5 msb of string length */ 
 char buf[]; 
}; 
struct __attribute__ ((__packed__)) sdshdr8 { 
 uint8_t len; /* used */ 
 uint8_t alloc; /* excluding the header and null terminator */ 
 unsigned char flags; /* 3 lsb of type， 5 unused bits */ 
 char buf[]; 
}; 
struct __attribute__ ((__packed__)) sdshdr16 { 
 uint16_t len; /* used */ 
 uint16_t alloc; /* excluding the header and null terminator */ 
 unsigned char flags; /* 3 lsb of type， 5 unused bits */ 
 char buf[]; 
}; 
struct __attribute__ ((__packed__)) sdshdr32 { 
 uint32_t len; /* used */ 
 uint32_t alloc; /* excluding the header and null terminator */ 
 unsigned char flags; /* 3 lsb of type， 5 unused bits */ 
 char buf[]; 
}; 
struct __attribute__ ((__packed__)) sdshdr64 { 
 uint64_t len; /* used */ 
 uint64_t alloc; /* excluding the header and null terminator */ 
 unsigned char flags; /* 3 lsb of type， 5 unused bits */ 
 char buf[]; 
};
```

sdshdr的存储结构

![image-20200709224512039](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200709224512039.png)

sdshdr是头部， buf是真实存储用户数据的地方.(buf="数据" + "\0" );sds有四种不同的头部. sdshdr5未 使用，未显示

![原创：redis中8种数据结构的底层数据结构源码详解](https://s2.51cto.com/oss/201910/29/97560edc327ca8156043f04e1438fabb.jpeg-wh_600x-s_3891482493.jpeg)

en分别以uint8， uint16， uint32， uint64表示用户数据的长度(不包括末尾的\0)

alloc分别以uint8， uint16， uint32， uint64表示整个SDS， 除过头部与末尾的\0， 剩余的字节数.

flag始终为一字节， 以低三位标示着头部的类型， 高5位未使用.

创建一个SDS实例的三个接口

![原创：redis中8种数据结构的底层数据结构源码详解](https://s5.51cto.com/oss/201910/29/3ef91a6836a5fa2d49f8bbe261393101.jpeg)

**2、list**

链表实现， 链表结点不直接持有数据， 而是通过void *指针来间接的指向数据. 其实现位于 src/adlist.h与src/adlist.c中，

**内存布局**

![image-20200709224607207](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200709224607207.png)

list在Redis除了作为一些Value Type的底层实现外， 还广泛用于Redis的其它功能实现中， 作为一种数据结构工具使用.

在list的实现中， 除了基本的链表定义外， 还额外增加了:迭代器listIter的定义， 与相关接口的实现.

由于list中的链表结点本身并不直接持有数据， 而是通过value字段， 以void *指针的形式间接持有， 所以数据的生命周期并不完全与链表及其结点一致. 这给了list的使用者相当大的灵活性. 比如可以多个结点持有同一份数据的地址. 但与此同时， 在对链表进行销毁， 结点复制以及查找匹配时， 就需要list的使用者将相关的函数指针赋值于list.dup， list.free， list.match字段.

**3、dict**

dict类似于C++标准库中的std::unordered_map， 其实现位于 src/dict.h 与 src/dict.c中

dict中存储的键值对， 是通过dictEntry这个结构间接持有的， k通过指针间接持有键， v通过指针间接持有值. 注意， 若值是整数值的话， 是直接存储在v字段中的， 而不是间接持有. 同时next指针用于指向， 在bucket索引值冲突时， 以链式方式解决冲突， 指向同索引的下一个dictEntry结构.

dict即为字典. 其中type字段中存储的是本字典使用到的各种函数指针， 包括散列函数， 键与值的复制函数， 释放函数， 以及键的比较函数. privdata是用于存储用户自定义数据. 这样， 字典的使用者可以最大化的自定义字典的实现， 通过自定义各种函数实现， 以及可以附带私有数据， 保证了字典有很大的调优空间.

字典为了支持平滑扩容， 定义了ht[2]这个数组字段. 其用意是这样的:

一般情况下， 字典dict仅持有一个哈希表dictht的实例， 即整个字典由一个bucket实现.

随着插入操作， bucket中出现冲突的概率会越来越大， 当字典中存储的结点数目， 与bucket数组长度的比值达到一个阈值(1:1)时， 字典为了缓解性能下降， 就需要扩容

扩容的操作是平滑的， 即在扩容时， 字典会持有两个dictht的实例， ht[0]指向旧哈希表， ht[1]指向扩容后的新哈希表.

**内存布局**

![原创：redis中8种数据结构的底层数据结构源码详解](https://s5.51cto.com/oss/201910/29/b91f066b88c845c406f1beacdac1e17b.jpeg)

**4、zskiplist**

zskiplist是Redis实现的一种特殊的跳跃表. 跳跃表是一种基于线性表实现简单的搜索结构， 其最大的特点就是: 实现简单， 性能能逼近各种搜索树结构.

**zskiplist的核心设计要点:**

头结点不持有任何数据， 且其level[]的长度为32

每个结点， 除了持有数据的ele字段， 还有一个字段score， 其标示着结点的得分， 结点之间凭借得分来判断先后顺序， 跳跃表中的结点按结点的得分升序排列.

每个结点持有一个backward指针， 这是原版跳跃表中所没有的. 该指针指向结点的前一个紧邻结点.

每个结点中最多持有32个zskiplistLevel结构. 实际数量在结点创建时， 按幂次定律随机生成(不超过32). 每个zskiplistLevel中有两个字段.

**内存布局**

![原创：redis中8种数据结构的底层数据结构源码详解](https://s5.51cto.com/oss/201910/29/dc5d5b2a20fd435025c02a037bab2f43.jpeg)

**5、intset**

用于存储在序的整数的数据结构， 也底层数据结构中最简单的一个， 其定义与实现在src/intest.h与src/intset.c中

inset结构中的encoding的取值有三个， 分别是宏INTSET_ENC_INT16， INTSET_ENC_INT32， INTSET_ENC_INT64. length代表其中存储的整数的个数， contents指向实际存储数值的连续内存区域

**内存布局**

![ååï¼redisä¸­8ç§æ°æ®ç»æçåºå±æ°æ®ç»ææºç è¯¦è§£](https://s5.51cto.com/oss/201910/29/b91f066b88c845c406f1beacdac1e17b.jpeg)

intset中各字段， 包括contents中存储的数值， 都是以主机序(小端字节序)存储的. 这意味着Redis若运行在PPC这样的大端字节序的机器上时， 存取数据都会有额外的字节序转换开销

当encoding == INTSET_ENC_INT16时， contents中以int16_t的形式存储着数值. 类似的， 当encoding == INTSET_ENC_INT32时， contents中以int32_t的形式存储着数值.

但凡有一个数值元素的值超过了int32_t的取值范围， 整个intset都要进行升级， 即所有的数值都需要以int64_t的形式存储. 显然升级的开销是很大的.

intset中的数值是以升序排列存储的， 插入与删除的复杂度均为O(n). 查找使用二分法， 复杂度为O(log_2(n))

intset的代码实现中， 不预留空间， 即每一次插入操作都会调用zrealloc接口重新分配内存. 每一次删除也会调用zrealloc接口缩减占用的内存. 省是省了， 但内存操作的时间开销上升了.

intset的编码方式一经升级， 不会再降级.

总之， intset适合于如下数据的存储:

所有数据都位于一个稳定的取值范围中. 比如均位于int16_t或int32_t的取值范围中

数据稳定， 插入删除操作不频繁. 能接受O(lgn)级别的查找开销

**6、ziplist**

ziplist是Redis底层数据结构中， 最苟的一个结构. 它的设计宗旨就是: 省内存， 从牙缝里省内存. 设计思路和TLV一致， 但为了从牙缝里节省内存， 做了很多额外工作.

ziplist的内存布局与intset一样: 就是一块连续的内存空间. 但区域划分比较复杂

![ååï¼redisä¸­8ç§æ°æ®ç»æçåºå±æ°æ®ç»ææºç è¯¦è§£](https://s5.51cto.com/oss/201910/29/dc5d5b2a20fd435025c02a037bab2f43.jpeg)

和intset一样， ziplist中的所有值都是以小端序存储的

zlbytes字段的类型是uint32_t， 这个字段中存储的是整个ziplist所占用的内存的字节数

zltail字段的类型是uint32_t， 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry， 以快速完成pop等操作

zllen字段的类型是uint16_t， 它指的是整个ziplit中entry的数量. 这个值只占16位， 所以蛋疼的地方就来了: 如果ziplist中entry的数目小于65535， 那么该字段中存储的就是实际entry的值. 若等于或超过65535， 那么该字段的值固定为65535， 但实际数量需要一个个entry的去遍历所有entry才能得到.

zlend是一个终止字节， 其值为全F， 即0xff. ziplist保证任何情况下， 一个entry的首字节都不会是255

在画图展示entry的内存布局之前， 先讲一下entry中都存储了哪些信息:

每个entry中存储了它前一个entry所占用的字节数. 这样支持ziplist反向遍历.

每个entry用单独的一块区域， 存储着当前结点的类型: 所谓的类型， 包括当前结点存储的数据是什么(二进制， 还是数值)， 如何编码(如果是数值， 数值如何存储， 如果是二进制数据， 二进制数据的长度)最后就是真实的数据了

**7、quicklist**

如果说ziplist是整个Redis中为了节省内存， 而写的最苟的数据结构， 那么称quicklist就是在最苟的基础上， 再苟了一层. 这个结构是Redis在3.2版本后新加的， 在3.2版本之前， 我们可以讲， dict是最复杂的底层数据结构， ziplist是最苟的底层数据结构. 在3.2版本之后， 这两个记录被双双刷新了.

这是一种， 以ziplist为结点的， 双端链表结构. 宏观上， quicklist是一个链表， 微观上， 链表中的每个结点都是一个ziplist.

它的定义与实现分别在src/quicklist.h与src/quicklist.c中

**这里定义了五个结构体:**

quicklistNode， 宏观上， quicklist是一个链表， 这个结构描述的就是链表中的结点. 它通过zl字段持有底层的ziplist. 简单来讲， 它描述了一个ziplist实例

quicklistLZF， ziplist是一段连续的内存， 用LZ4算法压缩后， 就可以包装成一个quicklistLZF结构. 是否压缩quicklist中的每个ziplist实例是一个可配置项. 若这个配置项是开启的， 那么quicklistNode.zl字段指向的就不是一个ziplist实例， 而是一个压缩后的quicklistLZF实例

quicklist. 这就是一个双链表的定义. head， tail分别指向头尾指针. len代表链表中的结点. count指的是整个quicklist中的所有ziplist中的entry的数目. fill字段影响着每个链表结点中ziplist的最大占用空间， compress影响着是否要对每个ziplist以LZ4算法进行进一步压缩以更节省内存空间.

**quicklistIter是一个迭代器**

quicklistEntry是对ziplist中的entry概念的封装. quicklist作为一个封装良好的数据结构， 不希望使用者感知到其内部的实现， 所以需要把ziplist.entry的概念重新包装一下.

quicklist的内存布局图如下所示:

![原创：redis中8种数据结构的底层数据结构源码详解](https://s3.51cto.com/oss/201910/29/572a78fa111c727d4d1610d832889e9e.jpeg)

下面是有关quicklist的更多额外信息:

quicklist.fill的值影响着每个链表结点中， ziplist的长度.

当数值为负数时， 代表以字节数限制单个ziplist的最大长度. 具体为:

-1 不超过4kb

-2 不超过 8kb

-3 不超过 16kb

-4 不超过 32kb

-5 不超过 64kb

当数值为正数时， 代表以entry数目限制单个ziplist的长度. 值即为数目. 由于该字段仅占16位， 所以以entry数目限制ziplist的容量时， 最大值为2^15个

quicklist.compress的值影响着quicklistNode.zl字段指向的是原生的ziplist， 还是经过压缩包装后的quicklistLZF

0 表示不压缩， zl字段直接指向ziplist

1 表示quicklist的链表头尾结点不压缩， 其余结点的zl字段指向的是经过压缩后的quicklistLZF

2 表示quicklist的链表头两个， 与末两个结点不压缩， 其余结点的zl字段指向的是经过压缩后的quicklistLZF

以此类推， 最大值为2^16

quicklistNode.encoding字段， 以指示本链表结点所持有的ziplist是否经过了压缩. 1代表未压缩， 持有的是原生的ziplist， 2代表压缩过

quicklistNode.container字段指示的是每个链表结点所持有的数据类型是什么. 默认的实现是ziplist， 对应的该字段的值是2， 目前Redis没有提供其它实现. 所以实际上， 该字段的值恒为2

quicklistNode.recompress字段指示的是当前结点所持有的ziplist是否经过了解压. 如果该字段为1即代表之前被解压过， 且需要在下一次操作时重新压缩.

quicklist的具体实现代码篇幅很长， 这里就不贴代码片断了， 从内存布局上也能看出来， 由于每个结点持有的ziplist是有上限长度的， 所以在与操作时要考虑的分支情况比较多. 想想都蛋疼.

quicklist有自己的优点， 也有缺点， 对于使用者来说， 其使用体验类似于线性数据结构， list作为最传统的双链表， 结点通过指针持有数据， 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题. 但引入了新的问题: 每次写操作整个ziplist的内存都需要重分配. quicklist在两者之间做了一个平衡. 并且使用者可以通过自定义quicklist.fill， 根据实际业务情况， 经验主义调参.

**8、zipmap**

dict作为字典结构， 优点很多， 扩展性强悍， 支持平滑扩容等等， 但对于字典中的键值均为二进制数据， 且长度都很小时， dict的中的一坨指针会浪费不少内存， 因此Redis又实现了一个轻量级的字典， 即为zipmap.

zipmap适合使用的场合是:

键值对量不大， 单个键， 单个值长度小

键值均是二进制数据， 而不是复合结构或复杂结构. dict支持各种嵌套， 字典本身并不持有数据， 而仅持有数据的指针. 但zipmap是直接持有数据的.

zipmap的定义与实现在src/zipmap.h与src/zipmap.c两个文件中， 其定义与实现均未定义任何struct结构体， 因为zipmap的内存布局就是一块连续的内存空间. 其内存布局如下所示:

![原创：redis中8种数据结构的底层数据结构源码详解](https://s3.51cto.com/oss/201910/29/18a4c3f961eddcc09f0333e6abec72b7.jpeg-wh_600x-s_2888420421.jpeg)

zipmap起始的第一个字节存储的是zipmap中键值对的个数. 如果键值对的个数大于254的话， 那么这个字节的值就是固定值254， 真实的键值对个数需要遍历才能获得.

**zipmap的最后一个字节是固定值0xFF**

zipmap中的每一个键值对， 称为一个entry， 其内存占用如上图， 分别六部分:

len_of_key， 一字节或五字节. 存储的是键的二进制长度. 如果长度小于254， 则用1字节存储， 否则用五个字节存储， 第一个字节的值固定为0xFE， 后四个字节以小端序uint32_t类型存储着键的二进制长度.

**key_data为键的数据**

len_of_val， 一字节或五字节， 存储的是值的二进制长度. 编码方式同len_of_key

len_of_free， 固定值1字节， 存储的是entry中未使用的空间的字节数. 未使用的空间即为图中的free， 它一般是由于键值对中的值被替换发生的. 比如， 键值对hello <-> word被修改为hello <-> w后， 就空了四个字节的闲置空间

**val_data， 为值的数据**

free， 为闲置空间. 由于len_of_free的值最大只能是254， 所以如果值的变更导致闲置空间大于254的话， zipmap就会回收内存空间.

#### 6. Redis的过期策略

Redis keys过期有两种方式：定期扫描和惰性删除.

###### [1] 定期删除（主动）

**定时删除，用一个定时器来负责监视所有key，当key过期则自动删除key**.
虽然内存及时释放，但是十分消耗CPU资源.在大并发请求下，会影响redis的性能.

###### [2]惰性删除（被动）

**客户端尝试访问key时，被访问的key会被发现并主动的过期**

缺陷：有些过期的keys，永远不会访问他们，那么他们就永远不会被删除，而占用内存.

###### [3] 定期删除+惰性删除

**redis默认每100ms主动检查一次，如果有过期的key则删除，当满足1/4的keys过期，则重复之前步骤.**具体步骤为：

1. redis默认每100ms随机抽取20个keys进行过期检查；
2. 同时删除已经过期的keys，如果有多于25%的keys过期，则重复抽取.
3. 直到过期的keys的百分比低于25%，
4. 这意味着，在任何给定的时刻，最多会清除1/4的过期keys.

###### [4] 内存淘汰机制

采用定期删除+惰性删除就能保证过期的key会全部删除掉么?

如果定期删除没删除key.然后也没去请求key，也就是说惰性删除也没生效.这样，redis的内存会越来越高.那么就应该采用内存淘汰机制.
在redis.conf中有配置

> maxmemory-policy volatile-lru

**内存淘汰策略如下:**

- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，不建议使用
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key.推荐使用
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除

###### [5] LRU算法

![image-20200719222247853](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200719222247853.png)

#### 7. Redis分布式锁

> https://www.jianshu.com/p/47fd7f86c848

在Java中，关于锁我想大家都很熟悉.在并发编程中，我们通过锁，来避免由于竞争而造成的数据不一致问题.通常，我们以`synchronized 、Lock`来使用它.但是Java中的锁，只能保证在同一个JVM进程内中执行.如果在分布式集群环境下呢？

###### **[1] 分布式锁**

分布式锁，是一种思想，它的实现方式有很多.比如，我们将沙滩当做分布式锁的组件，那么它看起来应该是这样的：

- **加锁**：在沙滩上踩一脚，留下自己的脚印，就对应了加锁操作.其他进程或者线程，看到沙滩上已经有脚印，证明锁已被别人持有，则等待.

- **解锁**：把脚印从沙滩上抹去，就是解锁的过程.

- **锁超时**：为了避免死锁，我们可以设置一阵风，在单位时间后刮起，将脚印自动抹去.

分布式锁的实现有很多，比如基于数据库、memcached、Redis、系统文件、zookeeper等.它们的核心的理念跟上面的过程大致相同.

###### **[2] redis**

我们先来看如何**通过单节点Redis实现一个简单的分布式锁**.

**1、加锁**

加锁实际上就是在redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间.

```
SET lock_key random_value NX PX 5000
```

值得注意的是：
 `random_value` 是客户端生成的唯一的字符串.
 `NX` 代表只在键不存在时，才对键进行设置操作.
 `PX 5000` 设置键的过期时间为5000毫秒.

这样，如果上面的命令执行成功，则证明客户端获取到了锁.

**2、解锁**

解锁的过程就是将Key键删除.但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉.这时候`random_value`的作用就体现出来.

为了保证解锁操作的原子性，我们用LUA脚本完成这一操作.先判断当前锁的字符串是否与传入的值相等，是的话就删除Key，解锁成功.

```kotlin
if redis.call('get'，KEYS[1]) == ARGV[1] then 
   return redis.call('del'，KEYS[1]) 
else
   return 0 
end
```

**3、实现**

首先，我们在pom文件中，引入Jedis.在这里，笔者用的是最新版本，注意由于版本的不同，API可能有所差异.

```xml
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
    <version>3.0.1</version>
</dependency>
```

加锁的过程很简单，就是通过SET指令来设置值，成功则返回；否则就循环等待，在timeout时间内仍未获取到锁，则获取失败.

```csharp
@Service
public class RedisLock {

    Logger logger = LoggerFactory.getLogger(this.getClass());

    private String lock_key = "redis_lock"; //锁键

    protected long internalLockLeaseTime = 30000;//锁过期时间

    private long timeout = 999999; //获取锁的超时时间

    
    //SET命令的参数 
    SetParams params = SetParams.setParams().nx().px(internalLockLeaseTime);

    @Autowired
    JedisPool jedisPool;

    
    /**
     * 加锁
     * @param id
     * @return
     */
    public boolean lock(String id){
        Jedis jedis = jedisPool.getResource();
        Long start = System.currentTimeMillis();
        try{
            for(;;){
                //SET命令返回OK ，则证明获取锁成功
                String lock = jedis.set(lock_key， id， params);
                if("OK".equals(lock)){
                    return true;
                }
                //否则循环等待，在timeout时间内仍未获取到锁，则获取失败
                long l = System.currentTimeMillis() - start;
                if (l>=timeout) {
                    return false;
                }
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }finally {
            jedis.close();
        }
    }
}
```

解锁我们通过`jedis.eval`来执行一段LUA就可以.将锁的Key键和生成的字符串当做参数传进来.

```dart
    /**
     * 解锁
     * @param id
     * @return
     */
    public boolean unlock(String id){
        Jedis jedis = jedisPool.getResource();
        String script =
                "if redis.call('get'，KEYS[1]) == ARGV[1] then" +
                        "   return redis.call('del'，KEYS[1]) " +
                        "else" +
                        "   return 0 " +
                        "end";
        try {
            Object result = jedis.eval(script， Collections.singletonList(lock_key)， 
                                    Collections.singletonList(id));
            if("1".equals(result.toString())){
                return true;
            }
            return false;
        }finally {
            jedis.close();
        }
    }
```

最后，我们可以在多线程环境下测试一下.我们开启1000个线程，对count进行累加.调用的时候，关键是唯一字符串的生成.这里，笔者使用的是`Snowflake`算法.

```java
@Controller
public class IndexController {

    @Autowired
    RedisLock redisLock;
    
    int count = 0;
    
    @RequestMapping("/index")
    @ResponseBody
    public String index() throws InterruptedException {

        int clientcount =1000;
        CountDownLatch countDownLatch = new CountDownLatch(clientcount);

        ExecutorService executorService = Executors.newFixedThreadPool(clientcount);
        long start = System.currentTimeMillis();
        for (int i = 0;i<clientcount;i++){
            executorService.execute(() -> {
            
                //通过Snowflake算法获取唯一的ID字符串
                String id = IdUtil.getId();
                try {
                    redisLock.lock(id);
                    count++;
                }finally {
                    redisLock.unlock(id);
                }
                countDownLatch.countDown();
            });
        }
        countDownLatch.await();
        long end = System.currentTimeMillis();
        logger.info("执行线程数:{}，总耗时:{}，count数为:{}"，clientcount，end-start，count);
        return "Hello";
    }
}
```

至此，单节点Redis的分布式锁的实现就已经完成了.比较简单，但是问题也比较大，最重要的一点是，锁不具有可重入性.

###### **[3] redisson**

> [Redisson](https://redisson.org/)是架设在[Redis](http://redis.cn/)基础上的一个Java驻内存数据网格（In-Memory Data Grid）.充分的利用了Redis键值数据库提供的一系列优势，基于Java实用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类.使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度.同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作.

相对于Jedis而言，Redisson强大的一批.当然了，随之而来的就是它的复杂性.它里面也实现了分布式锁，而且包含多种类型的锁，更多请参阅[分布式锁和同步器](https://github.com/redisson/redisson/wiki/8.-分布式锁和同步器)

**1、可重入锁**

上面我们自己实现的Redis分布式锁，其实不具有可重入性.那么下面我们先来看看Redisson中如何调用可重入锁.

在这里，笔者使用的是它的最新版本，3.10.1.

```xml
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.10.1</version>
</dependency>
```

首先，通过配置获取RedissonClient客户端的实例，然后`getLock`获取锁的实例，进行操作即可.

```csharp
public static void main(String[] args) {

    Config config = new Config();
    config.useSingleServer().setAddress("redis://127.0.0.1:6379");
    config.useSingleServer().setPassword("redis1234");
    
    final RedissonClient client = Redisson.create(config);  
    RLock lock = client.getLock("lock1");
    
    try{
        lock.lock();
    }finally{
        lock.unlock();
    }
}
```

**2、获取锁实例**

我们先来看`RLock lock = client.getLock("lock1");`  这句代码就是为了获取锁的实例，然后我们可以看到它返回的是一个`RedissonLock`对象.

```cpp
public RLock getLock(String name) {
    return new RedissonLock(connectionManager.getCommandExecutor()， name);
}
```

在`RedissonLock`构造方法中，主要初始化一些属性

```kotlin
public RedissonLock(CommandAsyncExecutor commandExecutor， String name) {
    super(commandExecutor， name);
    //命令执行器
    this.commandExecutor = commandExecutor;
    //UUID字符串
    this.id = commandExecutor.getConnectionManager().getId();
    //内部锁过期时间
    this.internalLockLeaseTime = commandExecutor.
                getConnectionManager().getCfg().getLockWatchdogTimeout();
    this.entryName = id + ":" + name;
}
```

**3、加锁**

当我们调用`lock`方法，定位到`lockInterruptibly`.在这里，完成了加锁的逻辑.

```java
public void lockInterruptibly(long leaseTime， TimeUnit unit) throws InterruptedException {
    
    //当前线程ID
    long threadId = Thread.currentThread().getId();
    //尝试获取锁
    Long ttl = tryAcquire(leaseTime， unit， threadId);
    // 如果ttl为空，则证明获取锁成功
    if (ttl == null) {
        return;
    }
    //如果获取锁失败，则订阅到对应这个锁的channel
    RFuture<RedissonLockEntry> future = subscribe(threadId);
    commandExecutor.syncSubscription(future);

    try {
        while (true) {
            //再次尝试获取锁
            ttl = tryAcquire(leaseTime， unit， threadId);
            //ttl为空，说明成功获取锁，返回
            if (ttl == null) {
                break;
            }
            //ttl大于0 则等待ttl时间后继续尝试获取
            if (ttl >= 0) {
                getEntry(threadId).getLatch().tryAcquire(ttl， TimeUnit.MILLISECONDS);
            } else {
                getEntry(threadId).getLatch().acquire();
            }
        }
    } finally {
        //取消对channel的订阅
        unsubscribe(future， threadId);
    }
    //get(lockAsync(leaseTime， unit));
}
```

如上代码，就是加锁的全过程.先调用`tryAcquire`来获取锁，如果返回值ttl为空，则证明加锁成功，返回；如果不为空，则证明加锁失败.这时候，它会订阅这个锁的Channel，等待锁释放的消息，然后重新尝试获取锁.流程如下：

![img](https:////upload-images.jianshu.io/upload_images/13230160-6c08ae68fe9a796f.png?imageMogr2/auto-orient/strip|imageView2/2/w/815/format/webp)



**获取锁**

获取锁的过程是怎样的呢？接下来就要看`tryAcquire`方法.在这里，它有两种处理方式，一种是带有过期时间的锁，一种是不带过期时间的锁.

```kotlin
private <T> RFuture<Long> tryAcquireAsync(long leaseTime， TimeUnit unit， final long threadId) {

    //如果带有过期时间，则按照普通方式获取锁
    if (leaseTime != -1) {
        return tryLockInnerAsync(leaseTime， unit， threadId， RedisCommands.EVAL_LONG);
    }
    
    //先按照30秒的过期时间来执行获取锁的方法
    RFuture<Long> ttlRemainingFuture = tryLockInnerAsync(
        commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout()，
        TimeUnit.MILLISECONDS， threadId， RedisCommands.EVAL_LONG);
        
    //如果还持有这个锁，则开启定时任务不断刷新该锁的过期时间
    ttlRemainingFuture.addListener(new FutureListener<Long>() {
        @Override
        public void operationComplete(Future<Long> future) throws Exception {
            if (!future.isSuccess()) {
                return;
            }

            Long ttlRemaining = future.getNow();
            // lock acquired
            if (ttlRemaining == null) {
                scheduleExpirationRenewal(threadId);
            }
        }
    });
    return ttlRemainingFuture;
}
```

接着往下看，`tryLockInnerAsync`方法是真正执行获取锁的逻辑，它是一段LUA脚本代码.在这里，它使用的是hash数据结构.

```csharp
<T> RFuture<T> tryLockInnerAsync(long leaseTime， TimeUnit unit，     
                            long threadId， RedisStrictCommand<T> command) {

        //过期时间
        internalLockLeaseTime = unit.toMillis(leaseTime);

        return commandExecutor.evalWriteAsync(getName()， LongCodec.INSTANCE， command，
                  //如果锁不存在，则通过hset设置它的值，并设置过期时间
                  "if (redis.call('exists'， KEYS[1]) == 0) then " +
                      "redis.call('hset'， KEYS[1]， ARGV[2]， 1); " +
                      "redis.call('pexpire'， KEYS[1]， ARGV[1]); " +
                      "return nil; " +
                  "end; " +
                  //如果锁已存在，并且锁的是当前线程，则通过hincrby给数值递增1
                  "if (redis.call('hexists'， KEYS[1]， ARGV[2]) == 1) then " +
                      "redis.call('hincrby'， KEYS[1]， ARGV[2]， 1); " +
                      "redis.call('pexpire'， KEYS[1]， ARGV[1]); " +
                      "return nil; " +
                  "end; " +
                  //如果锁已存在，但并非本线程，则返回过期时间ttl
                  "return redis.call('pttl'， KEYS[1]);"，
        Collections.<Object>singletonList(getName())， 
                internalLockLeaseTime， getLockName(threadId));
    }
```

这段LUA代码看起来并不复杂，有三个判断：

- **通过exists判断，如果锁不存在，则设置值和过期时间，加锁成功**
- **通过hexists判断，如果锁已存在，并且锁的是当前线程，则证明是重入锁，加锁成功**
- **如果锁已存在，但锁的不是当前线程，则证明有其他线程持有锁.返回当前锁的过期时间，加锁失败**

![img](https:////upload-images.jianshu.io/upload_images/13230160-2046b77640392660.png?imageMogr2/auto-orient/strip|imageView2/2/w/913/format/webp)

加锁成功后，在redis的内存数据中，就有一条hash结构的数据.Key为锁的名称；field为随机字符串+线程ID；值为1.如果同一线程多次调用`lock`方法，值递增1.



```css
127.0.0.1:6379> hgetall lock1
1) "b5ae0be4-5623-45a5-8faa-ab7eb167ce87:1"
2) "1"
```

**解锁**

我们通过调用`unlock`方法来解锁.

```php
public RFuture<Void> unlockAsync(final long threadId) {
    final RPromise<Void> result = new RedissonPromise<Void>();
    
    //解锁方法
    RFuture<Boolean> future = unlockInnerAsync(threadId);

    future.addListener(new FutureListener<Boolean>() {
        @Override
        public void operationComplete(Future<Boolean> future) throws Exception {
            if (!future.isSuccess()) {
                cancelExpirationRenewal(threadId);
                result.tryFailure(future.cause());
                return;
            }
            //获取返回值
            Boolean opStatus = future.getNow();
            //如果返回空，则证明解锁的线程和当前锁不是同一个线程，抛出异常
            if (opStatus == null) {
                IllegalMonitorStateException cause = 
                    new IllegalMonitorStateException("
                        attempt to unlock lock， not locked by current thread by node id: "
                        + id + " thread-id: " + threadId);
                result.tryFailure(cause);
                return;
            }
            //解锁成功，取消刷新过期时间的那个定时任务
            if (opStatus) {
                cancelExpirationRenewal(null);
            }
            result.trySuccess(null);
        }
    });

    return result;
}
```

然后我们再看`unlockInnerAsync`方法.这里也是一段LUA脚本代码.

```csharp
protected RFuture<Boolean> unlockInnerAsync(long threadId) {
    return commandExecutor.evalWriteAsync(getName()， LongCodec.INSTANCE， EVAL，
    
            //如果锁已经不存在， 发布锁释放的消息
            "if (redis.call('exists'， KEYS[1]) == 0) then " +
                "redis.call('publish'， KEYS[2]， ARGV[1]); " +
                "return 1; " +
            "end;" +
            //如果释放锁的线程和已存在锁的线程不是同一个线程，返回null
            "if (redis.call('hexists'， KEYS[1]， ARGV[3]) == 0) then " +
                "return nil;" +
            "end; " +
            //通过hincrby递减1的方式，释放一次锁
            //若剩余次数大于0 ，则刷新过期时间
            "local counter = redis.call('hincrby'， KEYS[1]， ARGV[3]， -1); " +
            "if (counter > 0) then " +
                "redis.call('pexpire'， KEYS[1]， ARGV[2]); " +
                "return 0; " +
            //否则证明锁已经释放，删除key并发布锁释放的消息
            "else " +
                "redis.call('del'， KEYS[1]); " +
                "redis.call('publish'， KEYS[2]， ARGV[1]); " +
                "return 1; "+
            "end; " +
            "return nil;"，
    Arrays.<Object>asList(getName()， getChannelName())， 
        LockPubSub.unlockMessage， internalLockLeaseTime， getLockName(threadId));

}
```

如上代码，就是释放锁的逻辑.同样的，它也是有三个判断：

- **如果锁已经不存在，通过publish发布锁释放的消息，解锁成功**
- **如果解锁的线程和当前锁的线程不是同一个，解锁失败，抛出异常**
- **通过hincrby递减1，先释放一次锁.若剩余次数还大于0，则证明当前锁是重入锁，刷新过期时间；若剩余次数小于0，删除key并发布锁释放的消息，解锁成功**

![img](https:////upload-images.jianshu.io/upload_images/13230160-34c1a3f8ec81a652.png?imageMogr2/auto-orient/strip|imageView2/2/w/876/format/webp)

至此，Redisson中的可重入锁的逻辑，就分析完了.但值得注意的是，上面的两种实现方式都是针对单机Redis实例而进行的.如果我们有多个Redis实例，请参阅**Redlock算法**.该算法的具体内容，请参考http://redis.cn/topics/distlock.html

https://blog.csdn.net/weixin_43258908/article/details/89199088

https://blog.csdn.net/liubenlong007/article/details/53690312?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare

https://blog.csdn.net/ai_goodStudent/article/details/86520018

- redis 服务器设置了一个 AOF 重写缓冲区.这个缓冲区在创建子进程后开始使用，当redis服务器执行一个客户端的写请求命令，之后将这个写命令也发送到 AOF 重写缓冲区.
- 当子进程完成 AOF 日志重写之后，给父进程发送信号，父进程接收此信号后，将 AOF 重写缓冲区的内容写到新的 AOF 文件中，保持数据的一致性.

###### [4] 牛客网总结

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629222006147.png" alt="image-20200629222006147" style="zoom:50%;" />

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629222115786.png" alt="image-20200629222115786" style="zoom:50%;" />

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629222136887.png" alt="image-20200629222136887" style="zoom:50%;" />

<img src="X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200629222204906.png" alt="image-20200629222204906" style="zoom:50%;" />

###### [5] 常用的分布式锁

https://www.jb51.net/article/184718.html

https://www.cnblogs.com/wlwl/p/11651409.html

https://www.cnblogs.com/owenma/p/12355262.html

**一、基于数据库实现分布式锁**

**1. 悲观锁**

利用select … where … for update 排他锁

注意: 其他附加功能与实现一基本一致，这里需要注意的是“where name=lock ”，name字段必须要走索引，否则会锁表.有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题.

**2. 乐观锁**

所谓乐观锁与前边最大区别在于基于CAS思想，是不具有互斥性，不会产生锁等待而消耗资源，操作过程中认为不存在并发冲突，只有update version失败后才能觉察到.我们的抢购、秒杀就是用了这种实现以防止超卖.
通过增加递增的版本号字段实现乐观锁

**二、基于jdk的实现方式**

**思路**：另启一个服务，利用jdk并发工具来控制唯一资源，如在服务中维护一个concurrentHashMap，其他服务对某个key请求锁时，通过该服务暴露的端口，以网络通信的方式发送消息，服务端解析这个消息，将concurrentHashMap中的key对应值设为true，分布式锁请求成功，可以采用基于netty通信调用，当然你想用java的bio、nio或者整合dubbo、spring cloud feign来实现通信也没问题
**缺点**：这种方式的分布式锁看似简单，但是要考虑可用性、可靠性、效率、扩展性的话，编码难度会比较高.

**三、基于缓存（Redis等）实现分布式锁**

1、官方叫做 RedLock 算法，是 redis 官方支持的分布式锁算法.

这个分布式锁有 3 个重要的考量点：

- 1.互斥（只能有一个客户端获取锁）
- 2.不能死锁
- 3.容错（只要大部分 redis 节点创建了这把锁就可以）

2、下面是redis分布式锁的各种实现方式和缺点，按照时间的发展排序

- 1、直接setnx
  直接利用setnx，执行完业务逻辑后调用del释放锁，简单粗暴
  **缺点**：如果setnx成功，还没来得及释放，服务挂了，那么这个key永远都不会被获取到
- 2、setnx设置一个过期时间
  为了改正第一个方法的缺陷，我们用setnx获取锁，然后用expire对其设置一个过期时间，如果服务挂了，过期时间一到自动释放
  **缺点**：setnx和expire是两个方法，不能保证原子性，如果在setnx之后，还没来得及expire，服务挂了，还是会出现锁不释放的问题
- 3、set nx px
  redis官方为了解决第二种方式存在的缺点，在2.8版本为set指令添加了扩展参数nx和ex，保证了setnx+expire的原子性，使用方法：
  `set key value ex 5 nx` 
  **缺点**：
  ①如果在过期时间内，事务还没有执行完，锁提前被自动释放，其他的线程还是可以拿到锁
  ②上面所说的那个缺点还会导致当前的线程释放其他线程占有的锁
- 4、加一个事务id
  上面所说的第一个缺点，没有特别好的解决方法，只能把过期时间尽量设置的长一点，并且最好不要执行耗时任务
  第二个缺点，可以理解为当前线程有可能会释放其他线程的锁，那么问题就转换为保证线程只能释放当前线程持有的锁，即setnx的时候将value设为任务的唯一id，释放的时候先get key比较一下value是否与当前的id相同，是则释放，否则抛异常回滚，其实也是变相地解决了第一个问题
  **缺点**：get key和将value与id比较是两个步骤，不能保证原子性
- 5、set nx px + 事务id + lua
  我们可以用lua来写一个getkey并比较的脚本，jedis/luttce/redisson对lua脚本都有很好的支持
  **缺点**：集群环境下，对master节点申请了分布式锁，由于redis的主从同步是异步进行的，master在内存中写入了nx之后直接返回，客户端获取锁成功，此时master节点挂了，并且数据还没来得及同步，另一个节点被升级为master，这样其他的线程依然可以获取锁
- 6、redlock
  为了解决上面提到的redis集群中的分布式锁问题，redis的作者antirez的提出了red lock的概念，假设集群中所有的n个master节点完全独立，并且没有主从同步，此时对所有的节点都去setnx，并且设置一个请求过期时间re和锁的过期时间le，同时re必须小于le（可以理解，不然请求3秒才拿到锁，而锁的过期时间只有1秒也太蠢了），此时如果有n / 2 + 1个节点成功拿到锁，此次分布式锁就算申请成功
  **缺点**：可靠性还没有被广泛验证，并且严重依赖时间，好的分布式系统应该是异步的，并不能以时间为担保，程序暂停、系统延迟等都可能会导致时间错误（网上还有很多人都对这个方法提出了质疑，比如full gc发生的锁的正确性问题，但是antirez都一一作出了解答，感兴趣的同学可以参考一下[这位同学的文章](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.xilidou.com%2F2017%2F10%2F23%2FRedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F)）

**四、基于zookeeper实现的分布式锁**

1. 实现方式

ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名.基于ZooKeeper实现分布式锁的步骤如下：

（1）创建一个目录mylock；
（2）线程A想获取锁就在mylock目录下创建临时顺序节点；
（3）获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；
（4）线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；
（5）线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁.

这里推荐一个Apache的开源库Curator，它是一个ZooKeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire方法用于获取锁，release方法用于释放锁.

**优点**：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题.

**缺点**：因为需要频繁的创建和删除节点，性能上不如Redis方式.

2. 两种利用特性实现原理：

- **1、利用临时节点特性**
  zookeeper的临时节点有两个特性，一是节点名称不能重复，二是会随着客户端退出而销毁，因此直接将key作为节点名称，能够成功创建的客户端则获取成功，失败的客户端监听成功的节点的删除事件
  **缺点**：所有客户端监听同一个节点，但是同时只有一个节点的事件触发是有效的，造成资源的无效调度
- **2、利用顺序临时节点特性**
  zookeeper的顺序临时节点拥有临时节点的特性，同时，在一个父节点下创建创建的子临时顺序节点，会根据节点创建的先后顺序，用一个32位的数字作为后缀，我们可以用key创建一个根节点，然后每次申请锁的时候在其下创建顺序节点，接着获取根节点下所有的顺序节点并排序，获取顺序最小的节点，如果该节点的名称与当前添加的名称相同，则表示能够获取锁，否则监听根节点下面的处于当前节点之前的节点的删除事件，如果监听生效，则回到上一步重新判断顺序，直到获取锁.

###### [6] 分布式锁三种实现方式

\1. 基于数据库实现分布式锁；

\2. 基于缓存（Redis等）实现分布式锁；

\3. 基于Zookeeper实现分布式锁；

**一， 基于数据库实现分布式锁**

\1. 悲观锁

利用select … where … for update 排他锁

注意: 其他附加功能与实现一基本一致，这里需要注意的是“where name=lock ”，name字段必须要走索引，否则会锁表.有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题.

\2. 乐观锁

所谓乐观锁与前边最大区别在于基于CAS思想，是不具有互斥性，不会产生锁等待而消耗资源，操作过程中认为不存在并发冲突，只有update version失败后才能觉察到.我们的抢购、秒杀就是用了这种实现以防止超卖.

通过增加递增的版本号字段实现乐观锁

**二， 基于缓存（Redis等）实现分布式锁**

\1. 使用命令介绍：

（1）SETNX

SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0.

（2）expire

expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁.

（3）delete

delete key：删除key

在使用Redis实现分布式锁的时候，主要就会使用到这三个命令.

\2. 实现思想：

（1）获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断.

（2）获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁.

（3）释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放.

**三， 基于Zookeeper实现分布式锁**

ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名.基于ZooKeeper实现分布式锁的步骤如下：

> （1）创建一个目录mylock；
> （2）线程A想获取锁就在mylock目录下创建临时顺序节点；
> （3）获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；
> （4）线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；
> （5）线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁.

这里推荐一个Apache的开源库Curator，它是一个ZooKeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire方法用于获取锁，release方法用于释放锁.

优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题.

缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式.

**四，对比**

数据库分布式锁实现

缺点：

1.db操作性能较差，并且有锁表的风险

2.非阻塞操作失败后，需要轮询，占用cpu资源;

3.长时间不commit或者长时间轮询，可能会占用较多连接资源

**Redis(缓存)分布式锁实现**

缺点：

1.锁删除失败 过期时间不好控制

2.非阻塞，操作失败后，需要轮询，占用cpu资源;

**ZK分布式锁实现**

缺点：性能不如redis实现，主要原因是写操作（获取锁释放锁）都需要在Leader上执行，然后同步到follower.

总之：ZooKeeper有较好的性能和可靠性.

从理解的难易程度角度（从低到高）数据库 > 缓存 > Zookeeper

从实现的复杂性角度（从低到高）Zookeeper >= 缓存 > 数据库

从性能角度（从高到低）缓存 > Zookeeper >= 数据库

从可靠性角度（从高到低）Zookeeper > 缓存 > 数据库

以上就是本文的全部内容，希望对大家的学习有所帮助，也希望大家多多支持脚本之家.

总结

**基于数据库分布式锁实现**

**优点**：直接使用数据库，实现方式简单.
**缺点**：

1. db操作性能较差，并且有锁表的风险
2. 非阻塞操作失败后，需要轮询，占用cpu资源;
3. 长时间不commit或者长时间轮询，可能会占用较多连接资源

**基于jdk的并发工具自己实现的锁**

**优点**：不需要引入中间件，架构简单
**缺点**：编写一个可靠、高可用、高效率的分布式锁服务，难度较大

**基于redis缓存**

\1. redis set px nx + 唯一id + lua脚本
**优点**：redis本身的读写性能很高，因此基于redis的分布式锁效率比较高
**缺点**：依赖中间件，分布式环境下可能会有节点数据同步问题，可靠性有一定的影响，如果发生则需要人工介入

\2. 基于redis的redlock
**优点**：可以解决redis集群的同步可用性问题
**缺点**：

1. 依赖中间件，并没有被广泛验证，维护成本高，需要多个独立的master节点；需要同时对多个节点申请锁，降低了一些效率 
2. 锁删除失败 过期时间不好控制
3. 非阻塞，操作失败后，需要轮询，占用cpu资源;

基于zookeeper的分布式锁

**优点**：不存在redis的超时、数据同步（zookeeper是同步完以后才返回）、主从切换（zookeeper主从切换的过程中服务是不可用的）的问题，可靠性很高

**缺点**：依赖中间件，保证了可靠性的同时牺牲了一部分效率（但是依然很高）.性能不如redis.

jdk的方式不太推荐.

1. 从理解的难易程度角度（从低到高）数据库 > 缓存 > Zookeeper
2. 从实现的复杂性角度（从低到高）Zookeeper >= 缓存 > 数据库
3. 从性能角度（从高到低）缓存 > Zookeeper >= 数据库
4. 从可靠性角度（从高到低）Zookeeper > 缓存 > 数据库

没有绝对完美的实现方式，具体要选择哪一种分布式锁，需要结合每一种锁的优缺点和业务特点而定

#### 8. Redis的I/O多路复用

https://www.jianshu.com/p/311f9d276b2a

###### [1] 为什么 Redis 中要使用 I/O 多路复用？

首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的.

**阻塞I/O：**

先来看一下传统的阻塞 I/O 模型到底是如何工作的：当使用 read 或者 write 对某一个文件描述符（File Descriptor 以下简称 FD)进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用.

![img](https://upload-images.jianshu.io/upload_images/13880925-cf34b76f18f4a53b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1000/format/webp)

###### [2] **I/O 多路复用模型**

https://blog.csdn.net/wuyangyang555/article/details/82146831

https://blog.csdn.net/wsx199397/article/details/38533239?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare

阻塞式的 I/O 模型并不能满足这里的需求，我们需要一种效率更高的 I/O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I/O 多路复用模型了：

**在 I/O 多路复用模型中，最重要的函数调用就是 select，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，select 方法就会返回可读以及可写的文件描述符个数**.

> 与此同时也有其它的 I/O 多路复用函数 epoll/kqueue/evport，它们相比 select 性能更优秀，同时也能支撑更多的服务.
>
> **文件描述符**：linux下，所有的操作都是对文件进行操作，而对文件的操作是利用[文件描述符](https://baike.baidu.com/item/文件描述符)(file descriptor)来实现的.**每个文件进程控制块中都有一份文件描述符表（可以把它看成是一个数组，里面的元素是指向file结构体指针类型），这个数组的下标就是文件描述符.**在[源代码](https://baike.baidu.com/item/源代码)中，一般用fd作为[文件描述符](https://baike.baidu.com/item/文件描述符)的标识.
>
> **套接字**：套接字是一种通信机制，凭借这种机制，客户/服务器系统的开发工作既可以在本地单机上进行，也可以跨网络进行，Linux所提供的功能（如打印服 务，ftp等）通常都是通过套接字来进行通信的，套接字的创建和使用与管道是有区别的，因为套接字明确地将客户和服务器区分出来，套接字可以实现将多个客 户连接到一个服务器.

![img](https://upload-images.jianshu.io/upload_images/13880925-ed04dfac6be688f0.png?imageMogr2/auto-orient/strip|imageView2/2/w/1000/format/webp)

在UNIX系统上，一切皆文件套接字也不例外，每一个套接字都有对应的fd（即文件描述符）我们简单看看这几个系统调用的原型.

###### [3] select

**select(int nfds， fd_set *r， fd_set *w，fd_set *e， struct timeval *timeout)**

对于select()，我们需要传3个集合，r（读），w（写）和e其中，r表示我们对哪些fd的可读事件感兴趣，w表示我们对哪些fd的可写事件感兴趣**每个集合其实是一个bitmap，通过0/1表示我们感兴趣的fd**.例如，

如：我们对于fd为6的可读事件感兴趣，那么r集合的第6个bit需要被设置为1这个系统调用会阻塞，直到我们感兴趣的事件（至少一个）发生调用返回时，内核同样使用这3个集合来存放fd实际发生的事件信息也就是说，调用前这3个集合表示我们感兴趣的事件，调用后这3个集合表示实际发生的事件.

select为最早期的UNIX系统调用，它存在4个问题：

1）**这3个bitmap有大小限制**（FD_SETSIZE，通常为1024）；

2）**由于这3个集合在返回时会被内核修改，因此我们每次调用时都需要重新设置**；

3）**我们在调用完成后需要扫描这3个集合才能知道哪些fd的读/写事件发生了，一般情况下全量集合比较大而实际发生读/写事件的fd比较少，效率比较低下；**

4）**内核在每次调用都需要扫描这3个fd集合，然后查看哪些fd的事件实际发生，在读/写比较稀疏的情况下同样存在效率问题.**

![image-20200720092539779](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200720092539779.png)

###### [4] poll

由于存在这些问题，于是人们对select进行了改进，从而有了poll

```c
poll(struct pollfd *fds， int nfds， inttimeout)

struct pollfd {int fd;short events;short revents;}
```

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.

poll调用需要传递的是一个**pollfd结构的数组**，调用返回时结果信息也存放在这个数组里面pollfd的结构中存放着fd我们对该fd感兴趣的事件(events)以及该fd实际发生的事件(revents)**，poll传递的不是固定大小的bitmap，因此select的问题1解决了**；**poll将感兴趣事件和实际发生事件分开了，因此select的问题2也解决了**但select的问题3和问题4仍然没有解决.

select问题3比较容易解决，只要系统调用返回的是实际发生相应事件的fd集合，我们便不需要扫描全量的fd集合.对于select的问题4，我们为什么需要每次调用都传递全量的fd呢？内核可不可以在第一次调用的时候记录这些fd，然后我们在以后的调用中不需要再传这些fd呢？问题的关键在于**无状态**对于每一次系统调用，内核不会记录下任何信息，所以每次调用都需要重复传递相同信息.

###### [5] **epoll**

上帝说要有状态，所以我们有了**epoll**和kqueue

```c
int epoll_create(int size);

int epoll_ctl(int epfd， int op， int fd，struct epoll_event *event);

int epoll_wait(int epfd， struct epoll_event*events， int maxevents， int timeout);
```

**epoll_create**的作用是创建一个context，这个context相当于状态保存者的概念

**epoll_ctl**的作用是，当你对一个新的fd的读/写事件感兴趣时，通过该调用将fd与相应的感兴趣事件更新到context中

**epoll_wait**的作用是，等待context中fd的事件发生

**epoll的解决方案不像select或poll一样每次都把current（现时发生的）轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表**）.epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd.

![image-20200720094515533](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200720094515533.png)

**epoll的两种工作方式：1.水平触发（LT）2.边缘触发（ET）** 

* **LT模式**：若就绪的事件一次没有处理完要做的事件，就会一直去处理.即就会将没有处理完的事件继续放回到就绪队列之中（即那个内核中的链表），一直进行处理. 
* **ET模式**：就绪的事件只能处理一次，若没有处理完会在下次的其它事件就绪时再进行处理.而若以后再也没有就绪的事件，那么剩余的那部分数据也会随之而丢失. 
  由此可见：ET模式的效率比LT模式的效率要高很多.只是如果使用ET模式，就要保证每次进行数据处理时，要将其处理完，不能造成数据丢失，这样对编写代码的人要求就比较高. 
  注意：ET模式只支持非阻塞的读写：为了保证数据的完整性.

###### [6] **Reactor 设计模式**

Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）

![img](https://upload-images.jianshu.io/upload_images/13880925-d45f44df7e39ed05.png?imageMogr2/auto-orient/strip|imageView2/2/w/1000/format/webp)

![img](https://upload-images.jianshu.io/upload_images/13880925-60b031d3effe4b8a.png?imageMogr2/auto-orient/strip|imageView2/2/w/876/format/webp)

**文件事件处理器使用 I/O 多路复用模块同时监听多个 FD**，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器.

虽然整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单.

**I/O 多路复用模块**

I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I/O 多路复用函数，为上层提供了相同的接口.

![img](https:////upload-images.jianshu.io/upload_images/13880925-32733025f1e5c721.png?imageMogr2/auto-orient/strip|imageView2/2/w/1000/format/webp)

在这里我们简单介绍 Redis 是如何包装 select 和 epoll 的，简要了解该模块的功能，整个 I/O 多路复用模块抹平了不同平台上 I/O 多路复用函数的差异性，提供了相同的接口：

- static int aeApiCreate(aeEventLoop *eventLoop)
- static int aeApiResize(aeEventLoop *eventLoop， int setsize)
- static void aeApiFree(aeEventLoop *eventLoop)
- static int aeApiAddEvent(aeEventLoop *eventLoop， int fd， int mask)
- static void aeApiDelEvent(aeEventLoop *eventLoop， int fd， int mask)
- static int aeApiPoll(aeEventLoop *eventLoop， struct timeval *tvp)

同时，因为各个函数所需要的参数不同，我们在每一个子模块内部通过一个 aeApiState 来存储需要的上下文信息：

```c
// select
typedef struct aeApiState {
    fd_set rfds， wfds;
    fd_set _rfds， _wfds;
} aeApiState;

// epoll
typedef struct aeApiState {
    int epfd;
    struct epoll_event *events;
} aeApiState;
```

这些上下文信息会存储在 eventLoop 的 void *state 中，不会暴露到上层，只在当前子模块中使用.

封装 select 函数

> select 可以监控 FD 的可读、可写以及出现错误的情况.

在介绍 I/O 多路复用模块如何对 select 函数封装之前，先来看一下 select 函数使用的大致流程：

```c
int fd = /* file descriptor */

fd_set rfds;
FD_ZERO(&rfds);
FD_SET(fd， &rfds)

for ( ; ; ) {
    select(fd+1， &rfds， NULL， NULL， NULL);
    if (FD_ISSET(fd， &rfds)) {
        /* file descriptor `fd` becomes readable */
    }
}
```

1. 初始化一个可读的 fd_set 集合，保存需要监控可读性的 FD；
2. 使用 FD_SET 将 fd 加入 rfds；
3. 调用 select 方法监控 rfds 中的 FD 是否可读；
4. 当 select 返回时，检查 FD 的状态并完成对应的操作.

而在 Redis 的 ae_select 文件中代码的组织顺序也是差不多的，首先在 aeApiCreate 函数中初始化 rfds 和 wfds：

```c
static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));
    if (!state) return -1;
    FD_ZERO(&state->rfds);
    FD_ZERO(&state->wfds);
    eventLoop->apidata = state;
    return 0;
}
```

而 aeApiAddEvent 和 aeApiDelEvent 会通过 FD_SET 和 FD_CLR 修改 fd_set 中对应 FD 的标志位：

```c
static int aeApiAddEvent(aeEventLoop *eventLoop， int fd， int mask) {
    aeApiState *state = eventLoop->apidata;
    if (mask & AE_READABLE) FD_SET(fd，&state->rfds);
    if (mask & AE_WRITABLE) FD_SET(fd，&state->wfds);
    return 0;
}
```

整个 ae_select 子模块中最重要的函数就是 aeApiPoll，它是实际调用 select 函数的部分，其作用就是在 I/O 多路复用函数返回时，将对应的 FD 加入 aeEventLoop 的 fired 数组中，并返回事件的个数：

```c
static int aeApiPoll(aeEventLoop *eventLoop， struct timeval *tvp) {
    aeApiState *state = eventLoop->apidata;
    int retval， j， numevents = 0;

    memcpy(&state->_rfds，&state->rfds，sizeof(fd_set));
    memcpy(&state->_wfds，&state->wfds，sizeof(fd_set));

    retval = select(eventLoop->maxfd+1，
                &state->_rfds，&state->_wfds，NULL，tvp);
    if (retval > 0) {
        for (j = 0; j <= eventLoop->maxfd; j++) {
            int mask = 0;
            aeFileEvent *fe = &eventLoop->events[j];

            if (fe->mask == AE_NONE) continue;
            if (fe->mask & AE_READABLE && FD_ISSET(j，&state->_rfds))
                mask |= AE_READABLE;
            if (fe->mask & AE_WRITABLE && FD_ISSET(j，&state->_wfds))
                mask |= AE_WRITABLE;
            eventLoop->fired[numevents].fd = j;
            eventLoop->fired[numevents].mask = mask;
            numevents++;
        }
    }
    return numevents;
}
```

###### [7] **封装 epoll 函数**

Redis 对 epoll 的封装其实也是类似的，使用 epoll_create 创建 epoll 中使用的 epfd：

```c
static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));

    if (!state) return -1;
    state->events = zmalloc(sizeof(struct epoll_event)*eventLoop->setsize);
    if (!state->events) {
        zfree(state);
        return -1;
    }
    state->epfd = epoll_create(1024); /* 1024 is just a hint for the kernel */
    if (state->epfd == -1) {
        zfree(state->events);
        zfree(state);
        return -1;
    }
    eventLoop->apidata = state;
    return 0;
}
```

在 aeApiAddEvent 中使用 epoll_ctl 向 epfd 中添加需要监控的 FD 以及监听的事件：

```c
static int aeApiAddEvent(aeEventLoop *eventLoop， int fd， int mask) {
    aeApiState *state = eventLoop->apidata;
    struct epoll_event ee = {0}; /* avoid valgrind warning */
    /* If the fd was already monitored for some event， we need a MOD
     * operation. Otherwise we need an ADD operation. */
    int op = eventLoop->events[fd].mask == AE_NONE ?
            EPOLL_CTL_ADD : EPOLL_CTL_MOD;

    ee.events = 0;
    mask |= eventLoop->events[fd].mask; /* Merge old events */
    if (mask & AE_READABLE) ee.events |= EPOLLIN;
    if (mask & AE_WRITABLE) ee.events |= EPOLLOUT;
    ee.data.fd = fd;
    if (epoll_ctl(state->epfd，op，fd，&ee) == -1) return -1;
    return 0;
}
```

由于 epoll 相比 select 机制略有不同，**在 epoll_wait 函数返回时并不需要遍历所有的 FD 查看读写情况；在 epoll_wait 函数返回时会提供一个 epoll_event 数组**：

```c
typedef union epoll_data {
    void    *ptr;
    int      fd; /* 文件描述符 */
    uint32_t u32;
    uint64_t u64;} epoll_data_t;

struct epoll_event {
    uint32_t     events; /* Epoll 事件 */
    epoll_data_t data;
};
```

> 其中保存了发生的 epoll 事件（EPOLLIN、EPOLLOUT、EPOLLERR 和 EPOLLHUP）以及发生该事件的 FD.

aeApiPoll 函数只需要将 epoll_event 数组中存储的信息加入 eventLoop 的 fired 数组中，将信息传递给上层模块：

```c
static int aeApiPoll(aeEventLoop *eventLoop， struct timeval *tvp) {
    aeApiState *state = eventLoop->apidata;
    int retval， numevents = 0;

    retval = epoll_wait(state->epfd，state->events，eventLoop->setsize，
            tvp ? (tvp->tv_sec*1000 + tvp->tv_usec/1000) : -1);
    if (retval > 0) {
        int j;

        numevents = retval;
        for (j = 0; j < numevents; j++) {
            int mask = 0;
            struct epoll_event *e = state->events+j;

            if (e->events & EPOLLIN) mask |= AE_READABLE;
            if (e->events & EPOLLOUT) mask |= AE_WRITABLE;
            if (e->events & EPOLLERR) mask |= AE_WRITABLE;
            if (e->events & EPOLLHUP) mask |= AE_WRITABLE;
            eventLoop->fired[j].fd = e->data.fd;
            eventLoop->fired[j].mask = mask;
        }
    }
    return numevents;
}
```

子模块的选择

因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I/O 多路复用函数作为子模块，提供给上层统一的接口；在 Redis 中，我们通过宏定义的使用，合理的选择不同的子模块：



```c
#ifdef HAVE_EVPORT#include "ae_evport.c"#else
    #ifdef HAVE_EPOLL
    #include "ae_epoll.c"
    #else
        #ifdef HAVE_KQUEUE
        #include "ae_kqueue.c"
        #else
        #include "ae_select.c"
        #endif
    #endif
#endif
```

因为 select 函数是作为 POSIX 标准中的系统调用，在不同版本的操作系统上都会实现，所以将其作为保底方案：

<img src="https:////upload-images.jianshu.io/upload_images/13880925-4f157293d864b83a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1000/format/webp" alt="img" style="zoom:67%;" />

Redis 会优先选择时间复杂度为 O(1)的 I/O 多路复用函数作为底层实现，包括 Solaries 10 中的 evport、Linux 中的 epoll 和 macOS/FreeBSD 中的 kqueue，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符.

但是如果当前编译环境没有上述函数，就会选择 select 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 O(n)，并且只能同时服务 1024 个文件描述符，所以一般并不会以 select 作为第一方案使用.

###### [8] select & poll & epoll比较

https://www.jianshu.com/p/c8f462827499

https://www.bilibili.com/video/BV1qJ411w7du

**select**： 单个进程所能打开的最大连接数有FD_SETSIZE宏定义， 其大小为1024或者2048； FD数目剧增后， 会带来性能问题；消息传递从内核到与到用户空间，需要copy数据；
 （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大

![image-20200711143703434](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200711143703434.png)

**poll**： 基本上与select一样， 不同点在于没有FD数目的限制， 因为底层实现不是一个数组， 而是链表；

![image-20200711144411018](X:\Users\xu\AppData\Roaming\Typora\typora-user-images\image-20200711144411018.png)

**epoll**： FD连接数虽然有限制， 但是很大几乎可以认为无限制；epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题； 内核和用户通过共享内存来传递消息；

>**什么是socket？**
>
>我们都知道unix(like)世界里，一切皆文件，而文件是什么呢？文件就是一二进制流而已，不管socket，还是FIFO、管道、终端，对我们来说，一切都是文件，一切都是流.在信息 交换的过程中，我们都是对这些流进行数据的收发操作，简称为I/O操作(input and output)，往流中读出数据，系统调用read，写入数据，系统调用write.不过话说回来了 ，计算机里有这么多的流，我怎么知道要操作哪个流呢？对，就是**文件描述符**，即通常所说的fd，一个fd就是一个整数，所以，对这个整数的操作，就是对这个文件（流）的操作.我们创建一个socket，通过系统调用会返回一个文件描述符，那么剩下对socket的操作就会转化为对这个描述符的操作.不能不说这又是一种分层和抽象的思想.
>
>> *socket*一般指套接字.所谓套接字(*Socket*)，就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象.

linux提供了select、poll、epoll接口来实现IO复用，三者的原型如下所示，本文从参数、实现、性能等方面对三者进行对比.

~~~c++
int select(int nfds， fd_set *readfds， fd_set *writefds， fd_set *exceptfds， struct timeval *timeout);
int poll(struct pollfd *fds， nfds_t nfds， int timeout);
int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeou);
~~~

**select、poll、epoll_wait参数及实现对比**

1. **int nfds**：select的第一个参数nfds为fdset集合中最大描述符值加1，fdset是一个位数组，其大小限制为__FD_SETSIZE（1024），位数组的每一位代表其对应的描述符是否需要被检查.

   **fd_set *readfds， fd_set *writefds， fd_set *exceptfds：**select的第二三四个参数表示需要关注读、写、错误事件的文件描述符位数组，这些参数既是输入参数也是输出参数，可能会被内核修改用于标示哪些描述符上发生了关注的事件.所以每次调用select前都需要重新初始化fdset.

   **struct timeval *timeout**：timeout参数为超时时间，该结构会被内核修改，其值为超时剩余的时间.

   select对应于内核中的sys_select调用，sys_select首先将第二三四个参数指向的fd_set拷贝到内核，然后对每个被SET的描述符调用进行poll，并记录在临时结果中（fdset），如果有事件发生，select会将临时结果写到用户空间并返回；当轮询一遍后没有任何事件发生时，如果指定了超时时间，则select会睡眠到超时，睡眠结束后再进行一次轮询，并将临时结果写到用户空间，然后返回.

   **select返回后**，需要逐一检查关注的描述符是否被SET（事件是否发生）.

2. **struct pollfd *fds：**poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次.

   poll的实现机制与select类似，其对应内核中的sys_poll，只不过poll向内核传递pollfd数组，然后对pollfd中的每个描述符进行poll，相比处理fdset来说，poll效率更高.poll返回后，需要对pollfd中的每个元素检查其revents值，来得指事件是否发生.


3. epoll通过epoll_create创建一个用于epoll轮询的描述符，通过epoll_ctl添加/修改/删除事件，通过epoll_wait检查事件，epoll_wait的第二个参数用于存放结果.

   epoll与select、poll不同，首先，其不用每次调用都向内核拷贝事件描述信息，在第一次调用后，事件信息就会与对应的epoll描述符关联起来.**另外epoll不是通过轮询，而是通过在等待的描述符上注册回调函数，当事件发生时，回调函数负责把发生的事件存储在就绪事件链表中，最后写到用户空间.**

   epoll返回后，该参数指向的缓冲区中即为发生的事件，对缓冲区中每个元素进行处理即可，而不需要像poll、select那样进行轮询检查.

   **select、poll、epoll_wait性能对比**
   select、poll的内部实现机制相似，性能差别主要在于向内核传递参数以及对fdset的位操作上，另外，select存在描述符数的硬限制，不能处理很大的描述符集合.这里主要考察poll与epoll在不同大小描述符集合的情况
   原文链接：https://blog.csdn.net/leafrenchleaf/article/details/84159301
   
   **拓展：目前的常用的IO复用模型有三种：select，poll，epoll。**
   
   (1)select==>时间复杂度O(n)
   
   它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。
   
   (2)poll==>时间复杂度O(n)
   
   poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， **但是它没有最大连接数的限制**，原因是它是基于链表来存储的.
   
   (3)epoll==>时间复杂度O(1)
   
   **epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**
   
   select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 
   
   epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

###### [9] 深入理解select、poll和epoll及区别：杂文

https://blog.csdn.net/wteruiycbqqvwt/article/details/90299610

https://blog.csdn.net/nanxiaotao/article/details/90612404?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare

原文链接：https://blog.csdn.net/nanxiaotao/article/details/90612404

#### 9. 多线程的 Redis

[link](https://baijiahao.baidu.com/s?id=1664285811566919896&wfr=spider&for=pc)

相信redis6.0以前一直都是单线程，到了6的版本才加入了多线程.

**一、问题概述**

Redis 6.0 之后的版本抛弃了单线程模型这一设计，原本使用单线程运行的 Redis 也开始选择性使用多线程模型，乍一看Redis的作者这么牛，也逃不过“真香定律”，

这个问题其实可以拆分，拆分为两个主要的问题：

（1）为什么 Redis 一开始选择单线程模型（单线程的好处）？

（2）为什么 Redis 在 6.0 之后加入了多线程（在某些情况下，单线程出现了缺点，多线程可以解决）？

随着时间的推移，单线程出现的问题也越来越多，原来的设计肯定就有些不合时宜，该做出改变就做出改变.技术并不是一成不变的.

**二、为什么Redis一开始使用单线程**

不管是单线程或者是多线程都是为了提升Redis的开发效率，因为Redis是一个基于内存的数据库，还要处理大量的外部的网络请求，这就不可避免的要进行多次IO.好在Redis使用了很多优秀的机制来保证了它的高效率.那么为什么Redis要设计成单线程模式的呢？可以总结如下：

（1）**IO多路复用**

我们来看一下Redis顶层设计.

![img](https://pics7.baidu.com/feed/dcc451da81cb39dba486f96646c28e22aa183092.jpeg?token=b7e96b5d677dac17de14489f884c271b)

FD是一个文件描述符，意思是表示当前文件处于可读、可写还是异常状态.使用 I/O 多路复用机制同时监听多个文件描述符的可读和可写状态.**你可以理解为具有了多线程的特点.**

一旦受到网络请求就会在内存中快速处理，由于绝大多数的操作都是纯内存的，所以处理的速度会非常地快.**也就是说在单线程模式下，即使连接的网络处理很多，因为有IO多路复用，依然可以在高速的内存处理中得到忽略.**

（2）**可维护性高**

多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题.单线程模式下，可以方便地进行调试和测试.

（3）**基于内存，单线程状态下效率依然高**

多线程能够充分利用CPU的资源，但对于Redis来说，由于基于内存速度那是相当的高，能达到在一秒内处理10万个用户请求，如果一秒十万还不能满足，那我们就可以使用Redis分片的技术来交给不同的Redis服务器.这样的做饭避免了在同一个 Redis 服务中引入大量的多线程操作.

而且基于内存，除非是要进行AOF备份，否则基本上不会涉及任何的 I/O 操作.这些数据的读写由于只发生在内存中，所以处理速度是非常快的；用多线程模型处理全部的外部请求可能不是一个好的方案.

**现在我们知道了基本上可以总结成两句话，基于内存而且使用多路复用技术，单线程速度很快，又保证了多线程的特点.因为没有必要使用多线程.**

**三、为什么引入多线程？**

刚刚说了一堆使用单线程的好处，现在话锋一转，又要说为什么要引入多线程，别不适应.引入多线程说明Redis在有些方面，单线程已经不具有优势了.

因为读写网络的read/write系统调用在Redis执行期间占用了大部分CPU时间，如果把网络读写做成多线程的方式对性能会有很大提升.

Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程.之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题.

Redis 在最新的几个版本中加入了一些可以被其他线程异步处理的删除操作，也就是我们在上面提到的 UNLINK、FLUSHALL ASYNC 和 FLUSHDB ASYNC，我们为什么会需要这些删除操作，而它们为什么需要通过多线程的方式异步处理？

我们知道Redis可以使用del命令删除一个元素，如果这个元素非常大，可能占据了几十兆或者是几百兆，那么在短时间内是不能完成的，这样一来就需要多线程的异步支持.

![img](https://pics4.baidu.com/feed/bd3eb13533fa828bbd4ad2d869cbc632960a5afe.jpeg?token=c7bd1ec4f81b30ba2d0916d7191e765c)

现在删除工作可以在后台进行.

**四、总结**

Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率.

**一句话讲完：之前用单线程是因为基于内存速度快，而且多路复用有多路复用的作用，也就是足够了，现在引入是因为在某些操作要优化，比如删除操作，因此引入了多线程.**

#### 10 Redis持久化方式

> 已订正

**1. Redis 提供了不同级别的持久化方式:**

- **RDB(Redis DataBase)持久化**：Redis 可以通**过创建快照来存储内存里面的数据在某个时间点上的副本到本地数据库中**，如果系统，Redis或者硬件其中之一崩溃，那么Redis将丢失最近一次创建快照之后写入的所有数据.
- **AOF(Append Only File)持久化**：**AOF持久化会将被执行的写命令写到AOF文件的末尾**，以此来记录数据发生的变化.它可以做到每秒一次的频率对AOF文件进行同步.
- **不持久化**：如果你只希望数据在服务器运行的时候存在，你也可以不使用任何持久化方式
- **RDB+AOF模式** ：在这种情况下， 当Redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.

**2. RDB的优点，和缺点**

**优点**：RDB是一个非常紧凑的文件，它保存了某个时间点的数据集，非常适用于数据集的备份，比如你可以在每个小时报保存一下过去24小时内的数据，同时每天保存过去30天的数据，这样即使出了问题你也可以根据需求恢复到不同版本的数据集.与AOF相比，**在恢复大的数据集的时候，RDB方式会更快一些**.

**缺点**：如果你希望在redis意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么RDB不适合你.**因为RDB更容易丢失数据**.虽然你可以配置不同的save时间点(例如每隔5分钟并且对数据集有100个写的操作)，是Redis要完整的保存整个数据集是一个比较繁重的工作，你通常会每隔5分钟或者更久做一次完整的保存，万一在Redis意外宕机，你可能会丢失几分钟的数据.RDB 需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致Redis在一些毫秒级内不能响应客户端的请求.

**3. AOF优点和缺点**

**优点**：使用AOF 会让你的Redis更加耐久: 你可以使用不同的fsync策略：无fsync，每秒fsync，每次写的时候fsync.使用默认的每秒fsync策略，Redis的性能依然很好(fsync是由后台线程进行处理的，主线程会尽力处理客户端请求)，**一旦出现故障，你最多丢失1秒的数据**.

**缺点**：对于相同的数据集来说，**AOF 文件的体积通常要大于 RDB 文件的体积**.根据所使用的 fsync 策略，**AOF 的速度可能会慢于 RDB .**

**4.  如何选择持久化方式**

**RDB 持久化恢复数据集的速度要比AOF快一点，但是容易丢失更多的数据.AOF可以在每秒进行一次记录，如果发生系统崩溃最多丢失1秒的数据，更加可靠.但是它AOF文件比较大，恢复速度要慢一点.**

如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化.有很多用户都只使用 AOF 持久化，但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快一般来说，如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能.

> **1. 快照与备份有什么区别？[link](https://www.zhihu.com/question/20374919)**
>
> **一句话答案：快照记录逻辑地址和物理地址的对应关系；备份则是数据存储的某一个时刻的副本.这是两种完全不同的概念.**
>
> **2. 内部存储与外部存储的区别：[link](https://blog.csdn.net/zhujunzhujun/article/details/78345554)**
>
> **内部存储：**
>
> 内部存储不是内存，而是一个位于系统中很特殊的一个位置.放入内部存储中的数据一般都只能被你的应用访问到，且一个应用所创建的所有文件都在应用包名相同的目录下，即/data/data/packagename.创建于内部存储的文件，是与这个应用关联起来的.当一个应用被卸载后，内部存储中的这些数据也被删除.
>
> **外部存储：**
>
> 最容易混淆的是外部存储，如果说pc上也要区分出外部存储和内部存储的话，那么自带的硬盘算是内部存储，U盘或者移动硬盘算是外部存储，因此我们很容易带着这样的理解去看待安卓手机，认为机身固有存储是内部存储，而扩展的T卡是外部存储.

#### 11. Redis哨兵（Sentinel）模式

>链接：https://www.jianshu.com/p/06ab9daf921d

**主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。**这不是一种推荐的方式，更多时候，我们优先考虑**哨兵模式**。

**一、哨兵模式概述**

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程。其原理是**哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。**

![img](https:////upload-images.jianshu.io/upload_images/11320039-57a77ca2757d0924.png?imageMogr2/auto-orient/strip|imageView2/2/w/507/format/webp)

这里的哨兵有两个作用

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机。

然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

用文字描述一下**故障切换（failover）**的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

**二、Redis配置哨兵模式**

配置3个哨兵和1主2从的Redis服务器来演示这个过程。

| 服务类型 | 是否是主服务器 | IP地址         | 端口  |
| -------- | -------------- | -------------- | ----- |
| Redis    | 是             | 192.168.11.128 | 6379  |
| Redis    | 否             | 192.168.11.129 | 6379  |
| Redis    | 否             | 192.168.11.130 | 6379  |
| Sentinel | -              | 192.168.11.128 | 26379 |
| Sentinel | -              | 192.168.11.129 | 26379 |
| Sentinel | -              | 192.168.11.130 | 26379 |

![img](https:////upload-images.jianshu.io/upload_images/11320039-3f40b17c0412116c.png?imageMogr2/auto-orient/strip|imageView2/2/w/747/format/webp)

多哨兵监控Redis

首先配置Redis的主从服务器，修改redis.conf文件如下

```bash
# 使得Redis服务器可以跨网络访问
bind 0.0.0.0
# 设置密码
requirepass "123456"
# 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置
slaveof 192.168.11.128 6379
# 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置
masterauth 123456
```

上述内容主要是配置Redis服务器，从服务器比主服务器多一个slaveof的配置和密码。

配置3个哨兵，每个哨兵的配置都是一样的。在Redis安装目录下有一个sentinel.conf文件，copy一份进行修改

```css
# 禁止保护模式
protected-mode no
# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。
sentinel monitor mymaster 192.168.11.128 6379 2
# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码
# sentinel auth-pass <master-name> <password>
sentinel auth-pass mymaster 123456
```

上述关闭了保护模式，便于测试。

有了上述的修改，我们可以进入Redis的安装目录的src目录，通过下面的命令启动服务器和哨兵

```bash
# 启动Redis服务器进程
./redis-server ../redis.conf
# 启动哨兵进程
./redis-sentinel ../sentinel.conf
```

注意启动的顺序。**首先是主机（192.168.11.128）的Redis服务进程，然后启动从机的服务进程，最后启动3个哨兵的服务进程。**

**三、Java中使用哨兵模式**

```csharp
/**
 * 测试Redis哨兵模式
 * @author liu
 */
public class TestSentinels {
    @SuppressWarnings("resource")
    @Test
    public void testSentinel() {
        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        jedisPoolConfig.setMaxTotal(10);
        jedisPoolConfig.setMaxIdle(5);
        jedisPoolConfig.setMinIdle(5);
        // 哨兵信息
        Set<String> sentinels = new HashSet<>(Arrays.asList("192.168.11.128:26379",
                "192.168.11.129:26379","192.168.11.130:26379"));
        // 创建连接池
        JedisSentinelPool pool = new JedisSentinelPool("mymaster", sentinels,jedisPoolConfig,"123456");
        // 获取客户端
        Jedis jedis = pool.getResource();
        // 执行两个命令
        jedis.set("mykey", "myvalue");
        String value = jedis.get("mykey");
        System.out.println(value);
    }
}
```

上面是通过Jedis进行使用的，同样也可以使用Spring进行配置RedisTemplate使用。

```jsx
        <bean id = "poolConfig" class="redis.clients.jedis.JedisPoolConfig">
            <!-- 最大空闲数 -->
            <property name="maxIdle" value="50"></property>
            <!-- 最大连接数 -->
            <property name="maxTotal" value="100"></property>
            <!-- 最大等待时间 -->
            <property name="maxWaitMillis" value="20000"></property>
        </bean>
        
        <bean id="connectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory">
            <constructor-arg name="poolConfig" ref="poolConfig"></constructor-arg>
            <constructor-arg name="sentinelConfig" ref="sentinelConfig"></constructor-arg>
            <property name="password" value="123456"></property>
        </bean>
        
        <!-- JDK序列化器 -->
        <bean id="jdkSerializationRedisSerializer" class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer"></bean>
        
        <!-- String序列化器 -->
        <bean id="stringRedisSerializer" class="org.springframework.data.redis.serializer.StringRedisSerializer"></bean>
        
        <bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate">
            <property name="connectionFactory" ref="connectionFactory"></property>
            <property name="keySerializer" ref="stringRedisSerializer"></property>
            <property name="defaultSerializer" ref="stringRedisSerializer"></property>
            <property name="valueSerializer" ref="jdkSerializationRedisSerializer"></property>
        </bean>
        
        <!-- 哨兵配置 -->
        <bean id="sentinelConfig" class="org.springframework.data.redis.connection.RedisSentinelConfiguration">
            <!-- 服务名称 -->
            <property name="master">
                <bean class="org.springframework.data.redis.connection.RedisNode">
                    <property name="name" value="mymaster"></property>
                </bean>
            </property>
            <!-- 哨兵服务IP和端口 -->
            <property name="sentinels">
                <set>
                    <bean class="org.springframework.data.redis.connection.RedisNode">
                        <constructor-arg name="host" value="192.168.11.128"></constructor-arg>
                        <constructor-arg name="port" value="26379"></constructor-arg>
                    </bean>
                    <bean class="org.springframework.data.redis.connection.RedisNode">
                        <constructor-arg name="host" value="192.168.11.129"></constructor-arg>
                        <constructor-arg name="port" value="26379"></constructor-arg>
                    </bean>
                    <bean class="org.springframework.data.redis.connection.RedisNode">
                        <constructor-arg name="host" value="192.168.11.130"></constructor-arg>
                        <constructor-arg name="port" value="26379"></constructor-arg>
                    </bean>
                </set>
            </property>
        </bean>
```

**四、哨兵模式的其他配置项**

| 配置项                           | 参数类型                     | 作用                                                         |
| -------------------------------- | ---------------------------- | ------------------------------------------------------------ |
| port                             | 整数                         | 启动哨兵进程端口                                             |
| dir                              | 文件夹目录                   | 哨兵进程服务临时文件夹，默认为/tmp，要保证有可写入的权限     |
| sentinel down-after-milliseconds | <服务名称><毫秒数（整数）>   | 指定哨兵在监控Redis服务时，当Redis服务在一个默认毫秒数内都无法回答时，单个哨兵认为的主观下线时间，默认为30000（30秒） |
| sentinel parallel-syncs          | <服务名称><服务器数（整数）> | 指定可以有多少个Redis服务同步新的主机，一般而言，这个数字越小同步时间越长，而越大，则对网络资源要求越高 |
| sentinel failover-timeout        | <服务名称><毫秒数（整数）>   | 指定故障切换允许的毫秒数，超过这个时间，就认为故障切换失败，默认为3分钟 |
| sentinel notification-script     | <服务名称><脚本路径>         | 指定sentinel检测到该监控的redis实例指向的实例异常时，调用的报警脚本。该配置项可选，比较常用 |

sentinel down-after-milliseconds配置项只是一个哨兵在超过规定时间依旧没有得到响应后，会自己认为主机不可用。对于其他哨兵而言，并不是这样认为。哨兵会记录这个消息，当拥有认为主观下线的哨兵达到sentinel monitor所配置的数量时，就会发起一次投票，进行failover，此时哨兵会重写Redis的哨兵配置文件，以适应新场景的需要。

# SpringMVC

#### **1、谈谈你对 MVC 模式的理解？**

MVC 是 Model — View — Controler 的简称，它是一种架构模式，它分离了表现与交互.它被分为三个核心部件：模型、视图、控制器.



![img](https://mmbiz.qpic.cn/mmbiz_png/I47RwB1Z6My1u9q6WKicg7V1wf3vbfZeUKf7cr0Y2icFq69fOS6Ial9hunHCyticY6Pp9ibUBkTWNeAGF6tvJGicrMg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Model（模型）：是程序的主体部分，主要包含业务数据和业务逻辑.在模型层，还会涉及到用户发布的服务，在服务中会根据不同的业务需求，更新业务模型中的数据.

View（视图）：是程序呈现给用户的部分，是用户和程序交互的接口，用户会根据具体的业务需求，在 View 视图层输入自己特定的业务数据，并通过界面的事件交互，将对应的输入参数提交给后台控制器进行处理.

Controller（控制器）：Controller 是用来处理用户输入数据，以及更新业务模型的部分.控制器中接收了用户与界面交互时传递过来的数据，并根据数据业务逻辑来执行服务的调用和更新业务模型的数据和状态.

#### **2、SpringMVC 的工作原理/执行流程？**

简单来说：客户端发送请求-> 前端控制器 DispatcherServlet 接受客户端请求 -> 找到处理器映射 HandlerMapping 解析请求对应的 Handler -> HandlerAdapter 会根据 Handler 来调用真正的处理器来处理请求，并处理相应的业务逻辑 -> 处理器返回一个**模型视图 ModelAndView** -> 视图解析器进行解析 -> 返回一个视图对象 -> **前端控制器 DispatcherServlet 渲染数据（Model）**-> 将得到视图对象返回给用户.

![img](https://mmbiz.qpic.cn/mmbiz_png/I47RwB1Z6My1u9q6WKicg7V1wf3vbfZeUJhbibaKxRPJI2W9lcQYt8hzvMXbI5yPsVibCXdDonMgQ8WIPRMoWSSDw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上图用于辅助理解，面试时可用下列 8 步描述 SpringMVC 运行流程：

1. 用户向服务器发送请求，请求被 Spring 前端控制Servelt DispatcherServlet 捕获；

2. DispatcherServlet 对请求 URL 进行解析，得到请求资源标识符（URI）.然后根据该 URI，调用 **HandlerMapping 获得该 Handler 配置的所有相关的对象（包括 Handler 对象以及 Handler 对象对应的拦截器），最后以 HandlerExecutionChain 对象的形式返回**；

3. DispatcherServlet 根据获得的 Handler，选择一个合适的HandlerAdapter；（附注：如果成功获得HandlerAdapter 后，此时将开始执行拦截器的 preHandler(...)方法）

4. **提取 Request 中的模型数据，填充 Handler 入参，开始执行Handler（Controller)**.在填充 Handler 的入参过程中，根据你的配置，Spring 将帮你做一些额外的工作：

（1）**HttpMessageConveter**：将请求消息（如：Json、xml 等数据）转换成一个对象，将对象转换为指定的响应信息；

（2）**数据转换**：对请求消息进行数据转换.如：String 转换成 Integer、Double 等；

（3）**数据格式化**：对请求消息进行数据格式化.如：将字符串转换成格式化数字或格式化日期等；

（4）**数据验证**：验证数据的有效性（长度、格式等），验证结果存储到 BindingResult 或 Error 中;

5. **Handler 执行完成后，向 DispatcherServlet 返回一个 ModelAndView 对象**；

6. 根据返回的 ModelAndView，选择一个适合的 ViewResolver（必须是已经注册到 Spring 容器中的 ViewResolver)返回给DispatcherServlet； 

7. **ViewResolver 结合 Model 和 View，来渲染视图**；

8. 将渲染结果返回给客户端.

#### **3、SpringMVC 的核心组件有哪些？**

- **1. 前端控制器 DispatcherServlet**

作用：Spring MVC 的入口函数.接收请求，响应结果，相当于转发器，中央处理器.有了 DispatcherServlet 减少了其它组件之间的耦合度.用户请求到达前端控制器，它就相当于 MVC 模式中的 C，DispatcherServlet 是整个流程控制的中心，由它调用其它组件处理用户的请求，DispatcherServlet 的存在降低了组件之间的**耦合性**.

> “耦合性(Coupling)，也叫耦合度，是对模块间关联程度的度量.耦合的强弱取决于模块间接口的复杂性、调用模块的方式以及通过界面传送数据的多少.**模块间的耦合度是指模块之间的依赖关系，包括控制关系、调用关系、数据传递关系.模块间联系越多，其耦合性越强，同时表明其独立性越差( 降低耦合性，可以提高其独立性).软件设计中通常用耦合度和内聚度作为衡量模块独立程度的标准**.划分模块的一个准则就是高内聚低耦合.”

- **2. 处理器映射器 HandlerMapping**

作用：根据请求的 url 查找 Handler.HandlerMapping 负责根据用户请求找到 Handler 即处理器（Controller），SpringMVC 提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等.

- **3. 处理器适配器 HandlerAdapter**

作用：按照特定规则（HandlerAdapter 要求的规则）去执行 Handler.通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行.

- **4. 处理器 Handler**

注意：编写 Handler 时按照 HandlerAdapter 的要求去做，这样适配器才可以去正确执行 Handler.Handler 是继 DispatcherServlet 前端控制器的后端控制器，在 DispatcherServlet 的控制下 Handler 对具体的用户请求进行处理.由于 Handler 涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发 Handler.

- **5. 视图解析器 View resolver**

作用：**进行视图解析，根据逻辑视图名解析成真正的视图（View** ）.View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户.SpringMVC 框架提供了很多的 View 视图类型，包括：jstlView、freemarkerView、pdfView 等.一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面.

- **6. 视图 View**

View 是一个接口，实现类支持不同的 View 类型（jsp、freemarker...）.

注意：处理器 Handler（也就是我们平常说的 Controller 控制器）以及视图层 View 都是需要我们自己手动开发的.其他的一些组件比如：前端控制器 DispatcherServlet、处理器映射器 HandlerMapping、处理器适配器 HandlerAdapter 等等都是框架提供给我们的，不需要自己手动开发.

#### **4、SpringMVC 常用的注解有哪些？**

1. @RequestMapping：**用于处理请求 url 映射的注解，可用于类或方法上**.用于类上，则表示类中的所有响应请求的方法都是以该地址作为父路径；

2. @RequestBody：注解实现接收 HTTP 请求的 json 数据，将 json 转换为 Java 对象；

3. @ResponseBody：注解实现将 Controller 方法返回对象转化为 json 对象响应给客户.

#### **5、@RequestMapping 的作用是什么？**

RequestMapping 是一个用来处理请求地址映射的注解，可用于类或方法上.用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径.RequestMapping 注解有六个属性，下面我们把它分成三类进行说明.

- **value、method：**

1. value：**指定请求的实际地址，指定的地址可以是 URI Template 模式**；

2. method：**指定请求的method类型， GET、POST、PUT、DELETE 等**；

- **consumes、produces：**

1. consumes：指定处理请求的提交内容类型（Content-Type），例如 application/json、text/html；

2. produces：指定返回的内容类型，仅当 request 请求头中的（Accept）类型中包含该指定类型才返回；

- **params、header：**

1. params：指定 request 中必须包含某些参数值是，才让该方法处理.

2. headers：指定 request 中必须包含某些指定的 header 值，才能让该方法处理请求.

#### **6、如何解决 POST 请求中文乱码问题，GET 的又如何处理呢？**

1. 解决 POST 请求乱码问题：在 web.xml 中配置一个 CharacterEncodingFilter 过滤器，设置成 utf-8；

2. GET 请求中文参数出现乱码解决方法有两个：

（1）修改 tomcat 配置文件添加编码与工程编码一致，如下：

```
<ConnectorURIEncoding="utf-8" connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443"/>
```

（2）对参数进行重新编码：

```
String userName = new String(request.getParamter("userName").getBytes("ISO8859-1")，"utf-8")
```

#### **7、SpringMVC 的控制器是不是单例模式，如果是会有什么问题，怎么解决？**

**是单例模式**，所以在多线程访问的时候有线程安全问题.但是不要使用同步，会影响性能，解决方案是在控制器里面不能写字段.

#### **8、SpringMVC 怎么样设定重定向和转发的？**

1. 转发：在返回值前面加 "forward:"，譬如：

```
"forward:user.do?name=method2"
```

2. 重定向：在返回值前面加 "redirect:"，譬如：

```
"redirect:http://www.zju.com"
```

#### **9、SpringMVC 里面拦截器是怎么写的？**

方法一：实现 HandlerInterceptor 接口；

方法二：继承适配器类，接着在接口方法当中，实现处理逻辑，然后在 SpringMVC 的配置文件中配置拦截器即可.

#### **10、SpringMVC 和 Struts2 的区别有哪些?**

1. SpringMVC 的入口是一个 Servlet 即前端控制器（DispatchServlet），而 Struts2 入口是一个 filter 过虑器（StrutsPrepareAndExecuteFilter）；

2. SpringMVC 是基于方法开发（一个 url 对应一个方法），请求参数传递到方法的形参，可以设计为单例或多例（建议单例），Struts2 是基于类开发，传递参数是通过类的属性，只能设计为多例；

3. Struts2 采用值栈存储请求和响应的数据，通过 OGNL 存取数据；SpringMVC 通过参数解析器是将 request 请求内容解析，并给方法形参赋值，将数据和视图封装成 ModelAndView 对象，最后又将 ModelAndView 中的模型数据通过 request 域传输到页面.jsp 视图解析器默认使用 jstl.

# Spring

####  1. 讲下Spring框架

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200325171109126.png#pic_center =800x)

Spring框架，可以管理web层，业务层，Dao层，持久层，该**Spring可以配置各个层的组件（bean），并且维护各个bean之间的关系.**
bean元素的作用是，当Spring的框架加载的时候，Spring就会自动创建一个Bean对象，并放入内存.
Spring中的中一个重要概念**是IOC（控制反转），它可以将将对象间的依赖关系交给Spring容器**，使用配置文件来创建所依赖的对象，由主动创建对象改为了被动方式，实现解耦合.

#### 2. Spring与SpringMVC的区别

1. Spring是IOC和AOP的容器框架，SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring. 

>简单点的话可以将SpringMVC类比于Struts. 

2. Spring可以说是一个管理bean的容器，也可以说是包括很多开源项目的总称，spring mvc是其中一个开源项目.

#### 3. Spring与SpringBoot的关系

**Spring Boot 是 Spring 开源组织下的子项目，是 Spring 组件一站式解决方案，它的出现简化了使用 Spring 的难度**.同时它集成了大量常用的第三方库配置，大部分的 Spring Boot 应用都只需要非常少量的配置代码（基于 Java 的配置），开发者能够更加专注于业务逻辑.
SpringBoot的优点包括可以独立运行，简化了配置，可以实现自动配置，无代码生成以及XML配置，并且可以进行应用监控.

#### 3. SpringBoot优势

> 已订正

**1. Spring Boot 让开发变得更简单**

Spring Boot 对开发效率的提升是全方位的，我们可以简单做一下对比：

在没有使用 Spring Boot 之前我们开发一个 web 项目需要做哪些工作：

- 1）配置 web.xml，加载 Spring 和 Spring mvc
- 2）配置数据库连接、配置 Spring 事务
- 3）配置加载配置文件的读取，开启注解
- 4）配置日志文件
- …
- n) 配置完成之后部署 tomcat 调试

可能你还需要考虑各个版本的兼容性，jar 包冲突的各种可行性.

**2. Spring Boot 使测试变得更简单**

Spring Boot 对测试的支持不可谓不强大，Spring Boot 内置了7种强大的测试框架：

- JUnit： 一个 Java 语言的单元测试框架
- Spring Test & Spring Boot Test：为 Spring Boot 应用提供集成测试和工具支持
- AssertJ：支持流式断言的 Java 测试框架
- Hamcrest：一个匹配器库
- Mockito：一个 java mock 框架
- JSONassert：一个针对 JSON 的断言库
- JsonPath：JSON XPath 库

我们只需要在项目中引入`spring-boot-start-test`依赖包，就可以对数据库、Mock、 Web 等各种情况进行测试.Spring Boot Test 中包含了我们需要使用的各种测试场景，满足我们日常项目的测试需求.

**3. Spring Boot 让配置变得更简单**

Spring Boot 让配置变简单，说到这里我们就需要了解一下 Spring Boot 的核心思想：约定优于配置（convention over configuration）.也称作按约定编程，是一种软件设计范式，旨在减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性.

>参考网站：
>
>springboot 的优点和不足：[link](https://www.jianshu.com/p/eb591c7363ca)
>
>使用SpringBoot的优势：[link](https://www.cnblogs.com/fenghh/p/9617648.html)

#### 4. Spring 、Spring Boot 和 Spring Cloud 的关系

> 已订正

**1.Spring**

Spring 最初最核心的两大核心功能 **Spring Ioc** 和 **Spring Aop** 成就了 Spring，Spring 在这两大核心的功能上不断的发展，才有了 Spring 事务、Spirng Mvc 等一系列伟大的产品，最终成就了 Spring 帝国，到了后期 Spring 几乎可以解决企业开发中的所有问题.

**2. Spring Boot**

Spring Boot 是在强大的 Spring 帝国生态基础上面发展而来，发明 Spring Boot 不是为了取代 Spring ，是为了让人们更容易的使用 Spring .所以说没有 Spring 强大的功能和生态，就不会有后期的 Spring Boot 火热， Spring Boot 使用约定优于配置的理念，重新重构了 Spring 的使用，让 Spring 后续的发展更有生命力.

**3. Spring  Cloud**

Spring Cloud 是一系列框架的有序集合.它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署.

**4. Spring 、Spring Boot 和 Spring Cloud 的关系**

Spring 并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包.

根据上面的说明我们可以看出来，Spring Cloud 是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，并且 Spring Cloud 是完全基于 Spring Boot 而开发，Spring Cloud 利用 Spring Boot 特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案.

综上我们可以这样来理解，正是由于 Spring Ioc 和 Spring Aop 两个强大的功能才有了 Spring ，Spring 生态不断的发展才有了 Spring Boot ，使用 Spring Boot 让 Spring 更易用更有生命力，Spring Cloud 是基于 Spring Boot 开发的一套微服务架构下的服务治理方案.

用一组不太合理的包含关系来表达它们之间的关系.

>Spring 、Spring Boot 和 Spring Cloud 的关系：[link](https://www.cnblogs.com/fenghh/p/9617648.html)

#### 4. SpringBoot常用注解

https://www.cnblogs.com/xiaoxi/p/5935009.html

@Configuration把一个类作为一个IoC容器，它的某个方法头上如果注册了@Bean，就会作为这个Spring容器中的Bean.
@Scope注解 作用域
@Lazy(true) 表示延迟初始化
**@Service用于标注业务层组件**
**@Controller用于标注控制层组件（如struts中的action）**
**@Repository用于标注数据访问组件，即DAO组件**
**@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注**
@Scope用于指定scope作用域的（用在类上）
@PostConstruct用于指定初始化方法（用在方法上）
@PreDestory用于指定销毁方法（用在方法上）
@DependsOn：定义Bean初始化及销毁时的顺序
@Primary：自动装配时当出现多个Bean候选者时，被注解为@Primary的Bean将作为首选者，否则将抛出异常
**@Autowired 默认按类型装配，如果我们想使用按名称装配，可以结合@Qualifier注解一起使用.如下：@Autowired @Qualifier("personDaoBean") 存在多个实例配合使用**
**@Resource默认按名称装配，当找不到与名称匹配的bean才会按类型装配.**
@PostConstruct 初始化注解
@PreDestroy 摧毁注解 默认 单例 启动就加载
@Async异步方法调用**@Test的使用 是该方法可以不用main方法调用就可以测试出运行结果，是一种测试方法**

#### 5. Spring IOC和AOP

**什么是Spring：**
  Spring是一个开源的，轻量级的IOC和AOP容器框架，简化了开发流程，方便了对其他框架的整合

**控制反转（Inversion Of Controll）:**
  将相互依赖对象的创建和协调工作都交由IOC容器来完成，当某个对象需要其他协作对象时，由IOC通过依赖注入(DI， Dependency Injection)的方式提供协作对象，达到只需要关注业务本身逻辑的目的.

**IOC源码中的实现思路**

1. **获取 Bean 的定义**
   Spring 中有 AnnotationConfigApplicationContext、ClassPathXmlApplicationContext 等类寻找定义的 Bean .
2. AnnotationConfigApplicationContext通过扫描包来寻找@Controller、@Service之类的注解，这些类都是@Component的派生注解.

3. 实例化 Bean 并利用反射注入字段或属性
4. 添加 Bean 到 Map 容器中

**面向切面编程（Aspect Oriented Programming）：**
效果：分离系统中的各种关注点，进一步解耦模块间的相互依赖，提高模块的重用性

**应用场景**：权限认证、日志、事务、全局事务处理等，几乎业务功能都需要的功能

**Spring AOP自动选择JDK动态代理和CGLIB动态代理：**
**JDK动态代理需要类实现接口**，重写类InvocationHandler中的invok方法，来调度目标对象的方法；

**CGLIB动态代理在运行时动态的生成某个类的子类**（如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的），重写接口MethodInterceptor中的intercept方法，来调度目标对象的方法.

使用AOP方式实现系读写分离

**代理模式**

Spring中基于AspectJ的AOP开发：
通过Pointcut定义表达式拦截指定的Joinpoint，再使用Advice在指定的位置增强.

#### 6 Bean生命周期

链接：https://www.zhihu.com/question/38597960/answer/77600561

![深究Spring中Bean的生命周期](https://www.javazhiyin.com/wp-content/uploads/2019/05/java0-1558500658.jpg)

**Bean 的生命周期**

如上图所示，Bean 的生命周期还是比较复杂的，下面来对上图每一个步骤做文字描述:

1. Spring启动**，查找并加载需要被Spring管理的bean，进行Bean的实例化**
2. Bean实例化后对将Bean的引入和值注入到Bean的**属性**中
3. 如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法**（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的**）
4. 如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入**（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等）**
5. 如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。**(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory )**
6. 如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。**（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能）**
7. 如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用**（作用与6的一样，只不过6是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 )**
8. 如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。
9. 此时，**Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。**
10. 如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。

#### 7. Spring事务及事务传播

**Spring 并不直接支持事务，只有当数据库支持事务时，Spring 才支持事务。**Spring中有**声明式**和**编程式（淘汰）事务**，声明式事务是基于Spring AOP方式实现的。**所谓事务传播机制，也就是在事务在多个方法的调用中是如何传递的，是重新创建事务还是使用父方法的事务？父方法的回滚对子方法的事务是否有影响？这些都是可以通过事务传播机制来决定的。**

**声明式事务隔离级别：**较SQL标准的四种隔离级别多一个，为使用数据库默认的隔离级别（isolation_default）。

**声明式事务传播特性：传播特性是Spring在当前线程内，处理多个数据库操作方法事务时所做的一种事务应用策略，且作用于内层的方法上**（多个方法的嵌套调用，最外层方法不存在传播）.

**Spring提供的事务七大传播方式：**

- **PROPAGATION_REQUIRED** （必须的，默认）– 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。
- **PROPAGATION_SUPPORTS**(支持) – 支持当前事务，如果当前没有事务，就以非事务方式执行。
- **PROPAGATION_MANDATORY** （强制）– 支持当前事务，如果当前没有事务，就抛出异常。
- **PROPAGATION_REQUIRES_NEW** (必须要新的) – 新建事务，如果当前存在事务，把当前事务挂起。
- **PROPAGATION_NOT_SUPPORTED** (不支持)– 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
- **PROPAGATION_NEVER**(从不) – 以非事务方式执行，如果当前存在事务，则抛出异常。
- **PROPAGATION_NESTED**(嵌套) – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 

>**当前是指外层事务。**
>
>**propagation_required（必须的，默认）**: 如果外层事务不存在，内层就主动开启事务；否则使用外层事务
>
>**propagation_supports(支持)** : 如果外层事务不存在，就不使用事务；否则使用外层事务**支持当前事务，如果当前没有事务，就以非事务方式执行。**
>
>**propagation_mandatory（强制）** : 如果外层事务不存在，就抛出异常；否则使用外层事务
>
>**propagation_requires_new(必须要新的)** ： 总是开启一个新事务；如果存在外层事务，就将外层事务挂起
>
>**propagation_not_supported(不支持)** : 总是不开启事务；如果存在外层事务，就将外层事务挂起
>
>**propagation_never(从不)** ：总是不使用事务；如果存在外层事务，就抛出异常.与mandatory相反
>
>**propagation_nested(嵌套)** ：如果外层事务不存在，就主动创建事务；否则创建嵌套的子事务.外层事务若回滚，会带着子事务一同回滚；子事务若回滚，则到 savepoint （即 刚进入 子事务的暂存点），不会影响到外层事务

**基本知识**

1. 事务传播机制只适用于**不同bean之间方法**的调用，如果一个bean中的两个方法互相调用并不会使用到事务传播。
2. 事务方法里如果抛**RuntimeException**，则会导致所有相关事务回滚，个别事务传播机制有点特殊，我们下面会讲到。
3. 事务方法里如果抛Throwable或者**Exception**，默认不会导致相关事务回滚，一般都会在出异常的地方提交，就有可能出现部分提交的问题。但可以配置rollback-for属性来控制。

**不同传播特性间的对比：**

https://blog.csdn.net/konaji/article/details/79626818

**nested** 与 **required** 外层事务不存在，都会主动创建事务，那他们两者有什么区别?
   required 外内层方法使用的是**同一个事务**，只要发生异常，外内层都要回滚；nested 内层使用的是**外层的子事务**，发生异常回滚时，要视情况而定（如上7中解释）.

**nested** 与 **requires_new** 在内层事务异常回滚时，都不会影响到外层事务，那他们两者有什么区别？
  nested使用的是外层事务的子事务，回滚时，会回到对应的 savepoint ，且外层事务的回滚会带动嵌套内层事务回滚；requires_new的外内层使用的是两个独立的事务，内层事务的操作，不会影响外层事务.

#### 8. Spring中的循环依赖

请讲一讲Spring中的循环依赖，我们的回答主要分下面几点

1. **什么是循环依赖？**
2. **什么情况下循环依赖可以被处理？**
3. **Spring是如何解决的循环依赖？**

同时本文希望纠正几个目前业界内经常出现的几个关于循环依赖的错误的说法

1. 只有在setter方式注入的情况下，循环依赖才能解决（**错**）
2. 三级缓存的目的是为了提高效率（**错**）

OK，铺垫已经做完了，接下来我们开始正文

**什么是循环依赖？**

从字面上来理解就是**A依赖B的同时B也依赖了A**，就像下面这样

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXbzgpQn8mteUQCjYy7iaHsxsEWwnjG9dKzPt9bCDmBgtcP0JaLNI0MoQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


体现到代码层次就是这个样子

```
@Component
public class A {
    // A中注入了B
 @Autowired
 private B b;
}

@Component
public class B {
    // B中也注入了A
 @Autowired
 private A a;
}
```

当然，这是最常见的一种循环依赖，比较特殊的还有

```
// 自己依赖自己
@Component
public class A {
    // A中注入了A
 @Autowired
 private A a;
}
```

虽然体现形式不一样，但是实际上都是同一个问题----->循环依赖

**什么情况下循环依赖可以被处理？**

在回答这个问题之前首先要明确一点，Spring解决循环依赖是有前置条件的

1. 出现循环依赖的Bean必须要是**单例**
2. 依赖注入的方式不能全是构造器注入的方式（很多博客上说，只能解决setter方法的循环依赖，这是错误的）

其中第一点应该很好理解，第二点：不能全是构造器注入是什么意思呢？我们还是用代码说话

```
@Component
public class A {
// @Autowired
// private B b;
 public A(B b) {

 }
}


@Component
public class B {

// @Autowired
// private A a;

 public B(A a){

 }
}
```

在上面的例子中，A中注入B的方式是通过构造器，B中注入A的方式也是通过构造器，这个时候循环依赖是无法被解决，如果你的项目中有两个这样相互依赖的Bean，在启动时就会报出以下错误：

```
Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'a': Requested bean is currently in creation: Is there an unresolvable circular reference?
```

为了测试循环依赖的解决情况跟注入方式的关系，我们做如下四种情况的测试

| 依赖情况               | 依赖注入方式                                       | 循环依赖是否被解决 |
| :--------------------- | :------------------------------------------------- | :----------------- |
| AB相互依赖（循环依赖） | 均采用setter方法注入                               | 是                 |
| AB相互依赖（循环依赖） | 均采用构造器注入                                   | 否                 |
| AB相互依赖（循环依赖） | A中注入B的方式为setter方法，B中注入A的方式为构造器 | 是                 |
| AB相互依赖（循环依赖） | B中注入A的方式为setter方法，A中注入B的方式为构造器 | 否                 |

具体的测试代码很简单，我就不放了。从上面的测试结果我们可以看到，不是只有在setter方法注入的情况下循环依赖才能被解决，即使存在构造器注入的场景下，循环依赖依然被可以被正常处理掉。

那么到底是为什么呢？Spring到底是怎么处理的循环依赖呢？不要急，我们接着往下看

**Spring是如何解决的循环依赖？**

关于循环依赖的解决方式应该要分两种情况来讨论

1. 简单的循环依赖（没有AOP）
2. 结合了AOP的循环依赖

**简单的循环依赖（没有AOP）**

我们先来分析一个最简单的例子，就是上面提到的那个demo

```
@Component
public class A {
    // A中注入了B
 @Autowired
 private B b;
}

@Component
public class B {
    // B中也注入了A
 @Autowired
 private A a;
}
```

通过上文我们已经知道了这种情况下的循环依赖是能够被解决的，那么具体的流程是什么呢？我们一步步分析

首先，我们要知道**Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A**。

与此同时，我们应该知道，Spring在创建Bean的过程中分为三步

1. 实例化，对应方法：`AbstractAutowireCapableBeanFactory`中的`createBeanInstance`方法
2. 属性注入，对应方法：`AbstractAutowireCapableBeanFactory`的`populateBean`方法
3. 初始化，对应方法：`AbstractAutowireCapableBeanFactory`的`initializeBean`

这些方法在之前源码分析的文章中都做过详细的解读了，如果你之前没看过我的文章，那么你只需要知道

1. 实例化，简单理解就是new了一个对象
2. 属性注入，为实例化中new出来的对象填充属性
3. 初始化，执行aware接口中的方法，初始化方法，完成`AOP`代理

基于上面的知识，我们开始解读整个循环依赖处理的过程，整个流程应该是以A的创建为起点，前文也说了，第一步就是创建A嘛！

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXr9WoZKU3wscwAH0IVUEUjPTEWdtaTKIibJ4s2T4vkV4R6y9A99XBYMA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


创建A的过程实际上就是调用`getBean`方法，这个方法有两层含义

1. 创建一个新的Bean
2. 从缓存中获取到已经被创建的对象

我们现在分析的是第一层含义，因为这个时候缓存中还没有A嘛！

**调用getSingleton(beanName)**

首先调用`getSingleton(a)`方法，这个方法又会调用`getSingleton(beanName, true)`，在上图中我省略了这一步

```
public Object getSingleton(String beanName) {
    return getSingleton(beanName, true);
}
```

`getSingleton(beanName, true)`这个方法实际上就是到缓存中尝试去获取Bean，整个缓存分为三级

1. `singletonObjects`，一级缓存，存储的是所有创建好了的单例Bean
2. `earlySingletonObjects`，完成实例化，但是还未进行属性注入及初始化的对象
3. `singletonFactories`，提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取到的对象

因为A是第一次被创建，所以不管哪个缓存中必然都是没有的，因此会进入`getSingleton`的另外一个重载方法`getSingleton(beanName, singletonFactory)`。

**调用getSingleton(beanName, singletonFactory)**

这个方法就是用来创建Bean的，其源码如下：

```
public Object getSingleton(String beanName, ObjectFactory<?> singletonFactory) {
    Assert.notNull(beanName, "Bean name must not be null");
    synchronized (this.singletonObjects) {
        Object singletonObject = this.singletonObjects.get(beanName);
        if (singletonObject == null) {

            // ....
            // 省略异常处理及日志
            // ....

            // 在单例对象创建前先做一个标记
            // 将beanName放入到singletonsCurrentlyInCreation这个集合中
            // 标志着这个单例Bean正在创建
            // 如果同一个单例Bean多次被创建，这里会抛出异常
            beforeSingletonCreation(beanName);
            boolean newSingleton = false;
            boolean recordSuppressedExceptions = (this.suppressedExceptions == null);
            if (recordSuppressedExceptions) {
                this.suppressedExceptions = new LinkedHashSet<>();
            }
            try {
                // 上游传入的lambda在这里会被执行，调用createBean方法创建一个Bean后返回
                singletonObject = singletonFactory.getObject();
                newSingleton = true;
            }
            // ...
            // 省略catch异常处理
            // ...
            finally {
                if (recordSuppressedExceptions) {
                    this.suppressedExceptions = null;
                }
                // 创建完成后将对应的beanName从singletonsCurrentlyInCreation移除
                afterSingletonCreation(beanName);
            }
            if (newSingleton) {
                // 添加到一级缓存singletonObjects中
                addSingleton(beanName, singletonObject);
            }
        }
        return singletonObject;
    }
}
```

上面的代码我们主要抓住一点，通过`createBean`方法返回的Bean最终被放到了一级缓存，也就是单例池中。

那么到这里我们可以得出一个结论：**一级缓存中存储的是已经完全创建好了的单例Bean**

**调用addSingletonFactory方法**

如下图所示：

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXqbInxnU2GDfYVucSNUDj7DosxW2p2TxUwibEOpKGwMdCic2VIVm8ibnNw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


在完成Bean的实例化后，属性注入之前Spring将Bean包装成一个工厂添加进了三级缓存中，对应源码如下：

```
// 这里传入的参数也是一个lambda表达式，() -> getEarlyBeanReference(beanName, mbd, bean)
protected void addSingletonFactory(String beanName, ObjectFactory<?> singletonFactory) {
    Assert.notNull(singletonFactory, "Singleton factory must not be null");
    synchronized (this.singletonObjects) {
        if (!this.singletonObjects.containsKey(beanName)) {
            // 添加到三级缓存中
            this.singletonFactories.put(beanName, singletonFactory);
            this.earlySingletonObjects.remove(beanName);
            this.registeredSingletons.add(beanName);
        }
    }
}
```

这里只是添加了一个工厂，通过这个工厂（`ObjectFactory`）的`getObject`方法可以得到一个对象，而这个对象实际上就是通过`getEarlyBeanReference`这个方法创建的。那么，什么时候会去调用这个工厂的`getObject`方法呢？这个时候就要到创建B的流程了。

当A完成了实例化并添加进了三级缓存后，就要开始为A进行属性注入了，在注入时发现A依赖了B，那么这个时候Spring又会去`getBean(b)`，然后反射调用setter方法完成属性注入。

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXBS9jPBeF8Xp9GDQWa0dibnlSLVgIhTgaz8DqIibb31f2pOs5LEqOXXFw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


因为B需要注入A，所以在创建B的时候，又会去调用`getBean(a)`，这个时候就又回到之前的流程了，但是不同的是，之前的`getBean`是为了创建Bean，而此时再调用`getBean`不是为了创建了，而是要从缓存中获取，因为之前A在实例化后已经将其放入了三级缓存`singletonFactories`中，所以此时`getBean(a)`的流程就是这样子了

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXVlZGALnia2xxbImpnj25Vppbib4VHrLdiaHqHOXzgPeBibqrNFvjfCI64g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


从这里我们可以看出，注入到B中的A是通过`getEarlyBeanReference`方法提前暴露出去的一个对象，还不是一个完整的Bean，那么`getEarlyBeanReference`到底干了啥了，我们看下它的源码

```
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
        for (BeanPostProcessor bp : getBeanPostProcessors()) {
            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {
                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;
                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);
            }
        }
    }
    return exposedObject;
}
```

它实际上就是调用了后置处理器的`getEarlyBeanReference`，而真正实现了这个方法的后置处理器只有一个，就是通过`@EnableAspectJAutoProxy`注解导入的`AnnotationAwareAspectJAutoProxyCreator`。**也就是说如果在不考虑**`AOP`的情况下，上面的代码等价于：

```
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    return exposedObject;
}
```

**也就是说这个工厂啥都没干，直接将实例化阶段创建的对象返回了！所以说在不考虑**`AOP`的情况下三级缓存有用嘛？讲道理，真的没什么用，我直接将这个对象放到二级缓存中不是一点问题都没有吗？如果你说它提高了效率，那你告诉我提高的效率在哪?

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXB53l5V1thJCQ4j8jqNWVXvjU2wRmaqcBWpd7kViawd6fMjyMlvuEd1w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


那么三级缓存到底有什么作用呢？不要急，我们先把整个流程走完，在下文结合`AOP`分析循环依赖的时候你就能体会到三级缓存的作用！

到这里不知道小伙伴们会不会有疑问，B中提前注入了一个没有经过初始化的A类型对象不会有问题吗？

答：不会

这个时候我们需要将整个创建A这个Bean的流程走完，如下图：

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuX9Qocjibiaz07hXItqjoWejaiauqu6uppr8hFv1T3U6RZdiaCOhSX5TW3iaA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


从上图中我们可以看到，虽然在创建B时会提前给B注入了一个还未初始化的A对象，但是在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化，所以这是没有问题的。

**结合了AOP的循环依赖**

之前我们已经说过了，在普通的循环依赖的情况下，三级缓存没有任何作用。三级缓存实际上跟Spring中的`AOP`相关，我们再来看一看`getEarlyBeanReference`的代码：

```
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
    Object exposedObject = bean;
    if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
        for (BeanPostProcessor bp : getBeanPostProcessors()) {
            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {
                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;
                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);
            }
        }
    }
    return exposedObject;
}
```

如果在开启`AOP`的情况下，那么就是调用到`AnnotationAwareAspectJAutoProxyCreator`的`getEarlyBeanReference`方法，对应的源码如下：

```
public Object getEarlyBeanReference(Object bean, String beanName) {
    Object cacheKey = getCacheKey(bean.getClass(), beanName);
    this.earlyProxyReferences.put(cacheKey, bean);
    // 如果需要代理，返回一个代理对象，不需要代理，直接返回当前传入的这个bean对象
    return wrapIfNecessary(bean, beanName, cacheKey);
}
```

回到上面的例子，我们对A进行了`AOP`代理的话，那么此时`getEarlyBeanReference`将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXPXibPhFlITR5HWxggc9P3PfRe1MibgsLZTRicfVHdeYJA0NXZ6b2HKMqA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

看到这个图你可能会产生下面这些疑问

1. 在给B注入的时候为什么要注入一个代理对象？

答：当我们对A进行了`AOP`代理时，说明我们希望从容器中获取到的就是A代理后的对象而不是A本身，因此把A当作依赖进行注入时也要注入它的代理对象

1. 明明初始化的时候是A对象，那么Spring是在哪里将代理对象放入到容器中的呢？

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXicTpnAQ7cGL42WJkIgtgYnzQAPIZj5C96EG3pYIiakkIXLleGKmA9W7A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


在完成初始化后，Spring又调用了一次`getSingleton`方法，这一次传入的参数又不一样了，false可以理解为禁用三级缓存，前面图中已经提到过了，在为B中注入A时已经将三级缓存中的工厂取出，并从工厂中获取到了一个对象放入到了二级缓存中，所以这里的这个`getSingleton`方法做的时间就是从二级缓存中获取到这个代理后的A对象。`exposedObject == bean`可以认为是必定成立的，除非你非要在初始化阶段的后置处理器中替换掉正常流程中的Bean，例如增加一个后置处理器：

```
@Component
public class MyPostProcessor implements BeanPostProcessor {
 @Override
 public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
  if (beanName.equals("a")) {
   return new A();
  }
  return bean;
 }
}
```

不过，请不要做这种骚操作，徒增烦恼！

1. 初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？

答：不会，这是因为不管是`cglib`代理还是`jdk`动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化

1. 三级缓存为什么要使用工厂而不是直接使用引用？换而言之，为什么需要这个三级缓存，直接通过二级缓存暴露一个引用不行吗？

答：**这个工厂的目的在于延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象**

我们思考一种简单的情况，就以单独创建A为例，假设AB之间现在没有依赖关系，但是A被代理了，这个时候当A完成实例化后还是会进入下面这段代码：

```
// A是单例的，mbd.isSingleton()条件满足
// allowCircularReferences：这个变量代表是否允许循环依赖，默认是开启的，条件也满足
// isSingletonCurrentlyInCreation：正在在创建A，也满足
// 所以earlySingletonExposure=true
boolean earlySingletonExposure = (mbd.isSingleton() && this.allowCircularReferences &&
                                  isSingletonCurrentlyInCreation(beanName));
// 还是会进入到这段代码中
if (earlySingletonExposure) {
 // 还是会通过三级缓存提前暴露一个工厂对象
    addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));
}
```

看到了吧，即使没有循环依赖，也会将其添加到三级缓存中，而且是不得不添加到三级缓存中，因为到目前为止Spring也不能确定这个Bean有没有跟别的Bean出现循环依赖。

假设我们在这里直接使用二级缓存的话，那么意味着所有的Bean在这一步都要完成`AOP`代理。这样做有必要吗？

不仅没有必要，而且违背了Spring在结合`AOP`跟Bean的生命周期的设计！Spring结合`AOP`跟Bean的生命周期本身就是通过`AnnotationAwareAspectJAutoProxyCreator`这个后置处理器来完成的，在这个后置处理的`postProcessAfterInitialization`方法中对初始化后的Bean完成`AOP`代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。

**三级缓存真的提高了效率了吗？**

现在我们已经知道了三级缓存的真正作用，但是这个答案可能还无法说服你，所以我们再最后总结分析一波，三级缓存真的提高了效率了吗？分为两点讨论：

1. 没有进行`AOP`的Bean间的循环依赖

从上文分析可以看出，这种情况下三级缓存根本没用！所以不会存在什么提高了效率的说法

1. 进行了`AOP`的Bean间的循环依赖

就以我们上的A、B为例，其中A被`AOP`代理，我们先分析下使用了三级缓存的情况下，A、B的创建流程

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuXyPibEX4RicjdOew3C3qwwxGmREqw4sWia4XusfBFfj7lxCk21G7vOTTzg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


假设不使用三级缓存，直接在二级缓存中

![img](https://mmbiz.qpic.cn/mmbiz_png/tpEILlElskLZVx9XICtHkcNxLxMg0TuX7Rd0bQL7RTl9ibP4WS0URgR9Vh6tDgAvIrY2zUGKg9Eb0IiaTVARIibjA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)


上面两个流程的唯一区别在于为A对象创建代理的时机不同，在使用了三级缓存的情况下为A创建代理的时机是在B中需要注入A的时候，而不使用三级缓存的话在A实例化后就需要马上为A创建代理然后放入到二级缓存中去。

对于整个A、B的创建过程而言，消耗的时间是一样的。

综上，不管是哪种情况，三级缓存提高了效率这种说法都是错误的！

**总结**

面试官：”Spring是如何解决的循环依赖？“

答：Spring通过**三级缓存**解决了**循环依赖**，其中一级缓存为单例池（`singletonObjects`）,二级缓存为早期曝光对象`earlySingletonObjects`，三级缓存为早期曝光对象工厂（`singletonFactories`）。

当A、B两个类发生循环引用时，在A完成实例化后，就使用**实例化**后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。

当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取：

**第一步**，先获取到三级缓存中的工厂；

**第二步**，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。

当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！

面试官：”为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？“

答：如果要使用二级缓存解决循环依赖，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过`AnnotationAwareAspectJAutoProxyCreator`这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。

>- A 创建过程中需要 B，于是 **A 将自己放到三级缓存里面** ，去实例化 B
>
>- B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了！
>
>- - **然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A**
>  - B 顺利初始化完毕，**将自己放到一级缓存里面**（此时B里面的A依然是创建中状态）
>
>- 然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，**并将自己放到一级缓存里面**

**一道思考题**

为什么在下表中的第三种情况的循环依赖能被解决，而第四种情况不能被解决呢？

提示：Spring在创建Bean时默认会根据自然排序进行创建，所以A会先于B进行创建

| 依赖情况               | 依赖注入方式                                       | 循环依赖是否被解决 |
| :--------------------- | :------------------------------------------------- | :----------------- |
| AB相互依赖（循环依赖） | 均采用setter方法注入                               | 是                 |
| AB相互依赖（循环依赖） | 均采用构造器注入                                   | 否                 |
| AB相互依赖（循环依赖） | A中注入B的方式为setter方法，B中注入A的方式为构造器 | 是                 |
| AB相互依赖（循环依赖） | B中注入A的方式为setter方法，A中注入B的方式为构造器 | 否                 |

# 消息队列

#### 1.  **消息队列的优点有哪些？**

消息队列的主要作用是：解耦、异步、削峰.

- **解耦**：**消费者和生产者互不影响，降低他们之间的耦合度.**A 系统通过接口调用发送数据到 B、C、D 三个系统.那如果现在 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？现在 A 系统又要发送第二种数据了呢？这样的话 A 系统的维护成本就非常的高，而且 A 系统要时时刻刻考虑B、C、D、E 四个系统如果出现故障该怎么办？A 系统是重发还是先把消息保存起来呢？使用消息队列就可以解决这个问题.A 系统只负责生产数据，不需要考虑消息被哪个系统来消费.

- **异步**：**生产者生产完消息直接放入消息队列中，不需要等待结果，继续处理其他.**A 系统需要发送个请求给 B 系统处理，由于 B 系统需要查询数据库花费时间较长，以至于 A 系统要等待 B 系统处理完毕后再发送下个请求，造成 A 系统资源浪费.使用消息队列后，A 系统生产完消息后直接丢进消息队列，不用等待 B 系统的结果，直接继续去干自己的事情了.

- **削峰**：**在请求数量太大导致系统无法承受的时候可以先放进消息队列再根据能力接受请求.**A 系统调用 B 系统处理数据，每天 0 点到 12 点，A 系统风平浪静，每秒并发请求数量就 100 个.结果每次一到 12 点 ~ 13 点，每秒并发请求数量突然会暴增到 1 万条.但是 B 系统最大的处理能力就只能是每秒钟处理 1000 个请求，这样系统很容易就会崩掉.这种情况可以引入消息队列，把请求数据先存入消息队列中，消费系统再根据自己的消费能力拉取消费.

#### 2. **消息队列的缺点有哪些？**

消息队列可能会引发：降低系统可用性、系统复杂度提高、一致性问题.

* **降低系统的可用性**：系统引入的外部依赖越多，越容易挂掉；

* **系统复杂度提高**：使用 MQ 后可能需要保证消息没有被重复消费、处理**消息丢失**的情况、保证消息传递的顺序性等等问题；

* **一致性问题**：A 系统处理完了直接返回成功了，但问题是：要是 B、C、D 三个系统那里，B 和 D 两个系统写库成功了，结果 C 系统写库失败了，就造成数据不一致了.

#### 3. 如何保证消息的有序性？

- **Kafka**：拆分多个 Queue，每个 Queue一个 Consumer（消费者），**就是多一些 Queue 而已**，确实是麻烦点；或者就一个 Queue 但是对应一个 Consumer，然后这个 Consumer 内部用内存队列做排队，然后分发给底层不同的 Worker 来处理.
- **RabbitMQ**：一个 Topic，一个 Partition，一个 Consumer，内部单线程消费，**单线程吞吐量太低，一般不会用这个**；写 N 个内存 Queue，具有相同 key 的数据都到同一个内存 Queue；然后对于 N 个线程，每个线程分别消费一个内存 Queue 即可，这样就能保证顺序性.

1. **应用场景方面**
   RabbitMQ：用于实时的，对可靠性要求较高的消息传递上.
   kafka：用于处于活跃的流式数据，大数据量的数据处理上.
2. **架构模型方面**
   producer，broker，consumer
   RabbitMQ：以broker为中心，有消息的确认机制
   kafka：以consumer为中心，无消息的确认机制

3. .**吞吐量方面**
   RabbitMQ：支持消息的可靠的传递，支持事务，不支持批量操作，基于存储的可靠性的要求存储可以采用内存或硬盘，吞吐量小.
   kafka：内部采用消息的批量处理，数据的存储和获取是本地磁盘顺序批量操作，消息处理的效率高，吞吐量高.
4. **.集群负载均衡方面**
   RabbitMQ：本身不支持负载均衡，需要loadbalancer的支持
   kafka：采用zookeeper对集群中的broker，consumer进行管理，可以注册topic到zookeeper上，通过zookeeper的协调机制，producer保存对应的topic的broker信息，可以随机或者轮询发送到broker上，producer可以基于语义指定分片，消息发送到broker的某个分片上.


#### 4. 如何保证消息的可靠性传输？

<img src="X:\Users\xu\Desktop\微信图片_20200505143053.png" alt="微信图片_20200505143053" style="zoom: 67%;" />

**一、如果是生产者弄丢了数据**  

　　生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。  

此时可以选择用RabbitMQ提供的**事务功能**，就是生产者发送数据之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。这种方式**会降低吞吐量，影响性能**。

　　还有一种方式是开启**confirm模式**，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你说这个消息ok了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。  

　　**对比：**事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你一个接口通知你这个消息接收到了。  所以一般在生产者这块避免数据丢失，都是用confirm机制的。

**二、如果是RabbitMQ弄丢了数据**  

　　就是RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的**持久化**，**消息写入之后会持久化到磁盘**，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。  

　　**设置持久化有两个步骤**，第一个是创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。

　　必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。  而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。  

　　给RabbitMQ开启了持久化机制后，也还有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ挂了，就会导致内存里的一点点数据会丢失。

**三、消费端弄丢了数据**  

　　消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，RabbitMQ认为你都消费了，这数据就丢了。  这个时候得用RabbitMQ提供的ack机制，简单来说，就是你**关闭RabbitMQ自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把**。

　　这样的话，如果你还没处理完，不就没有ack？那RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。



<img src="X:\Users\xu\Desktop\微信图片_20200505143059.jpg" alt="微信图片_20200505143059" style="zoom:150%;" />

-

**消费端弄丢了数据**  

　　你消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费完了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢了。  

　　那么只要**关闭自动提交offset**，在处理完之后自己手动提交offset，就可以保证数据不会丢。

　　但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。  

**kafka弄丢了数据**  

　　这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？  

　　生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了  所以此时**一般是要求起码设置如下4个参数**：  

　　在topic设置**replication.factor**参数：这个值必须大于1，要求每个partition必须有至少2个副本  

　　在kafka服务端设置**min.insync.replicas**参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower  

　　在**producer**端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了  

　　在**producer**端设置retries=MAX（无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了  

　　我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失

**生产者会不会弄丢数据**

　　如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

#### 5. RabbitMQ如何实现消息确认机制？

https://www.cnblogs.com/DBGzxx/p/10091070.html

1. 当消息的投送方把消息投递出去，却不知道消息是否投递成功了.如果消息投送方不管的话，势必对系统的造成可靠性的影响.

2. 可是如果要保证系统的可靠性，消息投靠方，如何知道消息是否投放成功了呢？

3. 这个就需要消息的确认机制，我们来看下rabbitMQ的消息去人机制是如何做的.

   

   ![img](https://img2018.cnblogs.com/blog/1366148/201812/1366148-20181209141813371-1360392310.png)

   **消息的确认分两部分：rabbitMQ确认生产者投递的消息 和 消费者确认 rabbitMQ服务器的消息**

   1. 首先说RabbitMQ对生产者的确认，总共分为两种模式分别为 同步模式 与 异步模式.

      (1) 同步模式分为 单条消息确认 与 批量确认.

      ① 单条消息确认： channel.waitForConfirms() 普通发送方确认模式；消息到达交换器，就会返回true.

      ② 批量消息确认： channel.waitForConfirmsOrDie()批量确认模式；使用同步方式等所有的消息发送之后才会执行后面代码，只要有一个消息未到达交换器就会抛出IOException异常.

      （2) 异步模式为生产者 异步监听消息确认.

   　　异步监听消息确认：channel.addConfirmListener()异步监听发送方确认模式.

      　　 3. 其次说下消费者对RabbitMQ 消息确认.总共分为两种方式 分别为 手动确认 和 自动确认.

   消费者收到的每一条消息都必须进行确认.消息确认后，RabbitMQ才会从队列删除这条消息，RabbitMQ不会为未确认的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消的消费者连接是否已经断开.

   这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久.

   (1)　**自动确认**：

   消费者在声明队列时，可以指定autoAck参数，当autoAck=true时，一旦消费者接收到了消息，就视为自动确认了消息.如果消费者在处理消息的过程中，出了错，就没有什么办法重新处理这条消息，所以我们很多时候，

   需要在消息处理成功后，再确认消息，这就需要手动确认.

    (2) **手动确认**：

   　 ①当autoAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息.否则，RabbitMQ会在队列中消息被消费后立即删除它.

    ②采用消息确认机制后，只要令autoAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止.

   　③当autoAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息.如果服务器端一直没有收到消费

   者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）.

     ④通过运行程序，启动两个消费者A、B，都可以收到消息，但是其中有一个消费者A不会对消息进行确认，当把这个消费者A关闭后，消费者B又会收到本来发送给消费者A的消息.所以我们一般使用手动确认的方法是，将消息的处理放在try/catch语句块中，成功处理了，就给RabbitMQ一个确认应答，如果处理异常了，就在catch中，进行消息的拒绝

**附录：**

**RabbitMQ**

 ![img](https://img2018.cnblogs.com/blog/720994/201811/720994-20181126151921987-1605239540.png)

 

**Kafka**

 ![img](https://img2018.cnblogs.com/blog/720994/201811/720994-20181126155338611-169461800.png)



#### 6. 如何保证消息队列的高可用？

根据不同的 MQ 或者你用过的 MQ 进行回答：

- **RabbitMQ：镜像集群模式**

RabbitMQ 是基于主从做高可用性的，Rabbitmq有三种模式：单机模式、普通集群模式、镜像集群模式.单机模式一般在生产环境中很少用，普通集群模式只是提高了系统的吞吐量，让集群中多个节点来服务某个 Queue 的读写操作.那么真正实现 RabbitMQ 高可用的是镜像集群模式.

镜像集群模式跟普通集群模式不一样的是，创建的 Queue，无论元数据还是Queue 里的消息都会存在于多个实例上，然后每次你写消息到 Queue 的时候，都会自动和多个实例的 Queue 进行消息同步.这样设计，好处在于：任何一个机器宕机不影响其他机器的使用.坏处在于：1. 性能开销太大：消息同步所有机器，导致网络带宽压力和消耗很重；2. 扩展性差：如果某个 Queue 负载很重，即便加机器，新增的机器也包含了这个 Queue 的所有数据，并没有办法线性扩展你的 Queue.

- **Kafka：partition 和 replica 机制**

Kafka 基本架构是多个 broker 组成，每个 broker 是一个节点.创建一个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据，这就是天然的分布式消息队列.就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据.

Kafka 0.8 以前，是没有 HA 机制的，任何一个 broker 宕机了，它的 partition 就没法写也没法读了，没有什么高可用性可言.

Kafka 0.8 以后，提供了 HA 机制，就是 replica 副本机制.每个 partition 的数据都会同步到其他机器上，形成自己的多个 replica 副本.然后所有 replica 会选举一个 leader 出来，生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower.写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上数据即可.Kafka 会均匀的将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性.

#### 7. RabbitMQ/ActiveMQ/RocketMQ/Kafka对比

https://www.cnblogs.com/Terry-Wu/p/7644279.html

![img](https://blog-10039692.file.myqcloud.com/1506330751030_7532_1506330753496.png)

#### 8. RabbitMQ/ActiveMQ/RocketMQ/Kafka如何选择

https://www.cnblogs.com/chjxbt/p/11394185.html

https://www.cnblogs.com/xiapu5150/p/9927323.html

***一、选择消息队列产品的基本标准***

在消息队列的技术选型上，并不存在说哪个消息队列就是“最好的”.常用的几个消息队列，每个产品都有自己的优势和劣势，需要根据现有系统的情况，选择最适合的那款产品.

 

技术产品的及格标准：

- 必须是**开源产品**：如果遇到Bug至少有机会通过修改源代码迅速修复或规避，解决燃眉之急.
- 必须是近年来**比较流行**并且有一定**社区活跃度**的产品：流行的好处是，只要使用的场景不太冷门，遇到的Bug都可以找到解决办法.
- 流行的产品与**周边生态系统**会有一个比较好的集成和兼容：比如kafka和Flink就有比较好的兼容性，Flink内置了kafka的Data Sourse，使得你不用自己开发一个Flink的Data Source.

 

消息队列产品的及格标准：

- 消息的可靠传递：确保**不丢消息**.
- Cluster：支持**集群**，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息.
- 性能：具备足够好的性能，能**满足绝大多数场景**的性能要求.

 

***二、可供选择的消息队列产品***

**1、RabbitMQ**

介绍：

- 使用**Erlang语言编写**，最早是为电信行业系统之间的可靠通讯性设计的，也是少数几个**支持AMQP**协议的消息队列.
- **轻量级**、迅速，开箱即用，非常容易部署和使用.
- 有一个特色的功能是支持非常**灵活的路由配置**.它在生产者和队列之间增加了一个**Exchange模块**，可以理解为交换机，根据配置的路由规则将生产者发出的消息分发到不同的队列中.
- 客户端支持的编程语言是所有消息队列中最多的.

劣势：

- 对**消息堆积的支持并不好**.在它的设计理念中，消息队列是一个管道，大量的消息积压不是正常的情况，应当尽量避免.**当大量消息积压时，会导致性能急剧下降**.
- RabbitMQ的性能是介绍的几个消息队列中最差的，它大概每秒可以处理**几万到几十万**条消息，这个性能也足够支撑绝大多数场景.不过，如果你的应用**对消息队列的性能要求非常高，那就不要选择RabbitMQ**.
- 小众的编程语言Erlang.如果想基于RabbitMQ做一些扩展和二次开发，建议你慎重考虑可持续维护的问题.

 

**RabbitMQ 官方文档**：https://www.rabbitmq.com/documentation.html

 

**2、RocketMQ**

介绍：

- RocketMQ是阿里巴巴2012年开源的产品，后来捐赠给Apache软件基金会.2017年正式成为Apache的顶级项目.
- 阿里内部也是使用RocketMQ作为支撑其业务的消息队列，经历多次“双十一”考验，它的性能、稳定性和可靠性都是值得信赖的.
- 有非常活跃的**中文社区**，大多数问题都可以找到中文答案.使用**Java语言开发**，它的贡献者大多数为中国人，源代码相对比较易懂或**易进行扩展和二次开发**.
- RocketMQ对**在线业务的响应时延**做了很多优化，大多数情况下可以做到**毫秒级的响应**，如果你的应用场景很在意响应时延，那应该选择使用RocketMQ.
- RocketMQ的性能比RabbitMQ要高一个数量级，每秒大概能处理**几十万条消息**.

劣势：

- 作为国产消息队列，相比国外比较流行的同类产品，**与周边生态系统的集成和兼容程度要略逊一筹**.

 

**RocketMQ 官方文档**：https://rocketmq.apache.org/docs/quick-start/

**RocketMQ 中国开发者中心**：http://rocketmq.cloud/zh-cn/

 

**3、Kafka**

介绍：

- 最早是由LinkedIn开发，目前也是Apache的顶级项目.最初的设计目的是用于处理海量的日志.
- 与**周边生态系统的兼容性是最好的**，尤其在**大数据和流计算**领域，几乎所有的相关开源软件系统都会优化支持kafka.
- 使用Scala和Java语言开发，设计上大量使用了批量和异步的思想，这种设计使得Kafka能做到超高的性能，尤其是**异步收发性能**，是三者中最好.
- 大概每秒可处理几十万条消息

劣势：

- **同步收发消息的响应时延比较高**，当你的业务场景中，每秒消息数量没那么多时，kafka的时延反而会比较高.所以**不太适合在线业务场景**.

 

**Kafka 官方文档**：http://kafka.apache.org/documentation/

 

***三、第二梯队的消息队列***

这些产品之所有没那么流行，或多或少都有着比较明显的短板，不推荐使用，只是作简单介绍.

**1、ActiveMQ**

- 最老牌的开源消息队列，目前已进入**老年期**，**社区不活跃**.
- 功能或性能方面都与现代的消息队列**存在明显的差距**，它存在的意义仅限于兼容还在用的爷爷辈系统.

 

**2、ZeroMQ**

- 严格来说ZeroMQ并不能称之为一个消息队列，而是一个**基于消息队列的多线程网络库**.
- 如果你需要将消息队列的功能集成到你的系统进程中，可以考虑使用ZeroMQ.

 

**3、Pulsar**

- 一个新兴的开源消息队列产品，最早由Yahoo开发，目前处于成长期，流行度和成熟度相对没有那么高.
- 采用**存储和计算分离的设计**，有可能会引领未来消息队列的一个发展方向，建议持续关注这个项目.

 

***四、总结：***

选择的建议：

如果消息队列并不是将要构建系统的主角之一，对消息队列**功能和性能都没有很高的要求**，只需一个开箱即用易维护的产品，建议使用**RabbitMQ**.(有良好的运维界面，仅仅只是使用消息队列功能，用于**异步和业务模块解耦**，对性能要求不是很高.rabbitMQ能满足现阶段需求)

- 如果系统使用消息队列的场景是**处理在线业务**(在线业务指的是那种**服务于web页面或者APP的服务**，这种服务都需要很低的延迟，否则APP就会很卡，体验不好)，比如在交易系统中用消息队列传递订单，那**RocketMQ**的低延迟和金融级的稳定性是你需要的.
- 如果需要处理**海量的消息**，想收集日志、监控信息或是前端埋点这类数据，或应用场景大量使用了**大数据、流计算**(做事后的统计分析)相关的开源产品，那**kafka**是最适合的.

# Git

#### 1. Git是什么

Git它是一个免费开源的分布式版本控制系统，你可以使用Git提高我们处理一些大大小小的项目所有文件，可以说是提高团队开发效率神器.

#### 2. Git命令行入门

>简易的命令行入门教程:

Git 全局设置:

```
git config --global user.name "徐明晓"
git config --global user.email "1206512593@qq.com"
```

创建 git 仓库:

```
mkdir Code-practice
cd Code-practice
git init  //初始化一个Git仓库的
touch README.md
git add README.md 
git commit -m "first commit"
git remote add origin https://gitee.com/xumingxiao/Code-practice.git
git push -u origin master
```

已有仓库?

```
cd existing_git_repo
git remote add origin https://gitee.com/xumingxiao/Code-practice.git
git push -u origin master
```

https://baijiahao.baidu.com/s?id=1662514114882320614&wfr=spider&for=pc

#### 3. Git常用命令

**初始仓库常用命令**

1，git init：Git是使用git init命令来初始化一个Git仓库的，安装完Git时第一个使用命令就是Git init命令.

2，git clone：使用该命令的时候，是从Git仓库拷贝项目，常见的是我们经常去GitHub下载开源项目，就相当克隆项目到本地，正确使用命令格式是git clone <repo> <dirrectory>，repo表示Git仓库，directory表示本地目录.

**创建与合并分支**

1，gir add x.html：修改代码，意思就是修改x.htnl.

2，git commit -m x.htnl：提交代码，x.htnl就是需要提交的文件.

3，git checkout master & git merge dev：将dev合并到master.

4，git checkout master & git checkout -b dev：意思是从master分支创建dev分支并切换到dev分支.

5，git branch -D issues：本地强制删除分支issues.

6，git status：该命令是查看你上次提交之后是否有修改.

7，git diff：该命令是用来查看执行git status的结果的详细信息，也是常用的一个命令.

8，git rm：该命令也是删除文件，命令格式为git rm <删除的文件>

9，git mv：此命令就是重命名或者移动，学过Linux系统的话，对这些命令就很熟悉了.

**Bug分支常用命令**

1，git stash clear：该命令是将stash空间清除.

2，git stash pop：该命令就是恢复的同时把stash内容进行删除的.

3，git stash：此命令将当前更新的代码储藏，等恢复再使用.

**标签管理命令**

1，git tag -a v1.0：该命令的-a参数会允许你添加一些信息，注意的是当使用git tag -a的时候，Git会打开一个编辑器让你输入tag信息.

2，git log --pretty=oneline --abbrev -commit：该命令就是要给某一周commit打标签的意思.

3，git show v1.0.0：该命令是查看所有标签.

4，git tag -d v1.0.0：该命令删除本地标签

5，git tag -d v1.0.0：该命令先从本地删除标签，然后在用远程删除命令git push orign ：refs/tags/v1.0.0.

**提取远程仓库**

1，git fatch：该命令是从远程仓库下载分支和数据.

2，git mergez：该命令就是从远程仓库提取数据并合并当前分支.

3，git remote rm 别名：我们可以删除远程仓库.

# MyBatis

#### **1. 谈谈你对 MyBatis 的理解？**

1. Mybatis是一个半ORM（对象关系映射）框架，它内部封装了 JDBC（**指Java数据库连接**），开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 Statement 等繁杂的过程.程序员直接编写原生态 SQL，可以严格控制 SQL 执行性能，灵活度高.

2. MyBat**is 可以使用 XML 或注解来配置和映射原生信息**，将 POJO 映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集.

3. **通过 XML 文件或注解的方式将要执行的各种 Statement 配置起来，并通过 Java 对象和 Statement 中 SQL 的动态参数进行映射生成最终执行的 SQL 语句**，最后由 MyBatis 框架执行 SQL并将结果映射为 Java 对象并返回.（从执行 SQL到返回 Result 的过程）.

#### **2. MyBaits 的优缺点有哪些？**

- **优点：**

1. 基于 SQL 语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL 写在 XML 里，解除 SQL 与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态 SQL 语句，并可重用；

2. 与 JDBC 相比，减少了代码量，消除了 JDBC 大量冗余的代码，不需要手动开关连接；

3. 很好的与各种数据库兼容（因为 MyBatis 使用 JDBC 来连接数据库，所以只要 JDBC 支持的数据库 MyBatis 都支持）；

4. 提供映射标签，支持对象与数据库的 ORM 字段关系映射；提供对象关系映射标签，支持对象关系组件维护.

- **缺点：**

1. SQL 语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写 SQL 语句的功底有一定要求；

2. .SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库.

#### 3. MyBatis 与 Hibernate 有哪些不同？

1. MyBatis 和 Hibernate不同，它不完全是一个 ORM 框架，因为 MyBatis 需要程序员自己编写 SQL 语句；Hibernate 对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用 **Hibernate 开发可以节省很多代码，提高效率**；

2. MyBatis 直接编写原生态 SQL，可以严格控制 SQL 执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果.但是灵活的前提是 MyBatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套 SQL 映射文件，工作量大.

>对象/关系数据库映射(object/relational mapping(ORM))这个术bai语表示一种du技术，用来把对象模zhi型表示的对象映射到基于daoSQL的关系模型数据库结构中去.ORM，即Object-Relational Mapping（对象关系映射），它的作用是在关系型数据库和业务实体对象之间作一个映射，这样，我们在具体的操作业务对象的时候，就不需要再去和复杂的SQL语句打交道，只要像平时操作对象一样操作它就可以了.

#### **4、MyBatis 中 #{} 和 ${}的区别是什么？**

- **#{} 是预编译处理，${} 是字符串替换**

1. Mybatis 在处理 #{} 时，会将 SQL 中的 #{} 替换为 ? 号，调用 PreparedStatement 的 set 方法来赋值；使用 #{} 可以有效的防止 SQL 注入，提高系统安全性；

2. MyBatis 在处理 ${} 时，就是把 ${} 替换成变量的值.

#### **5、MyBatis 是如何进行分页的？分页插件的原理是什么？**

MyBatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页.可以在 SQL 内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页.

分页插件的基本原理是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 SQL，然后重写 SQL，根据 dialect 方言，添加对应的物理分页语句和物理分页参数.

#### **6、MyBatis 有几种分页方式？**

1. 数组分页

2. SQL 分页

3. 拦截器分页

4. RowBounds 分页

#### **7、MyBatis 逻辑分页和物理分页的区别是什么？**

1. 物理分页速度上并不一定快于逻辑分页，逻辑分页速度上也并不一定快于物理分页.

2. 物理分页总是优于逻辑分页：没有必要将属于数据库端的压力加到应用端来，就算速度上存在优势，然而其它性能上的优点足以弥补这个缺点.

#### **8、MyBatis 是否支持延迟加载？如果支持，它的实现原理是什么？**

Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询.在MyBatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false.

它的原理是，使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke() 方法发现 a.getB() 是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 SQL，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName() 方法的调用.这就是延迟加载的基本原理.

#### **9、说一下 MyBatis 的一级缓存和二级缓存？**

一级缓存：基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存；

二级缓存：与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache.默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现 Serializable 序列化接口(可用来保存对象的状态)，可在它的映射文件中配置 <cache/> ；

对于缓存数据更新机制，当某一个作用域(一级缓存 Session / 二级缓存 Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear.

#### **10、Mybatis 有哪些执行器（Executor）？**

Mybatis 有 3 种基本的执行器（Executor）：

1. SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象；

2. ReuseExecutor：执行 update 或 select，以 SQL 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map 内，供下一次使用.简言之，就是重复使用 Statement 对象；

3. BatchExecutor：执行 update（没有 select，JDBC 批处理不支持select），将所有 SQL 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement对 象都是 addBatch() 完毕后，等待逐一执行 executeBatch() 批处理.与 JDBC 批处理相同.

#### **11、MyBatis 动态 SQL 是做什么的？都有哪些动态 SQL？能简述一下动态 SQL的执行原理不？**

1. MyBatis 动态 SQL 可以让我们在 XML 映射文件内，以标签的形式编写动态 SQL，完成逻辑判断和动态拼接 SQL 的功能；

2. MyBatis 提供了 9 种动态 SQL 标签：trim、where、set、foreach、if、choose、when、otherwise、bind；

3. 执行原理：使用 OGNL 从 SQL 参数对象中计算表达式的值，根据表达式的值动态拼接 SQL，以此来完成动态 SQL 的功能.

> **对象导航图语言**（Object Graph Navigation Language），简称**OGNL**，是应用于[Java](https://baike.baidu.com/item/Java)中的一个[开源](https://baike.baidu.com/item/开源)的表达式语言（Expression Language），它被集成在[Struts2](https://baike.baidu.com/item/Struts2)等框架中，作用是对[数据](https://baike.baidu.com/item/数据)进行访问，它拥有[类型](https://baike.baidu.com/item/类型)转换、访问[对象](https://baike.baidu.com/item/对象)[方法](https://baike.baidu.com/item/方法)、操作[集合](https://baike.baidu.com/item/集合)对象等功能.

# Zookeeper

#### **1、谈下你对 Zookeeper 的认识？**

ZooKeeper 是一个**分布式**的，**开源**的**分布式应用程序协调服务**.它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等.ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户.

#### **2、Zookeeper 都有哪些功能？**

**1. 集群管理**：监控节点存活状态、运行请求等；

**2. 主节点选举**：主节点挂掉了之后可以从备用的节点开始新一轮选主，主节点选举说的就是这个选举的过程，使用 Zookeeper 可以协助完成这个过程；

**3. 分布式锁**：Zookeeper 提供两种锁：**独占锁**、**共享锁**.独占锁即一次只能有一个线程使用资源，共享锁是读锁共享，读写互斥，即可以有多线线程同时读同一个资源，如果要使用写锁也只能有一个线程使用.Zookeeper 可以对分布式锁进行控制.

**4. 命名服务**：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息.

#### **3、谈下你对 ZAB 协议的了解？**

**ZAB 协议**是为分布式协调服务 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议.ZAB 协议包括两种基本的模式：**崩溃恢复和消息广播.**当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步.当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理.

#### **4、Zookeeper 怎么保证主从节点的状态同步？**

Zookeeper 的核心是**原子广播**机制，这个机制保证了各个 server 之间的同步.实现这个机制的协议叫做 Zab 协议.Zab 协议有两种模式，它们分别是恢复模式和广播模式.

- **1. 恢复模式**

当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了.状态同步保证了 leader 和 server 具有相同的系统状态.

- **2. 广播模式**

一旦 leader 已经和多数的 follower 进行了状态同步后，它就可以开始广播消息了，即进入广播状态.这时候当一个 server 加入 ZooKeeper 服务中，它会在恢复模式下启动，发现 leader，并和 leader 进行状态同步.待到同步结束，它也参与消息广播.ZooKeeper 服务一直维持在 Broadcast 状态，直到 leader 崩溃了或者 leader 失去了大部分的 followers 支持.

#### 5**、Zookeeper 有几种部署模式？**

Zookeeper 有三种部署模式：

\1. 单机部署：一台集群上运行；

\2. 集群部署：多台集群运行；

\3. 伪集群部署：一台集群启动多个 Zookeeper 实例运行.

#### 6、说一下 Zookeeper 的通知机制？

client 端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些 client 会收到 zk 的通知，然后 client 可以根据 znode 变化来做出业务上的改变等.

#### **7、集群中为什么要有主节点？**

在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行 leader 选举.

#### **8、集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗？**

可以继续使用，单数服务器只要没超过一半的服务器宕机就可以继续使用.

集群规则为 2N+1 台，N >0，即最少需要 3 台.

#### 9、说一下两阶段提交和三阶段提交的过程？分别有什么问题？

- **两阶段提交协议 2PC**

**1. 第一阶段（投票阶段）：**

（1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应；

（2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志.

（3）各参与者节点响应协调者节点发起的询问.如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息.

**2. 第二阶段（提交执行阶段）：**

当协调者节点从所有参与者节点获得的相应消息都为”同意”时：

（1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求；

（2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源；

（3）参与者节点向协调者节点发送”完成”消息；

（4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务.

**两阶段提交存在的问题：**

\1. 执行过程中，所有参与节点都是事务阻塞型的.当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态；

\2. 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败；

\3. 协调者发生故障：参与者会一直阻塞下去.需要额外的备机进行容错；

\4. 二阶段无法解决的问题：协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了.那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交.

- **三阶段提交协议 3PC**

与两阶段提交不同的是，三阶段提交有两个改动点：

\1. 引入超时机制.同时在协调者和参与者中都引入超时机制；

\2. 在第一阶段和第二阶段中插入一个准备阶段.保证了在最后提交阶段之前各参与节点的状态是一致的.

也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段.

**1. CanCommit 阶段**

3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像.协调者向参与者发送 commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应.

（1）事务询问：协调者向参与者发送 CanCommit 请求.询问是否可以执行事务提交操作.然后开始等待参与者的响应.

（2）响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态.否则反馈 No.

**2. PreCommit 阶段**

协调者根据参与者的反应情况来决定是否可以继续事务的 PreCommit 操作.根据响应情况，有以下两种可能：

假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行.

（1）发送预提交请求：协调者向参与者发送 PreCommit 请求，并进入 Prepared 阶段.

（2）事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 undo 和 redo 信息记录到事务日志中.

（3）响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令.

假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断.

（1）发送中断请求：协调者向所有参与者发送 abort 请求.

（2）中断事务：参与者收到来自协调者的 abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断.

**3. doCommit 阶段**

该阶段进行真正的事务提交，也可以分为以下两种情况.

3.1 执行提交

（1）发送提交请求：协调接收到参与者发送的 ACK 响应，那么他将从预提交状态进入到提交状态.并向所有参与者发送 doCommit 请求.

（2）事务提交：参与者接收到 doCommit 请求之后，执行正式的事务提交.并在完成事务提交之后释放所有事务资源.

（3）响应反馈：事务提交完之后，向协调者发送 ACK 响应.

（4）完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务.

3.2 中断事务

协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务.

（1）发送中断请求：协调者向所有参与者发送 abort 请求.

（2）事务回滚：参与者接收到 abort 请求之后，利用其在阶段二记录的 undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源.

（3）反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息.

（4）中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断.

**三阶段提交的问题：**

网络分区可能会带来问题.需要四阶段解决：四阶段直接调用远程服务的数据状态，确定当前数据一致性的情况.

**10、Zookeeper 宕机如何处理？**

Zookeeper 本身也是集群，推荐配置不少于 3 个服务器.Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务.如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader.

Zookeeper 集群的机制是只要超过半数的节点正常，集群就能正常提供服务.只有在 Zookeeper 节点挂得太多，只剩一半或不到一半节点能工作，集群才失效.所以：

3 个节点的 cluster 可以挂掉 1 个节点(leader 可以得到 2 票 > 1.5)

2 个节点的 cluster 就不能挂掉任何1个节点了(leader 可以得到 1 票 <= 1)

#### **11. 说下四种类型的数据节点 Znode？**

\1. PERSISTENT：持久节点，除非手动删除，否则节点一直存在于 Zookeeper 上.

\2. EPHEMERAL：临时节点，临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与 Zookeeper连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除.

\3. PERSISTENT_SEQUENTIAL：持久顺序节点，基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字.

\4. EPHEMERAL_SEQUENTIAL：临时顺序节点，基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字.

#### **12、Zookeeper 和 Dubbo 的关系？**

Dubbo 的将注册中心进行抽象，是得它可以外接不同的存储媒介给注册中心提供服务，有 ZooKeeper，Memcached，Redis 等.

引入了 ZooKeeper 作为存储媒介，也就把 ZooKeeper 的特性引进来.首先是负载均衡，单注册中心的承载能力是有限的，在流量达到一定程度的时 候就需要分流，负载均衡就是为了分流而存在的，一个 ZooKeeper 群配合相应的 Web 应用就可以很容易达到负载均衡；资源同步，单单有负载均衡还不 够，节点之间的数据和资源需要同步，ZooKeeper 集群就天然具备有这样的功能；命名服务，将树状结构用于维护全局的服务地址列表，服务提供者在启动 的时候，向 ZooKeeper 上的指定节点 /dubbo/${serviceName}/providers 目录下写入自己的 URL 地址，这个操作就完成了服务的发布. 其他特性还有 Mast 选举，分布式锁等.

![img](https://mmbiz.qpic.cn/mmbiz_png/I47RwB1Z6Mw0ria869rB2Jsc6GQAoWICpjdypwkJdvLnakuReFkIkPTCjjXibwFVcAy4BYsmqUtCWPiaXHTh9woEA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# [Elecsticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)

#### 1. Elecsticsearch介绍

Elasticsearch 是一个**分布式可扩展**的**实时搜索**和分析引擎，一个建立在全文搜索引擎 Apache **Lucene**TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了**全文搜索**功能，还可以进行以下工作:

- 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。
- 实时分析的分布式搜索引擎。
- 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。

**集群分布式底层实现**：ES实际上就是利用分片来实现分布式。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， ES会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。默认情况下，一个索引会有5个主分片，而其副本可以有任意数量。

主分片和副本分片的状态决定了集群的健康状态。每一个节点上都只会保存主分片或者其对应的一个副本分片，相同的副本分片不会存在于同一个节点中。如果集群中只有一个节点，则副本分片将不会被分配，此时集群健康状态为yellow，存在丢失数据的风险。

>1. **分布式的含义**
>
>分布式系统（distributed system）是建立在网络之上的软件系统。正是因为软件的特性，所以分布式系统具有高度的内聚性和透明性。因此，网络和分布式系统之间的区别更多的在于高层软件（特别是操作系统），而不是硬件。
>
>2. **可拓展的含义**
>
> 可伸缩性(可扩展性)是一种对软件系统计算处理能力的设计指标，高可伸缩性代表一种弹性，在系统扩展成长过程中，软件能够保证旺盛的生命力，通过很少的改动甚至只是硬件设备的添置，就能实现整个系统处理能力的线性增长，实现高吞吐量和低延迟高性能。
>
>　　 可伸缩性和纯粹性能调优有本质区别， 可伸缩性是高性能、低成本和可维护性等诸多因素的综合考量和平衡，可伸缩性讲究平滑线性的性能提升，更侧重于系统的水平伸缩，通过廉价的服务器实现分布式计算；而普通性能优化只是单台机器的性能指标优化。他们共同点都是根据应用系统特点在吞吐量和延迟之间进行一个侧重选择，当然水平伸缩分区后会带来[CAP定理](http://www.jdon.com/37625)约束。
>
>　　 软件的可扩展性设计非常重要，但又比较难以掌握，业界试图通过云计算或高并发语言等方式节省开发者精力，但是，无论采取什么技术，如果应用系统内部是铁板一块，例如严重依赖数据库，系统达到一定访问规模，负载都集中到一两台数据库服务器上，这时进行分区扩展伸缩就比较困难，正如[Hibernate框架](https://www.jdon.com/dl/best/hibernate.htm)创建人Gavin King所说：关系数据库是最不可扩展的。
>
>3. **实时搜索**
>
>实时搜索（Real Time Search）简而言之就是对互联网上的一些信息进行即时、快速搜索，实现即搜即得的效果。
>
>4. **Lucene（雷森）**
>
>它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分[文本分析](https://baike.baidu.com/item/文本分析/11046544)引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。
>
>5. **Elasticsearch设计理念**
>
>一切设计都是为了提高搜索的性能
>
>6. **全文搜索**
>
>**全文搜索**是指计算机搜索程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，搜索程序就会根据事先建立的索引进行查找，并将查询结果返回给用户。

#### 2. Elecsticsearch核心概念

**1. 节点（node）**

**一个节点是集群中的一个服务器**，作为集群的一部分，存储数据，参与集群的索引和搜索功能。一个节点也是由一个名字来标识的。默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点，这个名字对于管理工作来说挺重要的，因为在这个管理过程中，要确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。

**2. 集群（cluster）**

**代表一个集群，集群中有多个节点node**，其中一个为主节点，这个主节点可以通过选举产生的，主节点是对于集群内部来说的。ES的一个概念就是**去中心化**，字面上理解就是无中心化节点，这是对于集群外部来说的，因为从外部来看ES集群，在逻辑上是一个整体，你与任何一个节点的通信和整个ES集群通信是等价的

一个集群就是由一个或者多个节点组织在一起，它们共同持有整个的数据，并在一起提供索引和搜索功能。一个集群由一个唯一的名字标识。一个节点只能通过指定某个集群的名字，来加入这个集群。

> **节点状态**：绿色（健康），黄色（预警），红色（报错）。

**3. 分片（shards）**

**shards代表索引分片**，ES可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。
 分片有两个好处，一是可以水平扩展，另一个是可以并发提高性能。

**4. 备份/副本（replicas）**

ES默认为一个索引创建5个主分片, 并分别为其创建一个副本分片. 也就是说每个索引都由5个主分片成本, 而每个主分片都相应的有一个copy.replicas代表索引副本，**副本指的是对主分片的备份**，这种备份是精确复制模式。ES可以设置多个索引副本，副本的作用一是提高系统的容错性，实现高可用（HA），当某个节点某个分片损坏或丢失时可以从副本中恢复；二是提高ES的查询效率，ES会自动对搜索请求进行负载均衡。

**5. 索引（index）**

ES将它的**数据存储在一个或多个索引（index）中**。类似sql中的数据库。可以向索引中写入文档或者读取文档，并通过ES内部使用Lucene将数据索引或从索引中检索数据，一个索引就是一个拥有几分相似特征的文档的集合（类似于我们在数据库中的库结构），一个索引由一个名字来标识，并且在我们要对对这个索引中的文档进行索引，搜索，更新和删除的时候，都要使用到这个名字。

**6. 类型（type）**

每个文档都有与之对应的类型定义。这允许用户在一个索引中存储多种文档类型，并为不同文档类型提供不同的映射

**7. 文档（document）**

文档是ES中主要的实体。对所有使用ES的案例来说，他们最终都可以终结为对文档的搜索。文档由字段构成。

**8. 映射（mapping）**

所有文档写进索引之前都会先进行分析，如果将输入的文本分割为词条，哪些词条又会被过滤，这种行为叫做映射（mapping）。一般由用户自己定义规则。 

#### 3. Elecsticsearch中的倒排索引

> [link1](https://blog.csdn.net/laoyang360/article/details/84727820?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare)
>
> [link2](https://blog.csdn.net/u013465194/article/details/83305411)

**倒排索引就建立分词与文档之间的映射关系**，在倒排索引之中，**数据时面向分词的而不是面向文档的**.

**在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合.例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置.**

那么，**倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词.**

举个栗子.

有以下文档：

![img](https://pic4.zhimg.com/80/v2-7dd22cae5e4c21870e6663955df5da7f_hd.jpg)

对文档进行分词之后，得到以下倒排索引.

![img](https://pic2.zhimg.com/80/v2-a65de3e2c0daebef6af836bdc2210675_hd.jpg)

另外，实用的倒排索引还可以记录更多的信息，比如文档频率信息，表示在文档集合中有多少个文档包含某个单词.那么，**有了倒排索引，搜索引擎可以很方便地响应用户的查询.比如用户输入查询 `Facebook`，搜索系统查找倒排索引，从中读出包含这个单词的文档，这些文档就是提供给用户的搜索结果.**

要注意倒排索引的两个重要细节：

- 倒排索引中的所有词项对应一个或多个文档；
- 倒排索引中的词项根据字典顺序升序排列

上面只是一个简单的栗子，并没有严格按照字典顺序升序排列.

#### 4. Elasticsearch分布式搜索引擎架构图

> https://www.cnblogs.com/ningskyer/articles/5789010.html

![img](https://images2015.cnblogs.com/blog/462486/201608/462486-20160819212144031-548437647.png)





#### 5. [Elasticsearch节点自动发现机制](https://www.cnblogs.com/jajian/p/10176707.html)

在Elasticsearch内部，通过在集群中配置一个相同的集群节点。就能将不同节点连接到一个集群，它是如何做到的呢？

Elasticsearch的选主是ZenDiscovery模块负责的，Zen discovery是内建的、默认的、用于Elasticsearch的发现模块。它提供了单播和基于文件的发现，可以通过插件扩展到支持云环境和其他形式的发现。有两种方法可用于配置种子节点列表：**单播**和**基于文件**。建议种子节点列表主要由集群中那些 Master-eligible 的节点组成。

**单播模式：**

   节点首先执行ping（节点之间通过这个RPC来发现彼此）命令，ping命令的返回结果是该节点的基本信息和该节点认为的主节点。

**那么ping命令是如何实现选举的呢?** 

　　Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；

　　对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点.
　　如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master.否则重新选举一直到满足上述条件。

**为什么节点数是n/2+1？**

Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？

　　当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；
当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题.

>**选举主节点详细解释：**
>
>作为 ping 过程的一部分，一个集群的主节点需要是被选举或者加入进来的(即选举主节点也会执行ping，其他的操作也会执行ping)。这个过程是自动执行的。通过配置`discovery.zen.ping_timeout`来控制节点加入某个集群或者开始选举的响应时间(默认3s)。
>
>在这段时间内有3个 ping 会发出。如果超时,重新启动 ping 程序。在网络缓慢时，3秒时间可能不够，这种情况下，需要慎重增加超时时间，增加超时时间会减慢选举进程。
>
>一旦节点决定加入一个存在的集群，它会发出一个加入请求给主节点，这个请求的超时时间由`discovery.zen.join_time`控制，默认是 ping 超时时间(`discovery.zen.ping_timeout`)的20倍。
>
>当主节点停止或者出现问题，集群中的节点会重新 ping 并选举一个新节点。有时一个节点也许会错误的认为主节点已死，所以这种 ping 操作也可以作为部分网络故障的保护性措施。在这种情况下，节点将只从其他节点监听有关当前活动主节点的信息。
>
>如果`discovery.zen.master_election.ignore_non_master_pings`设置为`true`时（默认值为`false`），`node.master`为`false`的节点不参加主节点的选举，同时选票也不包含这种节点。
>
>通过设置`node.master`为`false`，可以将节点设置为非备选主节点，永远没有机会成为主节点。
>
>`discovery.zen.minimum_master_nodes`设置了最少有多少个备选主节点参加选举，同时也设置了一个主节点需要控制最少多少个备选主节点才能继续保持主节点身份。如果控制的备选主节点少于`discovery.zen.minimum_master_nodes`个，那么当前主节点下台，重新开始选举。
>
>`discovery.zen.minimum_master_nodes`必须设置一个恰当的备选主节点值(`quonum`，一般设置 为备选主节点数/2+1)，尽量避免只有两个备选主节点，因为两个备选主节点`quonum`应该为2，那么如果一个节点出现问题，另一个节点的同意人数最多只能为1，永远也不能选举出新的主节点，这时就发生了脑裂现象。

#### **6. Elasticsearch搜索数据过程**

es最强大的是做全文检索，搜索过程大体上分为**查询**和**取回**这两个阶段，搜索的底层原理：倒排索引，**查询**阶段通过结果分词得到文档标识符，协调结点在对其进行处理后，再**取回**实际的文档数据。

1. 客户端发送请求到一个coordinate node（协调节点）
2. 协调节点将搜索请求转发到所有的shard（分片）对应的primary shard（主分片）或replica shard（副本分片）也可以。
3. query phase（查询阶段）：每个shard将自己的搜索结果（其实就是一些doc id（文档标识符）），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果
4. fetch phase（取回阶段）：接着由协调节点，根据doc id（文档标识符）去各个节点上拉取实际的document（document）数据，最终返回给客户端

>**搜索的底层原理**：，广播查询请求到所有相关分片，并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端.
>
>  1. 当一个节点接收到一个搜索请求，这这个节点就会变成协调节点，第一步就是将广播请求到搜索的每一个节点的分片拷贝，查询请求可以被某一个主分片或某一个副分片处理，协调节点将在之后的请求中轮训所有的分片拷贝来分摊负载.
>  2. 每一个分片将会在本地构建一个优先级队列，如果客户端要求返回结果排序中从from 名开始的数量为size的结果集，每一个节点都会产生一个from+size大小的结果集，因此优先级队列的大小也就是from+size，分片仅仅是返回一个轻量级的结果给协调节点，包括结果级中的每一个文档的ID和进行排序所需要的信息.
>  3. 协调节点将会将所有的结果进行汇总，并进行全局排序，最总得到排序结果.
>  1. 查询过程得到的排序结果，标记处哪些文档是符合要求的，此时仍然需要获取这些文档返回给客户端
>  2. 协调节点会确定实际需要的返回的文档，并向含有该文档的分片发送get请求，分片获取的文档返回给协调节点，协调节点将结果返回给客户端.

#### **7. Elasticsearch写数据的过程**

![img](https://pic4.zhimg.com/80/v2-4de48f728e3ed0fa74db9e2e3b0a1cdb_hd.jpg)

1. 客户端选择一个**node**发送请求过去，这个node就是**coordinating node** (协调节点)
2. coordinating node，对document（文档）进行路由，将请求转发给**对应的node**（有**primary shard**）
3. 实际上的**node**上的primary shard（主分片）处理请求，然后将数据同步到**replica node**（副本结点）
4. coordinating node，如果发现**primary node**和所有的**replica node**都搞定之后，就会返回请求到客户端

>**写入数据的底层原理**
>
>1. 数据先写入到buffer里面，在buffer里面的数据时搜索不到的，同时将数据写入到translog日志文件之中
>2. 如果buffer快满了，或是一段时间之后，就会将buffer数据refresh到一个新的OS cache之中，然后每隔1秒，就会将OS cache的数据写入到segment file之中，但是如果每一秒钟没有新的数据到buffer之中，就会创建一个新的空的segment file，只要buffer中的数据被refresh到OS cache之中，就代表这个数据可以被搜索到了.当然可以通过restful api 和Java api，手动的执行一次refresh操作，就是手动的将buffer中的数据刷入到OS cache之中，让数据立马搜索到，只要数据被输入到OS cache之中，buffer的内容就会被清空了.同时进行的是，数据到shard之后，就会将数据写入到translog之中，每隔5秒将translog之中的数据持久化到磁盘之中
>3. 重复以上的操作，每次一条数据写入buffer，同时会写入一条日志到translog日志文件之中去，这个translog文件会不断的变大，当达到一定的程度之后，就会触发commit操作.
>4. 将一个commit point写入到磁盘文件，里面标识着这个commit point 对应的所有segment file
>5. 强行将OS cache 之中的数据都fsync到磁盘文件中去.
>     解释：translog的作用：在执行commit之前，所有的而数据都是停留在buffer或OS cache之中，无论buffer或OS cache都是内存，一旦这台机器死了，内存的数据就会丢失，所以需要将数据对应的操作写入一个专门的日志问价之中，一旦机器出现宕机，再次重启的时候，es会主动的读取translog之中的日志文件的数据，恢复到内存buffer和OS cache之中.
>6. 将现有的translog文件进行清空，然后在重新启动一个translog，此时commit就算是成功了，默认的是每隔30分钟进行一次commit，但是如果translog的文件过大，也会触发commit，整个commit过程就叫做一个flush操作，我们也可以通过ES API，手动执行flush操作，手动将OS cache 的数据fsync到磁盘上面去，记录一个commit point，清空translog文件
>     补充：其实translog的数据也是先写入到OS cache之中的，默认每隔5秒之中将数据刷新到硬盘中去，也就是说，可能有5秒的数据仅仅停留在buffer或者translog文件的OS cache中，如果此时机器挂了，会丢失5秒的数据，但是这样的性能比较好，我们也可以将每次的操作都必须是直接fsync到磁盘，但是性能会比较差.
>7. 如果时删除操作，commit的时候会产生一个.del文件，里面讲某个doc标记为delete状态，那么搜索的时候，会根据.del文件的状态，就知道那个文件被删除了.
>8. 如果时更新操作，就是讲原来的doc标识为delete状态，然后重新写入一条数据即可.
>9. buffer每次更新一次，就会产生一个segment file 文件，所以在默认情况之下，就会产生很多的segment file 文件，将会定期执行merge操作
>10. 每次merge的时候，就会将多个segment file 文件进行合并为一个，同时将标记为delete的文件进行删除，然后将新的segment file 文件写入到磁盘，这里会写一个commit point，标识所有的新的segment file，然后打开新的segment file供搜索使用.
>
>总之，segment的四个核心概念，**refresh**，**flush**，**translog**、**merge**
>

 **写数据底层原理**



![img](https://pic2.zhimg.com/80/v2-fd22b4cf9003391a521da8d7c10e458d_hd.jpg)![img](https://pic2.zhimg.com/80/v2-fd22b4cf9003391a521da8d7c10e458d_hd.jpg)

#### 8. Elasticsearch读数据过程

查询，GET某一条的数据，写入某个document，这个document会自动给你分配一个全局的唯一ID，同时根据这个ID进行hash路由到对应的primary shard上面去，当然也可以手动的设置ID。

1. 客户端发送任何一个请求到任意一个node，成为coordinate node
2. coordinate node 对document进行路由，将请求转发到对应的node，此时会使用round-robin**随机轮训算法**，在primary shard 以及所有的replica中随机选择一个，让读请求**负载均衡**，
3. 接受请求的node，返回document（**文件**）给coordinate note。
4. coordinate node返回给客户端

~~~markdown
1.写入document时，每个document会自动分配一个全局唯一的id即doc id，同时也是根据doc id进行hash路由到对应的primary shard上。也可以手动指定doc id，比如用订单id，用户id。
2.读取document时，你可以通过doc id来查询，然后会根据doc id进行hash，判断出来当时把doc id分配到了哪个shard上面去，从那个shard去查询
~~~

#### 9. Elasticsearch文档的索引更新和删除

> **文档**是ES中主要的实体。对所有使用ES的案例，它们最终都可以总结为对文档的搜索。文档由字段构成。

**1. Elasticsearch索引文档的过程**

协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的分片。

~~~markdown
shard = hash(document_id) % (num_of_primary_shards)
~~~

1、当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到 Filesystem Cache，这个从 Momery Buffer 到 Filesystem Cache 的过程就叫做 refresh；

2、当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；

3、在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync将创建一个新的提交点，并将容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。

4、flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；

**补充：关于 Lucene 的 Segement：**

1、Lucene 索引是由多个段组成，段本身是一个功能齐全的倒排索引。

2、段是不可变的，允许 Lucene 将新的文档增量地添加到索引中，而不用从头重

建索引。

3、对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗

CPU 的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。

4、为了解决这个问题，Elasticsearch 会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。

**2.Elasticsearch更新和删除文档的过程**

　　删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；
　　磁盘上的每个段都有一个相应的.del文件.当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除.该文档依然能匹配查询，但是会在结果中被过滤掉.当段合并时，在.del文件中被标记为删除的文档将不会被写入新段.
　　在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段.旧版本的文档依然能匹配查询，但是会在结果中被过滤掉.

#### 10. Elasticsearch如果保证在并发情况下读写一致？

　　可以通过版本号使用**乐观并发控制**，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
　　另外对于**写操作**，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作.但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建.
　　对于**读操作**，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本.

#### 11. Elasticsearch对于大数据量的聚合如何实现？

​	　　Elasticsearch 提供的首个近似聚合是cardinality 度量.它提供一个字段的基数，即该字段的distinct或者unique值的数目.它是基于HLL算法的.HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数.其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量.无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 .

#### **12. Elasticsearch在海量数据中怎样提高效率**

1. filesystem cache
     ES的搜索引擎是严重的依赖底层的filesystem cache，如果给filesystem cache更多的内存，尽量让内存可以容纳所有的index segment file 索引数据文件
2. 数据预热
     对于那些你觉得比较热的数据，经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据，每隔一段时间，你就提前访问以下，让数据进入filesystem cache里面去，这样期待下次访问的时候，性能会更好一些.
3. 冷热分离

关于ES的性能优化，数据拆分，将大量的搜索不到的字段，拆分到别的存储中去，这个类似于MySQL的分库分表的垂直才分.

1. document的模型设计

不要在搜索的时候去执行各种复杂的操作，尽量在document模型设计的时候，写入的时候就完成了，另外对于一些复杂的操作，尽量要避免

1. 分页性能优化

翻页的时候，翻得越深，每个shard返回的数据越多，而且协调节点处理的时间越长，当然是用scroll，scroll会一次性的生成所有数据的一个快照，然后每次翻页都是通过移动游标完成的. api 只是在一页一页的往后翻

作者：雨露
        链接：https://segmentfault.com/a/1190000015256970
        来源：SegmentFault 思否
        著作权归作者所有.商业转载请联系作者获得授权，非商业转载请注明出处.



#### 13.[Elasticsearch 字段数据类型](https://www.cnblogs.com/valor-xh/p/6250302.html)

Elasticsearch 可以支持单个document中含有多个不同的数据类型。

------

**核心数据类型（Core datatypes）**

- 字符型（[String datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/string.html)）：string
- 数字型（[Numeric datatypes](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/number.html)）：long：64位存储 , integer：32位存储 , short：16位存储 , byte：8位存储 , double：64位双精度存储 , float：32位单精度存储 
- 日期型（[Date datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/date.html)）：date
- 布尔型（[Boolean datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/boolean.html)）：boolean
- 二进制型（[Binary datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/binary.html)）：binary

**复杂数据类型（Complex datatypes）**

- 数组类型（

  Array datatype

  ）：数组类型不需要专门指定数组元素的type，例如：

  - 字符型数组: [ "one", "two" ]
  - 整型数组：[ 1, 2 ]
  - 数组型数组：[ 1, [ 2, 3 ]] 等价于[ 1, 2, 3 ]
  - 对象数组：[ { "name": "Mary", "age": 12 }, { "name": "John", "age": 10 }]

- 对象类型（[Object datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/object.html)）： *object* 用于单个JSON对象；

- 嵌套类型（[Nested datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/nested.html)）： *nested* 用于JSON数组；

**地理位置类型（Geo datatypes）**

- 地理坐标类型（[Geo-point datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/geo-point.html)）： *geo_point* 用于经纬度坐标；
- 地理形状类型（[Geo-Shape datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/geo-shape.html)）： *geo_shape* 用于类似于多边形的复杂形状；

**专业类型（Specialised datatypes）**

- IPv4 类型（[IPv4 datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/ip.html)）： *ip* 用于IPv4 地址；
- Completion 类型（[Completion datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/search-suggesters-completion.html)）： *completion* 提供自动补全建议；
- Token count 类型（[Token count datatype](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/token-count.html)）： *token_count* 用于统计做了标记的字段的index数目，该值会一直增加，不会因为过滤条件而减少。
- [mapper-murmur3 ](https://www.elastic.co/guide/en/elasticsearch/plugins/2.3/mapper-size.html)类型：通过插件，可以通过 *murmur3* 来计算index的 hash 值；
- 附加类型（Attachment datatype）：采用[mapper-attachments ](https://www.elastic.co/guide/en/elasticsearch/plugins/2.3/mapper-attachments.html)插件，可支持 *attachments* 索引，例如Microsoft Office 格式，Open Document 格式，ePub, HTML 等。



# Nginx

#### **1、什么是Nginx**

Nginx是一个高性能的反向代理服务器，他是一个非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发

#### **2、为什么要用Nginx**

跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少，

而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。

使用Nginx的话还能：

节省宽带：支持GZIP压缩，可以添加浏览器本地缓存

稳定性高：宕机的概率非常小

接收用户请求是异步的

#### **3、为什么Nginx性能这么高**

因为他的事件处理机制：异步非阻塞事件处理机制：运用了**epoll**模型，提供了一个队列，排队解决

#### **4.Nginx怎么处理请求的**

nginx接收一个请求后，首先由listen和server_name指令匹配server模块，再匹配server模块里的location，location就是实际地址

#### **5.什么是正向代理和反向代理**

1、正向代理就是一个人发送一个请求直接就到达了目标的服务器

2、反方代理就是请求统一被Nginx接收，nginx反向代理服务器接收到之后，按照一定的规则分发给了后端的业务处理服务器进行处理了

#### **6.使用“反向代理服务器的优点是什么?**

反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

#### **7.Nginx的优缺点**

优点：

1.占内存小，可实现高并发连接，处理响应快

2.可实现http服务器、虚拟主机、方向代理、负载均衡

3.Nginx配置简单

4.可以不暴露正式的服务器IP地址

缺点：

动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，

**8.如何用Nginx解决前端跨域问题？**

使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。

**9 .限流怎么做的，算法是什么，（限制请求速度）**

Nginx限流就是限制用户请求速度，防止服务器受不了

限流有3种，我这只写了最平常的一种（限制访问频率（正常流量））

1、限制访问频率（正常流量）

2、限制访问频率（突发流量）

3、限制并发连接数

1、限制访问频率（正常流量）：限制一个用户发送的请求，我Nginx多久接收一个。

\#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉

1. limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;
2. \#绑定限流维度
3. server{
4. location/seckill.html{
5. limit_req zone=one
6. proxy_pass [http://lj_seckill](https://link.zhihu.com/?target=http%3A//lj_seckill);
7. }
8. }

1r/s代表1秒一个请求1r/m一分钟接收一个请求

（此流也叫做漏桶流，多余的请求全部不要，漏掉）

#### **10.为什么要做动静分离?**

Nginx是当下最热的Web容器，网站优化的重要点在于静态化网站，网站静态化的关键点则是是动静分离，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们则根据静态资源的特点将其做缓存操作。

让静态的资源只走静态资源服务器，动态的走动态的服务器

Nginx的静态处理能力很强，但是动态处理能力不足，因此，在企业中常用动静分离技术。

对于静态资源比如图片，js，css等文件，我们则在反向代理服务器nginx中进行缓存。这样浏览器在请求一个静态资源时，代理服务器nginx就可以直接处理，无需将请求转发给后端服务器tomcat。

若用户请求的动态文件，比如servlet,jsp则转发给Tomcat服务器处理，从而实现动静分离。这也是反向代理服务器的一个重要的作用。

#### **11.怎么做的动静分离**

只需要指定路径对应的目录。location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：（操作都是在Linux上）

1. location /image/ {
2. root /usr/local/static/;
3. autoindex on;
4. }

1、创建目录

mkdir /usr/local/static/image

2、进入目录

cd /usr/local/static/image

3、放一张照片上去#

ls

1.jpg

4、重启 nginx

sudo nginx -s reload

5、打开浏览器 输入 server_name/image/1.jpg 就可以访问该静态图片了

#### **12、Nginx负载均衡的算法怎么实现的?策略有哪些?**

为了避免服务器崩溃，大家会通过负载均衡的方式来分担服务器压力。将对台服务器组成一个集群，当用户访问时，先访问到一个转发服务器，再由转发服务器将访问分发到压力更小的服务器。

Nginx负载均衡实现的策略有以下五种：

(1) 轮询(默认)

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。

1. upstream backserver {
2. server 192.168.0.12;
3. server 192.168.0.13;
4. }

(2) 权重 weight

weight的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。其次是为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。

1. upstream backserver {
2. server 192.168.0.12 weight=2;
3. server 192.168.0.13 weight=8;
4. }

权重越高，在被访问的概率越大，如上例，分别是20%，80%。

(3) ip_hash( IP绑定)

每个请求按访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题

1. upstream backserver {
2. ip_hash;
3. server 192.168.0.12:88;
4. server 192.168.0.13:80;
5. }

(4) fair(第三方插件)

必须安装upstream_fair模块。

对比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。

1. upstream backserver {
2. server server1;
3. server server2;
4. fair;
5. }

哪个服务器的响应速度快，就将请求分配到那个服务器上。

(5) url_hash(第三方插件)

必须安装Nginx的hash软件包

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。

1. upstream backserver {
2. server squid1:3128;
3. server squid2:3128;
4. hash $request_uri;
5. hash_method crc32;
6. }

# 项目相关

#### 1. session 和 cookie的区别

cookie 的出现是因为 **HTTP 是无状态**的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录.这显然是让人无法接受的，cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你.

抽象地概括一下：**一个 cookie 可以认为是一个「变量」，形如** **`name=value`**，**存储在浏览器**；一个 session 可以理解为一种数据结构，多数情况是「映射」（键值对），存储在服务器上.

注意，我说的是「一个」cookie 可以认为是一个变量，但是服务器可以一次设置多个 cookie，所以有时候说 cookie 是「一组」键值对儿，这也可以说得通.

cookie 可以在服务器端通过 HTTP 的 SetCookie 字段设置 cookie，比如我用 Go 语言写的一个简单服务：

```
func cookie(w http.ResponseWriter， r *http.Request) {    // 设置了两个 cookie     http.SetCookie(w， &http.Cookie{        Name:       "name1"，        Value:      "value1"，    })
    http.SetCookie(w， &http.Cookie{        Name:  "name2"，        Value: "value2"，    })    // 将字符串写入网页    fmt.Fprintln(w， "页面内容")}
```

当浏览器访问对应网址时，通过浏览器的开发者工具查看此次 HTTP 通信的细节，可以看见服务器的回应发出了两次 `SetCookie` 命令：

![img](https://gblobscdn.gitbook.com/assets%2F-LrtQOWSnDdXhp3kYN4k%2Fsync%2F906f7090f76e1605ddc3e8d4ea7ca5b8418dd735.png?alt=media)

在这之后，浏览器的请求中的 `Cookie` 字段就带上了这两个 cookie：

![img](https://gblobscdn.gitbook.com/assets%2F-LrtQOWSnDdXhp3kYN4k%2Fsync%2Fd2660b22193958f9209ee4cc2b9ed23f7ae64f9f.png?alt=media)

**cookie 的作用其实就是这么简单，无非就是服务器给每个客户端（浏览器）打的标签**，方便服务器辨认而已.当然，HTTP 还有很多参数可以设置 cookie，比如过期时间，或者让某个 cookie 只有某个特定路径才能使用等等.

但问题是，我们也知道现在的很多网站功能很复杂，而且涉及很多的数据交互，比如说电商网站的购物车功能，信息量大，而且结构也比较复杂，无法通过简单的 cookie 机制传递这么多信息，而且要知道 cookie 字段是存储在 HTTP header 中的，就算能够承载这些信息，也会消耗很多的带宽，比较消耗网络资源.

session 就可以配合 cookie 解决这一问题，比如说一个 cookie 存储这样一个变量 `sessionID=xxxx`，仅仅把这一个 cookie 传给服务器，然后服务器通过这个 ID 找到对应的 session，这个 session 是一个数据结构，里面存储着该用户的购物车等详细信息，服务器可以通过这些信息返回该用户的定制化网页，有效解决了追踪用户的问题.

**session 是一个数据结构，由网站的开发者设计，所以可以承载各种数据**，只要客户端的 cookie 传来一个唯一的 session ID，服务器就可以找到对应的 session，认出这个客户.

当然，由于 session 存储在服务器中，肯定会消耗服务器的资源，所以 session 一般都会有一个过期时间，服务器一般会定期检查并删除过期的 session，如果后来该用户再次访问服务器，可能就会面临重新登录等等措施，然后服务器新建一个 session，将 session ID 通过 cookie 的形式传送给客户端.

那么，我们知道 cookie 和 session 的原理，有什么切实的好处呢？**除了应对面试，我给你说一个鸡贼的用处，就是可以白嫖某些服务**.

有些网站，你第一次使用它的服务，它直接免费让你试用，但是用一次之后，就让你登录然后付费继续使用该服务.而且你发现网站似乎通过某些手段记住了你的电脑，除非你换个电脑或者换个浏览器才能再白嫖一次.

那么问题来了，你试用的时候没有登录，网站服务器是怎么记住你的呢？这就很显然了，服务器一定是给你的浏览器打了 cookie，后台建立了对应的 session 记录你的状态.你的浏览器在每次访问该网站的时候都会听话地带着 cookie，服务器一查 session 就知道这个浏览器已经免费使用过了，得让它登录付费，不能让它继续白嫖了.

那如果我不让浏览器发送 cookie，每次都伪装成一个第一次来试用的小萌新，不就可以不断白嫖了么？浏览器会把网站的 cookie 以文件的形式存在某些地方（不同的浏览器配置不同），你把他们找到然后删除就行了.但是对于 Firefox 和 Chrome 浏览器，有很多插件可以直接编辑 cookie，比如我的 Chrome 浏览器就用的一款叫做 EditThisCookie 的插件，这是他们官网：

![img](https://gblobscdn.gitbook.com/assets%2F-LrtQOWSnDdXhp3kYN4k%2Fsync%2F622a8f707eaa67359df9ae72ce941d44e16b61fb.png?alt=media)

http://www.editthiscookie.com/

这类插件可以读取浏览器在当前网页的 cookie，点开插件可以任意编辑和删除 cookie.**当然，偶尔白嫖一两次还行，不鼓励高频率白嫖，想常用还是掏钱吧，否则网站赚不到钱，就只能取消免费试用这个机制了**.

以上就是关于 cookie 和 session 的简单介绍，cookie 是 HTTP 协议的一部分，不算复杂，而 session 是可以定制的，所以下面详细看一下实现 session 管理的代码架构吧.

**二、session 的实现**

session 的原理不难，但是具体实现它可是很有技巧的，一般需要三个组件配合完成，它们分别是 `Manager`、`Provider` 和 `Session` 三个类（接口）.

![img](https://gblobscdn.gitbook.com/assets%2F-LrtQOWSnDdXhp3kYN4k%2Fsync%2F81e92eedd11aa0d409adca08c160e3224b0e1d29.jpg?alt=media)

1、浏览器通过 HTTP 协议向服务器请求路径 `/content` 的网页资源，对应路径上有一个 Handler 函数接收请求，解析 HTTP header 中的 cookie，得到其中存储的 sessionID，然后把这个 ID 发给 `Manager`.

2、`Manager` 充当一个 session 管理器的角色，主要存储一些配置信息，比如 session 的存活时间，cookie 的名字等等.而所有的 session 存在 `Manager` 内部的一个 `Provider` 中.所以 `Manager` 会把 `sid`（sessionID）传递给 `Provider`，让它去找这个 ID 对应的具体是哪个 session.

3、`Provider` 就是一个容器，最常见的应该就是一个散列表，将每个 `sid` 和对应的 session 一一映射起来.收到 `Manager` 传递的 `sid` 之后，它就找到 `sid` 对应的 session 结构，也就是 `Session` 结构，然后返回它.

4、`Session` 中存储着用户的具体信息，由 Handler 函数中的逻辑拿出这些信息，生成该用户的 HTML 网页，返回给客户端.

那么你也许会问，为什么搞这么麻烦，直接在 Handler 函数中搞一个哈希表，然后存储 `sid` 和 `Session` 结构的映射不就完事儿了？

**这就是设计层面的技巧了**，下面就来说说，为什么分成 `Manager`、`Provider` 和 `Session`.

先从最底层的 `Session` 说.既然 session 就是键值对，为啥不直接用哈希表，而是要抽象出这么一个数据结构呢？

第一，因为 `Session` 结构可能不止存储了一个哈希表，还可以存储一些辅助数据，比如 `sid`，访问次数，过期时间或者最后一次的访问时间，这样便于实现想 LRU、LFU 这样的算法.

第二，因为 session 可以有不同的存储方式.如果用编程语言内置的哈希表，那么 session 数据就是存储在内存中，如果数据量大，很容易造成程序崩溃，而且一旦程序结束，所有 session 数据都会丢失.所以可以有很多种 session 的存储方式，比如存入缓存数据库 Redis，或者存入 MySQL 等等.

因此，`Session` 结构提供一层抽象，屏蔽不同存储方式的差异，只要提供一组通用接口操纵键值对：



```
type Session interface {
    // 设置键值对
    Set(key， val interface{})
    // 获取 key 对应的值
    Get(key interface{}) interface{}
    // 删除键 key
    Delete(key interface{})
}
```

再说 `Provider` 为啥要抽象出来.我们上面那个图的 `Provider` 就是一个散列表，保存 `sid` 到 `Session` 的映射，但是实际中肯定会更加复杂.我们不是要时不时删除一些 session 吗，除了设置存活时间之外，还可以采用一些其他策略，比如 LRU 缓存淘汰算法，这样就需要 `Provider` 内部使用哈希链表这种数据结构来存储 session.

PS：关于 LRU 算法的奥妙，参见前文「LRU 算法详解」.

因此，`Provider` 作为一个容器，就是要屏蔽算法细节，以合理的数据结构和算法组织 `sid` 和 `Session` 的映射关系，只需要实现下面这几个方法实现对 session 的增删查改：



```
type Provider interface {
    // 新增并返回一个 session
    SessionCreate(sid string) (Session， error)
    // 删除一个 session
    SessionDestroy(sid string)
    // 查找一个 session
    SessionRead(sid string) (Session， error)
    // 修改一个session
    SessionUpdate(sid string)
    // 通过类似 LRU 的算法回收过期的 session
    SessionGC(maxLifeTime int64)
}
```

最后说 `Manager`，大部分具体工作都委托给 `Session` 和 `Provider` 承担了，`Manager` 主要就是一个参数集合，比如 session 的存活时间，清理过期 session 的策略，以及 session 的可用存储方式.`Manager` 屏蔽了操作的具体细节，我们可以通过 `Manager` 灵活地配置 session 机制.

综上，session 机制分成几部分的最主要原因就是解耦，实现定制化.我在 Github 上看过几个 Go 语言实现的 session 服务，源码都很简单，有兴趣的朋友可以学习学习：

https://github.com/alexedwards/scs

https://github.com/astaxie/build-web-application-with-golang

# 正则表达式

https://www.runoob.com/regexp/regexp-syntax.html

https://blog.csdn.net/qq_41035588/article/details/80561278?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.compare)



# 知识修补

 **1.** **es相关知识（es中的数据类型，倒排索引，插入数据和读数据过程es中refresh过程）**

**2.** 消息队列

**3.** **JVM调优**

**4.**MYSQL调优

**5.**redis分布式锁